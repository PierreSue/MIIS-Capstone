[
    {
        "start_timestamp": "00:00:00",
        "transcript": "Okay, we might have some later and people come in, but i'm going to start anyway. Today's lecture. Oh, i noticed that we're not 492 anymore. We're 18495. but that's not important. And today's lecture is about human speech, so how humans process speech. We're not really going to be talking about humans as such. We're really interested in computer speech processing. But understanding the space that affects humans in dealing with human language is pretty important or useful when trying to design algorithms for dealing with computational speech. So i'm going to give pretty much an overview of phonetics and phonology prosody, just so that you get a background. I know some of you have already seen this in other classes. In fact, you've probably gone in more detail if you've done an actual phonology class. I'm not going into much detail, but i'm just making sure that you have some understanding of, uh, of the background. Okay, as usual, you can interrupt me anytime with questions. Just unmute yourself and speak. Now, speech is generated by the vocal",
        "transcript-corrected": "Okay, we might have some later and people come in, but I'm going to start anyway. Today's lecture. Oh, I noticed that we're not 492 anymore. We're 18495. But that's not important. And today's lecture is about human speech, so how humans process speech. We're not really going to be talking about humans as such. We're really interested in computer speech processing. But understanding the space that affects humans in dealing with human language is pretty important or useful when trying to design algorithms for dealing with computationally speech. So I'm going to give pretty much an overview of phonetics and phonology prosody, just so that you get a background. I know some of you have already seen this in other classes. In fact, you've probably gone into more detail if you've done an actual phonology class. I'm not going into much detail, but I'm just making sure that you have some understanding of, uh, of the background. Okay, as usual, you can interrupt me anytime with questions. Just unmute yourself and speak. Now, speech is generated by the vocal",
        "brief-summary": "Hello everyone, and welcome to today's lecture. I'm not going into much detail, but I'm just making sure that you have some understanding of, uh, of the background."
    },
    {
        "start_timestamp": "00:01:16",
        "transcript": "Now, speech is generated by the vocal tract, which is a lump of meat inside your head and throat. You blow air through it, and you put things in the way. So you make it a bit like a trumpet, and blow air. And it's got resonant frequencies, like a trumpet that allow you to get vowels like r and e. and how you position your mouth and how you position your tongue allows you to get different frequencies that allow you to get things that other humans can recognize, and dogs can recognize, as you actually making different sounds, then we've decided to recognize these as such, these different noises that we make. Or can be there's just the wind blowing through a tube. But we can also put things in the way. So we have our tongue, we have our teeth, we have our lips. We have a thing down the back of our throat, the larynx. And if we blow hard enough, it vibrates, so we get things like ah. And if we don't blow hard enough, we get things that don't make these voicing noises, and we get things like okay. And most human speech distinguishes between languages, distinguish between voiced ah and unvoiced. And you can do this for consonants. Almost all vowels are are voiced. There are technically a few examples of where vowels are not voiced, but they're a little weird, so we won't go into those. But consonants, we can voice or unvoice them. Okay? So we can have which is unvoiced, then we can have which is voiced. Okay. And i apologize to all of the southern chinese people that we have, because you probably don't make distinctions between s and z. okay? Actually, lots of different languages and dialects don't make distinctions between some of those. And we'll come up with those. And we'll show you some of the distinctions which are there, which you have and you think others have and that you do not have others, just to give you some variety here. But it's pretty interesting that we have this lump of meat that we blow air through, and it causes us to make noises that other people can actually hear, okay, and understand and distinguish. And so that's what's interesting about um",
        "transcript-corrected": "Now, speech is generated by the vocal tract, which is a lump of meat inside your head and throat. You blow air through it, and you put things in the way. So you make it a bit like a trumpet, and blow air. And it's got resonant frequencies, like a trumpet that allow you to get vowels like r and e. and how you position your mouth and how you position your tongue allows you to get different frequencies that allow you to get things that other humans can recognize, and dogs can recognize, as you actually making different sounds, then we've decided to recognize these as such, these different noises that we make. Or can be there's just the wind blowing through a tube. But we can also put things in the way. So we have our tongue, we have our teeth, we have our lips. We have a thing down the back of our throat, the larynx. And if we blow hard enough, it vibrates, so we get things like ah. And if we don't blow hard enough, we get things that don't make these voicing noises, and we get things like okay. And most human speech distinguishes between languages, distinguish between voiced ah and unvoiced. And you can do this for consonants. Almost all vowels are voiced. There are technically a few examples of where vowels are not voiced, but they're a little weird, so we won't go into those. But consonants, we can voice or enforce them. Okay? So we can have which is unvoiced, then we can have which is voiced. Okay. And I apologize to all of the southern Chinese people that we have, because you probably don't make distinctions between s and z. Okay? Actually, lots of different languages and dialects don't make distinctions between any of those. And we'll come up with those. And we'll show you some of the distinctions which are there, which you have and you think others have and that you do not have others, just to give you some variety here. But it's pretty interesting that we have this lump of meat that we blow air through, and it causes us to make noises that other people can actually hear, okay, and understand and distinguish. And so that's what's interesting about um",
        "brief-summary": "We're going to talk a little bit about speech."
    },
    {
        "start_timestamp": "00:03:42",
        "transcript": "So that's what's interesting about a speech generation. So why is it the other end? What happens at the other end, the ear? So we generate these sounds, and what we're actually doing coming out of our mouth is we're changing air pressure. So we're changing air pressure at different frequencies. So when i do something that's higher range, like e it's going to change the pressure quicker than if it does it that okay? So we're going to get different amounts of pressure. So pressure is high pressure air and low pressure. Here will be these sound waves that come out of my mouth. Now, what happens to that? Well, actually, imagine that we're in the lecture theater, because i want to explain that to you now. Rather than the intermediate thing of going through a microphone and going across the internet and coming internet and coming out of the speaker or your earbuds, but imagine that we're in the lecture hall. When i'm speaking, what happens is these pressure waves go off and bounce off all the walls and the ceiling and the floor and the people and the blackboard, and they go back and forward. And they eventually, with all of that going back and forward, get to your ears. You in particular, not the person next to you. Some other route will get to the person sitting next to you. And what happens inside your ear is that you have a little eardrwhich is like a little drit's a piece of skin that goes over your ear, protects it. And it's often covered in earwax, but let's not go into that. And as the these, uh waveform, air pressure waves hit, your eardrit vibrates at the same rate at these high pressure and low pressure waveforms that come in. So the high pressure pushes it, low pressure and relaxes it, so it starts to vibrate. Behind that eardrthere's a little bone. And that bone that gets pushed back and forward with the same frequency, is what your eardris uh getting uh vibrated. And that little bone then actually leads into this thing called the cochlea, which is a spiral organ. And this spiral organ is oil, uh, fluid filled, and around the outside of it there are little hairs. And the liquid inside it gets vibrated by your eardrpressing on that little bone, and inside it gets vibrated. Now what happens, rather interestingly, in the cochlea, because it's spiral, is depending on the frequency of the noises it hears, different parts of the spiral, of the outer part of the spiral, get vibrated. Okay? So high frequencies come at this is where you can never remember, further down the spiral, and low frequencies happen nearer the beginning of the spiral. Okay? And so what your ear is actually doing is converting this a waveform, pulse modulated form, coming in, and effectively doing a frequency transformation on it and decomposing the signal into different frequencies. We call this fourier transform and bath, and in computer science, we usually want a fast fourier transformer. Fft. But that cochlea, because of its spiral form, is good at decoding the different frequencies that are happening in the noises that we hear. Now, that's actually quite important, because vowels fundamentally have two, or potentially three, uh, high power frequencies in them. Okay? It's a little bit like a, uh, telephone touchdown noise. Actually, it's really the other way around. The telephone touchdown noise is a bit like a human vowel. But basically we've got two resonant frequencies that happen in our mouths when we speak and things like ah. I've got one that's relatively high and one that's relatively low, while e is actually got two that are relatively high. But different parts of your cochlea are being stimulated depending on whether it's an ah or an e sound that you hear. Okay. Now, of course, we've now got microphones and, uh, and speakers or earbuds in between it. But the same thing is happening is that, while i'm speaking, goes for the internet, comes out the internet, into your m or a machine, and then comes out into your ear. And it's vibrating your tucula at the right point so that you hear an ah when i go or hear an e when i go e, or any of the other faults. Now, sometimes there's a relatively common disability, congenital disability, where people are born without fluid in the cochlea. This usually makes them absolutely death. Now, when we say profoundly or absolutely deaf, actually, we don't really mean you can't hear anything, because actually we can feel vibrations through our hands and our head all the time. And so even when you don't have the ability to be able to hear sounds through your ear, you're still conscious of sounds, okay? And you can still feel them in some sense. But if you have no fluid in your cochlea, it doesn't work. And that's a bit of a bummer, because if you can't hear, life is very different. You can still take part in life, and there's lots of things that you can do, and many people do. But around about 30 years ago, it was discovered that actually you can replace the cochlea with an electronic computer. And so what you can have is a chip, as a microphone on it, that will listen to the noises that are coming in like the eardrand. It can convert them into the frequencies, and it can stimulate the auditory nerve, which is the thing that comes out the other side of the cochlea. And that that the human brain then can hear the noises. It can't hear the noises as well as a working calculator, but it can hear the noises well enough to basically continue with pretty much good hearing, if not perfect hearing to begin with. This could only really be done on prevocal children. And because it doesn't give the same stimulus as what the cochlear does, but the brain's quite plastic, and they can do and learn new things. And so they would basically put it on children under the age of about 80 months. And these children have since grown up, and they can hear, as i say, not completely normally, but they can hear well enough to be able to have some hearing loss, but pretty much live a normal life. There doesn't affect their speech, and they can hear most things, and they don't have to wear hearing aids, and they can continue in life. And that's actually a pretty big thing that's happened in my life in speech technology. We've actually allowed people to do it. This technology has improved pretty significantly over the last 30 years, and it's no longer the case that it only needs to be done in prevocal children. And it can be done on children and adults. Basically what they try to do is they try to other interestingly, using neural nets to be able to get a better link to the auditory nerve, and so that they can actually deal with either what the person did before when they had a working cochlear, or if they never had a working calcula enough so that the brain can actually pick up what's going on. If you look on youtube for cochlear implant, you'll see some extremely moving videos about people hearing for the first time, little kids and adults. And it's moving. And it's really quite a success that we can actually replace what's in the cochlea. We can't, you know, grow new cochlear, and we can't put fluid into the cochlea and make it work, but we can bypass it. There are actually similar things that people are looking at to see they can do with eyesight. But from the other point of view, it's actually quite interesting. And one of the major organs within the ear and can actually be replaced with electronics.",
        "transcript-corrected": "So that's what's interesting about a speech generation. So why is it the other end? What happens at the other end, the ear? So we generate these sounds, and what we're actually doing coming out of our mouth is we're changing air pressure. So we're changing air pressure at different frequencies. So when I do something that's higher range, like me, it's going to change the pressure quicker than if it does it that okay? So we're going to get different amounts of pressure. So the pressure is high pressure air and low pressure. Here will be these sound waves that come out of my mouth. Now, what happens to that? Well, actually, imagine that we're in the lecture theater, because I want to explain that to you now. Rather than the intermediate thing about going through a microphone and going across the internet and coming internet and coming out of the speaker or your earbuds, but imagine that we're in the lecture hall. When I'm speaking, what happens is these pressure waves go off and bounce off all the walls and the ceiling and the floor and the people and the blackboard, and they go back and forward. And they, eventually, with all of that going back and forward, get to your ears. You, in particular, not the person next to you. Some other route will get to the person sitting next to you. And what happens inside your ear is that you have a little eardrwhich is like a little dart a piece of skin that goes over your ear, protects it. And it's often covered in earwax, but let's not go into that. And as the these, uh waveform, air pressure waves hit, your audit vibrates at the same rate at these high pressure and low pressure waveforms that come in. So the high pressure pushes it, low pressure and relaxes it, so it starts to vibrate. Behind that eardrthere's a little bone. And that bone that gets pushed back and forward with the same frequency, is what your address uh getting uh vibrated. And that little bone, then actually leads into this thing called the cochlea, which is a spiral organ. And this spiral organ is oil, uh, fluid filled, and around the outside of it there are little hairs. And the liquid inside it gets vibrated by your eardrpressing on that little bone, and inside it gets vibrated. Now what happens, rather interestingly, in the cochlea, because it's spiral, is depending on the frequency of the noises it hears, different parts of the spiral, of the outer part of the spiral, get vibrated. Okay? So high frequencies come at, this is where you can never remember, further down the spiral, and low frequencies happen nearer the beginning of the spiral. Okay? And so what your ear is actually doing is converting this a waveform, pulse modulated form, coming in, and effectively doing a frequency transformation on it and decomposing the signal into different frequencies. We call this Fourier transform and bath, and in computer science, we usually want a fast Fourier transformer. Fft. But that cochlea, because of its spiral form, is good at decoding the different frequencies that are happening in the noises that we hear. Now, that's actually quite important, because vowels fundamentally have two, or potentially three, uh, high power frequencies in them. Okay? It's a little bit like a, uh, telephone touchdown noise. Actually, it's really the other way around. The telephone touchdown noise is a bit like a human vowel. But basically we've got two resonant frequencies that happen in our mouths when we speak and things like ah. I've got one that's relatively high and one that's relatively low, while e is actually getting two that are relatively high. But different parts of your cochlea are being stimulated depending on whether it's an ah or an e sound that you hear. Okay. Now, of course, we've now got microphones and, uh, and speakers or earbuds in between it. But the same thing is happening is that, while I'm speaking, goes for the internet, comes out the internet, into your m or a machine, and then comes out into your ear. And it's vibrating your tequila at the right point so that you hear an ah, when I go or hear an e when I go e, or any of the other faults. Now, sometimes there's a relatively common disability, congenital disability, where people are born without fluid in the cochlea. This usually makes them absolute death. Now, when we say profoundly or absolutely deaf, actually, we don't really mean you can't hear anything, because actually we can feel vibrations through our hands and our head all the time. And so even when you don't have the ability to be able to hear sounds through your ear, you're still conscious of sounds, okay? And you can still feel them in some sense. But if you have no fluid in your cochlea, it doesn't work. And that's a bit of a bummer, because if you can't hear, life is very different. You can still take part in life, and there's lots of things that you can do, and many people do. But around about 30 years ago, it was discovered that actually you can replace the cochlea with an electronic computer. And so what you can have is a chip, as a microphone on it, that will listen to the noises that are coming in like the errand. It can convert them into the frequencies, and it can stimulate the auditory nerve, which is the thing that comes out the other side of the cochlea. And that that the human brain, then can hear the noises. It can't hear the noises as well as a working calculator, but it can hear the noises well enough to basically continue with pretty much good hearing, if not perfect hearing to begin with. This could only really be done on prevocal children. And because it doesn't give the same stimulus as what the cochlear does, but the brain's quite plastic, and they can do and learn new things. And so they would basically put it on children under the age of about 80 months. And these children have since grown up, and they can hear, as I say, not completely normally, but they can hear well enough to be able to have some hearing loss, but pretty much live a normal life. There doesn't affect their speech, and they can hear most things, and they don't have to wear hearing aids, and they can continue in life. And that's actually a pretty big thing that's happened in my life in speech technology. We've actually allowed people to do it. This technology has improved pretty significantly over the last 30 years, and it's no longer the case that it only needs to be done in provincial children. And it can be done on children and adults. Basically what they try to do is they try to other interests, using neural nets to be able to get a better link to the auditory nerve, and so that they can actually deal with either what the person did before when they had a working cochlear, or if they never had a working calcula enough so that the brain can actually pick up what's going on. If you look on YouTube for cochlear implant, you'll see some extremely moving videos about people hearing for the first time, little kids and adults. And it's moving. And it's really quite a success that we can actually replace what's in the cochlea. We can't, you know, grow new cochlear, and we can't put fluid into the cochlea and make it work, but we can bypass it. There are actually similar things that people are looking at to see they can do with eyesight. But from the other point of view, it's actually quite interesting. And one of the major organs within the ear and can actually be replaced with electronics.",
        "brief-summary": "When I'm speaking, I'm generating sound waves that come out of my mouth."
    },
    {
        "start_timestamp": "00:12:16",
        "transcript": "Be replaced with electronics. That's basically says the same thing. So i've explained to you how noises you make by blowing air through your vocal tract and scattering the noises off walls and bounced into your ear, can get back into the brain, but there's nothing about the meaning of these noises. How do we get from grunts and screams and laughs and sighs and yawns to actually getting meaning? About explaining, you know, the meaning of the universe, or where black holes come from, or what the best ice cream is in pittsburgh? How do how do we get from there? Okay? And the answer is, well, evolution, over time, we've managed to make these different noises, and the people at the other end have learned that these noises mean particular things. When you're growing up and learning your first language, probably from your mother, and you're going to hear these noises, actually, you hear them before you're born, and you're going to learn that there's distinctions between these noises, and eventually work out that these things are, you don't know at the time that they're called vowels and consonants, and you learn the distinctions between them and the things that are important for the particular language that you're learning. They're not all the same. Languages are different. They use these noises in different ways. There's still a space of noises that are possible when we're speaking, but we vary them. And although they may standardize in the language, within dialects, within the language, they may differ. And within idiolex. And idiolex means the particular way that somebody speaks. So the way that i speak, i have a scottish accent, but it's been internationalized because when i first went abroad, way back in the 1980s, nobody understood anything that i said at all. So i had to modify to still be scottish, but make it so that when i'm traveling the world, people actually understand me. And realistically, i've now been in the us. Too long. So i actually pick up a number of americanisms in my speech. And i say things like mom instead of mand and uh. I say things like water instead of water that i've learned to be able to do. So i have all these things that i've collected together. And i'll speak differently when i'm talking to you across zoom, rather when i'm talking to you in person. When there's only one or two of us around, or when i'm talking to, say, scottish friends, i'm going to speak in a different way. Or even british friends, i'm going to adapt the way that i speak depending on who i'm speaking to. But given that big space of what everybody does, what are the fundamental units that we actually have of speech? It's basically a huge analog space. And we'd really like to make it into much more discrete units so that we can identify what the space of when something is the same or different. Okay,",
        "transcript-corrected": "Be replaced with electronics. That's basically saying the same thing. So I've explained to you how noises you make by blowing air through your vocal tract and scattering the noises off walls and bounced into your ear, can get back into the brain, but there's nothing about the meaning of these noises. How do we get from grunts and screams and laughs and sighs and yawns to actually getting meaner? About explaining, you know, the meaning of the universe, or where black holes come from, or what the best ice cream is in Pittsburgh? How do how do we get from there? Okay? And the answer is, well, evolution, over time, we've managed to make these different noises, and the people at the other end have learned that these noises mean particular things. When you're growing up and learning your first language, probably from your mother, and you're going to hear these noises, actually, you hear them before you're born, and you're going to learn that there's distinctions between these noises, and eventually work out that these things are, you don't know at the time that they're called vowels and consonants, and you learn the distinctions between them and the things that are important for the particular language that you're learning. They're not all the same. Languages are different. They use these noises in different ways. There's still a space of noises that are possible when we're speaking, but we vary them. And although they may standardize in the language, within dialects, within the language, they may differ. And within idiolex. And idiolex means the particular way that somebody speaks. So the way that I speak, I have a Scottish accent, but it's been internationalized because when I first went abroad, way back in the 1980s, nobody understood anything that I said at all. So I had to modify to still be Scottish, but make it so that when I'm traveling the world, people actually understand me. And realistically, I've now been in the us. Too long. So I actually pick up a number of Americanisms in my speech. And I say things like mom instead of mourned and uh. I say things like water instead of water that I've learned to be able to do. So I have all these things that I've collected together. And I'll speak differently when I'm talking to you across zoom, rather when I'm talking to you in person. When there's only one or two of us around, or when I'm talking to, say, Scottish friends, I'm going to speak in a different way. Or even British friends, I'm going to adapt the way that I speak depending on who I'm speaking to. But given that big space of what everybody does, what are the fundamental units that we actually have about speech? It's basically a huge analog space. And we'd really like to make it into much more discrete units so that we can identify what the space  when something is the same or different. Okay,",
        "brief-summary": "In our series of letters from African-American journalists, film-maker and columnist Steve Kroft looks at the meaning of grunts and screams."
    },
    {
        "start_timestamp": "00:15:08",
        "transcript": "Something is the same or different. Okay? Now we can actually investigate how people move their tongue, teeth, lips when they're actually speaking. And we can do this in a somewhat frightening way, okay? But there is a machine called a electromagnetic articulative graph which is incredibly hard to say, where what we do is we attach metal studs to the front of our tongue, tip, the middle part of our tongue and further down at the back, hopefully not causing you to gag. And we attach them to the teeth, the lips, the nose and the velthe velis the thing at the back of your throat that opens up into your nasal passage. And you've got to learn not to gag when you do that, okay? And what we then do with all these metal, metal studs inside your mouth, we then put you inside our magnetic resonance chamber, and we get you to speak normally, which is quite hard because you've got these wires coming out of your mouth. But we get you to speak normally. And then what we can do is we can look in the magnetic changes that actually happen and track with these metal studs that are happening. And we can work out what happens when you say something like e or ah, or what happens when you say uh, or happen when you say er? Okay? And so we don't have one of these machines at cmu, so you don't get the pleasure to use it. It's not a pleasure, okay? And so what i'm going to do is going to show you somebody in one of these machines. Okay? This is professor current",
        "transcript-corrected": "Something is the same or different. Okay? Now we can actually investigate how people move their tongue, teeth, lips when they're actually speaking. And we can do this in a somewhat frightening way, okay? But there is a machine called a electromagnetic articulate graph which is incredibly hard to say, where what we do is we attach metal studs to the front of our tongue, tip, the middle part of our tongue and further down at the back, hopefully not causing you to gag. And we attach them to the teeth, the lips, the nose and the vet values the thing at the back of your throat that opens up into your nasal passage. And you've got to learn not to gag when you do that, okay? And what we then do with all these metal, metal studs inside your mouth, we then put you in our magnetic resonance chamber, and we get you to speak normally, which is quite hard because you've got these wires coming out of your mouth. But we get you to speak normally. And then what we can do is we can look at the magnetic changes that actually happen and track with these metal studs that are happening. And we can work out what happens when you say something like e or ah, or what happens when you say uh, or happen when you say ER? Okay? And so we don't have one of these machines at cmu, so you don't get the pleasure to use it. It's not a pleasure, okay? And so what I'm going to do is going to show you somebody in one of these machines. Okay? This is professor current",
        "brief-summary": "Professor current:"
    },
    {
        "start_timestamp": "00:16:52",
        "transcript": "Machines. Okay? This is professor current richmond at edinburgh university. And they have a number of machines there. And there you see him in the machine, okay? And you can see that our wires on three parts of his tongue. And you can see a wire that disappears further back. There's actually two wires. One is going to his teeth, and one is going to the back of his throat. Actually, there's another wire and over here, and i think that's actually going to what's called a palatograph, which is a plate that goes on the top of your mouth. And this is allows you to detect, when the person's speaking, whether the tongue hits the top of the mouth or not. There's a, uh, one other marker up on his nose, which is used to be able to align where these things are when we get the information afterwards. And a little bit outside the picture is the magnetic resonance chain chamber. It's like a big space helmet. And, uh, you can also see that there are bolts here, okay? And what we do is we basically try to get the person not to move. And we put the bolts against their head, trying to keep it to work. Now this is pretty frightening. And of course, it's pretty hard to speak normally when you've got all of these things in your mouth. But this is one way that we can do to actually work out, when people are speaking, what's actually happening to the articulators in their mouth. Because the other way of cutting them open is even less pleasant than this. But once you collect this data, you can actually follow the information, and then you can actually build, say, a movie of what's happening when people are actually speaking. So i'm going to show you a movie of this. So what i have to do is switch into another um",
        "transcript-corrected": "Machines. Okay? This is professor current Richmond at Edinburgh university. And they have a number of machines there. And there you see him in the machine, okay? And you can see that our wires on three parts of his tongue. And you can see a wire that disappears further back. There's actually two wires. One is going to his teeth, and one is going to the back of his throat. Actually, there's another wire and over here, and I think that's actually going to what's called a palatograph, which is a plate that goes on the top of your mouth. And this allows you to detect, when the person's speaking, whether the tongue hits the top of the mouth or not. There's a, uh, one other marker up on his nose, which is used to be able to align where these things are when we get the information afterwards. And a little bit outside the picture is the magnetic resonance chain chamber. It's like a big space helmet. And, uh, you can also see that there are bolts here, okay? And what we do is we basically try to get the person not to move. And we put the bolts against their head, trying to keep it working. Now this is pretty frightening. And of course, it's pretty hard to speak normally when you've got all of these things in your mouth. But this is one way that we can do to actually work out, when people are speaking, what's actually happening to the articulators in their mouth. Because the other way of cutting them open is even less pleasant than this. But once you collect this data, you can actually follow the information, and then you can actually build, say, a movie of what's happening when people are actually speaking. So I'm going to show you a movie of this. So what I have to do is switch into another um",
        "brief-summary": "In our series of letters from British journalists, film-maker and columnist John Humphrys looks at some of the more unusual ways that people communicate."
    },
    {
        "start_timestamp": "00:18:36",
        "transcript": "Another share screen. Do you see something on the screen that says, something, something, something. A a will robin wear a yellow lily. That's what it actually says. Does anybody confirm that? You see the video? Thank you. Never very sure about that. What's actually going on? So what we have here is, these are the phonemes that are actually spoken, and we're actually going to get something that moves across it over time. This is the tongue. This is the tongue tip. This is the middle, this is the back, okay? And this is the, uh, uh, upper teeth. And this is the lower teeth. There's a lower lips. And this is the velthe thing that opens to your a nasal passage. So i'm just going to play this, and then i'm going to explain what's going on here. Now, this is obviously not caught in speaking, because this is a female speaker. But she's got all of the the the wires in her mouth. Look at the tongue tip when she says, lily, we'll rob him. We're a yellow lily. We'll rob him. Wear a yellow lily. We'll rob him. Wear a yellow lily. Yes. So i see sean has pointed out that you can also do this with mri. So what you can do is put the person's and head in a magnetic resonance chamber, and the thing that you would get if you were being checked for, uh, brain tumors and other things that look inside your head, and you can actually find out how people move their tongue there. The problem with that is it's much more analog, and it's harder to follow what the tongue is doing. Well, here is a little easier, following the metal studs, but it's the same thing. And people do that. People also do with ultrasound. And they also do with xray. Actually, they used to do with xray, but they don't anymore, because it's not very safe to do it with xray, because you need quite powerful xray and you want to record somebody for a long time. Okay? But this is how you can actually do it. And so you can get that information. And there's a number of people out there who've recorded this information and released it as open source. And we can actually use it to try to do modeling of how can we model somebody's articulatory movements based on the phonemes that they're saying, and while they're actually speaking. And also we can do things like, what happens if their tongue doesn't work because they've maybe lost it through cancer? Can we actually do identification of what's going on, or be able to test how to improve these things? So we've uh done things with articulation. Okay, now let's go back to, uh, the main",
        "transcript-corrected": "Another share screen. Do you see something on the screen that says, something, something, something. A a will rob in wear a yellow lily. That's what it actually says. Does anybody confirm that? You see the video? Thank you. Never very sure about that. What's actually going on? So what we have here is, these are the phonemes that are actually spoken, and we're actually going to get something that moves across it over time. This is the tongue. This is the tongue tip. This is the middle, this is the back, okay? And this is the, uh, uh, upper teeth. And this is the lower teeth. There's a lower lip. And this is the vet thing that opens to your a nasal passage. So I'm just going to play this, and then I'm going to explain what's going on here. Now, this is obviously not caught in speaking, because this is a female speaker. But she's got all of the the the wires in her mouth. Look at the tongue tip when she says, lily, we'll rob him. We're a yellow lily. We'll rob him. Wear a yellow lily. We'll rob him. Wear a yellow lily. Yes. So I see Sean has pointed out that you can also do this with more. So what you can do is put the person's and head in a magnetic resonance chamber, and the thing that you would get if you were being checked for, uh, brain tumors and other things that look inside your head, and you can actually find out how people move their tongue there. The problem with that is it's much more analog, and it's harder to follow what the tongue is doing. Well, here is a little easier, following the metal studs, but it's the same thing. And people do that. People also do with ultrasound. And they also do with X-ray. Actually, they used to do with x-ray, but they don't anymore, because it's not very safe to do it with x-ray, because you need quite powerful X-ray and you want to record somebody for a long time. Okay? But this is how you can actually do it. And so you can get that information. And there's a number of people out there who've recorded this information and released it as open source. And we can actually use it to try to do modeling of how can we model somebody's articulatory movements based on the phonemes that they're saying, and while they're actually speaking. And also we can do things like, what happens if their tongue doesn't work because they've maybe lost it through cancer? Can we actually do the identification of what's going on, or be able to test how to improve these things? So we've uh done things with articulation. Okay, now let's go back to, uh, the main",
        "brief-summary": "In our series of letters from African journalists, filmmaker and columnist Farai Sevenzo looks at some of the ways in which we can learn more about our African ancestors."
    },
    {
        "start_timestamp": "00:21:36",
        "transcript": "Now let's go back to, uh, the main slides. Cordon is still there and switching on the machine. He's done quite a lot of work on this, and especially on the modeling from speech to articulation. So this is still looking at these articulatory movements. Everything is still pretty analog. We've, we've taken it from being all this movement thing to just a few actual points, and modeling those is almost sufficient to be able to recognize speech and to generate speech. Okay, but how do we try to split these into individual units? You've probably heard the term phoneme before. So phonemes are like the individual segments of speech. And the definition of them is deeply disappointing to a computer scientist, but it's actually quite acceptable in the linguistic domain. And it is very, you know, sufficient to be able to describe what phonemes are. And phonemes are whatever. The thing is that if you change, you might change the meaning, like we, well, that's not very good. But let me give you an example. So we have a word like pat. Well, if we change the p to we get bad. So is a phoneme, and so is b now, phonemes are abstract linguistic units. People can realize these in different ways and across different languages. And we'll talk about how that actually happens, even within dialects of uh, english. But, uh, the fundamental idea is that there is these segments that have a beginning and an end time, sometimes it's hard to define what they are, that have some distinction between them, that allow us to be able to split up words, not into letters, because english is one of the worst languages on the planet for having a relationship between the letters and the pronunciation, but the p or the t impact to an m in pam. All of these are examples of phonemes. And this actually works quite well, even though, from a computer science point of view, you probably want a more concrete definition of that, and i'm about to give that. Um,",
        "transcript-corrected": "Now let's go back to, uh, the main slides. Cordon is still there and switching on the machine. He's done quite a lot of work on this, and especially in the modeling of speech  articulate. So this is still looking at these articulatory movements. Everything is still pretty analog. We've, we've taken it from being all this movement thing to just a few actual points, and modeling those is almost sufficient to be able to recognize speech and to generate speech. Okay, but how do we try to split these into individual units? You've probably heard the term phoneme before. So phonemes are like the individual segments of speech. And the definition of them is deeply disappointing to a computer scientist, but it's actually quite acceptable in the linguistic domain. And it is very, you know, sufficient to be able to describe what phonemes are. And phonemes are whatever. The thing is that if you change, you might change the meaning, like us, well, that's not very good. But let me give you an example. So we have a word like a pat. Well, if we change the p to we get worse. So is a phoneme, and so is by now, phonemes are abstract linguistic units. People can realize these in different ways and across different languages. And we'll talk about how that actually happens, even within dialects of uh, English. But, uh, the fundamental idea is that there is these segments that have a beginning and an end time, sometimes it's hard to define what they are, that have some distinction between them, that allow us to be able to split up words, not into letters, because English is one of the worst languages on the planet for having a relationship between the letters and the pronunciation, but the p or the t impact to an m in pain. All of these are examples of phonemes. And this actually works quite well, even though, from a computer science point of view, you probably want a more concrete definition of that, and I'm about to give that. Um,",
        "brief-summary": "We're going to talk a little bit about phonemes."
    },
    {
        "start_timestamp": "00:23:56",
        "transcript": "So what is the space of all possible noises we can make? And phonologists have been looking at this for years, but over the last hundred years, we've come up with the international phonetic alphabet. And it defines everything that we can do with our mouths. Ish, and definitely in the sound part, and actually sometimes in the nonsound back, because there are some sounds, phonemes, that we make that don't make any noise. Okay? All vowels, consonants, with various forms and modifications, including things like tones. It's got all the distinctions, and it's, it prides itself in dealing with all of the languages. Now, what's quite interesting about it, because it's quite structured in the way it does, it actually identifies things that don't exist in any language, which is really interesting. So why are some of these things which you can actually almost generate, but there's no languages that ever use them? Okay? The writing system for ipa uses something that's in unicode. It's sort of latin letters, but with a whole bunch of other additional things in it. Sometimes borrowing letters from other languages, sometimes taking existing languages and turning them backwards and upside down. It takes a little while to learn. Actually, most people don't know it all, but they know the main things. But it can be quite hard to type on computers. Well, i know all of you are saying, well, it's really easy. I can just put in no. But when i say typing on computers, i mean in computer programs. And how can you use it in as variable names in python? Okay, so actually what we often do is we convert it to an ascii representation. And unfortunately, there are multiple ascii representations of ipa. Most people who work in the ipea care about a particular language, and therefore they have their subset of the ipa that they use for that language. The ipa has actually got three major parts, but we're only going to look at two of them, and that's the vowels and the consonants. There are also other things that are in further tables that have modifications on them. I'll mention some of these later. But the vowels, what's interesting about the vowels in in the whole world is that",
        "transcript-corrected": "So what is the space of all possible noises we can make? And phonologists have been looking at this for years, but over the last hundred years, we've come up with the international phonetic alphabet. And it defines everything that we can do with our mouths. Ish, and definitely in the sound part, and actually sometimes with the non sound back, because there are some sounds, phonemes, that we make that don't make any noise. Okay? All vowels, consonants, with various forms and modifications, including things like tones. It's got all the distinctions, and it's, it prides itself in dealing with all of the languages. Now, what's quite interesting about it, because it's quite structured in the way it does, it actually identifies things that don't exist in any language, which is really interesting. So why are some of these things which you can actually almost generate, but there's no languages that ever use them? Okay? The writing system for iPod uses something that's in unicode. It's sort of Latin letters, but with a whole bunch of other additional things in it. Sometimes borrowing letters from other languages, sometimes taking existing languages and turning them backwards and upside down. It takes a little while to learn. Actually, most people don't know it all, but they know the main things. But it can be quite hard to type on computers. Well, I know all of you are saying, well, it's really easy. I can just put in no. But when I say typing on computers, I mean  computer programs. And how can you use it in as variable names in python? Okay, so actually what we often do is we convert it to an ASCII representation. And unfortunately, there are multiple ASCII representations of IPA. Most people who work in the pea care about a particular language, and therefore they have their subset of the IPA that they use for that language. The IPA has actually got three major parts, but we're only going to look at two of them, and that's the vowels and the consonants. There are also other things that are in further tables that have modifications on them. I'll mention some of these later. But the vowels, what's interesting about the vowels in the whole world is that",
        "brief-summary": "We're going to look at the space of all noises."
    },
    {
        "start_timestamp": "00:26:10",
        "transcript": "The vowels in in the whole world, is that basically, the vowels, fundamentally okay, have got two frequencies in them, two formants, is the technical term for it. And there's somewhere between 700 and, sorry, 300 and 700 hertz and, uh, 300 and 2 000 hertz. And so these two tones that would appear differently in a fft. But we can take this chart, okay? And what we can do is point to places in that chart, and you could actually generate a vowel. And there are things online that would allow you to do it. And what languages do, humans and languages, the languages themselves don't really do that is partition the space in what we consider to be different vowels. And different languages will have different boundaries. In fact, normally you wouldn't generate anything near the boundaries because that would be too confusing. So what you would actually do is generate, sort of in the center of different partitions of that space. Now, some languages, including english, have got a sort of neutral vowel, which is called a schwa, which is basically, i don't care which of these vowels it is, it's somewhere in the middle, and it's pronounced uh okay. It's the unstressed version of the indefinite article in english. And contrasted with the it's in the word about okay. But also when we're speaking in unstressed species places, we often use it, and we often use it instead of the real vowel, which often makes it hard for us to spell properly, because we don't know whether the word independent is independent or independent. And at least i don't, okay, because we actually reduce it to a schwa when we're speaking. But this space is there, and it's different for different languages. And it's different even for different speakers in the same language. And there's often different different dialects of the language. And that's the vowels. Let's move on to the consonants. So the consonants are basically often things that are called obstruents. And they're often things which stop the airflow or affect the airflow. So they're not usually things that let all the air out, like vowels do. And they're basically classed in two dimensions. One is the place of articulation. And the place of articulation is sort of the important part. And what we do is we talk about the lips at the front, we talk about the teeth, we talk about behind the teeth, we talk about the top of the palate. We talk about slightly further back. And then we can get further back in the throat and even down the throat. Okay? So going left to right on this chart, we're moving from the front of the mouth down to the back of the mouth. And the first one that's listed here, okay, is stops, or plosive stops, stop the air. Okay? And we often have voiced and unvoiced versions. So the one that's on the lips at the front is going to be, okay, actually, it's going to be rather than because i just voiced it to make it clear. And the other one is, okay. So you got an [music]. Okay. And that's to do with the mouth. And you can move back to the teeth. You can have tur and you can have d you can move back. I'm going to skip the next two, and we move further back on to the velar. This is back at the top of the mouth. And this is, and in english, that's about all we have. Actually, because i'm a scot speaker, i've got another one that's further back and and that's the one that's in law, okay, the ch that isn't normally spoken outside scotland. It's sort of germanic, okay? So is actually that one that's further back. But actually, in scots english, we've only got the unvoiced one, and we do not have the voiced one. But if we go across the north sea to the netherlands, actually we go to holland, because it's only in the north that has it. The south doesn't, and they have a voiced version. So a. and sean is, uh, yeah, i'll get to that one. Sean, that is a. so if anybody's ever been to amsterdam airport, you'll probably know that it's called skipple airport, schipol, okay? And the first part of it means ship, but actually the locals don't say skipple. They actually say circle, okay? So they've got this voiced version of ah, okay, which, which is a, okay. And there's a town near there called chronican, and they use it around that. In fact, it's actually a way to identify whether some dutch person is a local or not, about how they say ripple when they're actually speaking. So i do that and then they say to me, you're a phonologist who comes from scotland, aren't you something? No, so it doesn't really work. Sean just pointed out in the chat, there's actually another one that's even further back. It's called the glottal stop. And that's one of these interesting ones that's actually nothing, makes no noise at all. But what you do is you stop the speech at the back of your throat. And we don't normally do this in english. It's not normally not thought as a phoneme, but we actually use it between vowels when it's confusable. So if you think about, uh, the chief executive officer of a company, we usually refer to them as a ceo. And when we say e o, we actually put a glottal stop between it. We don't say co we say c e o. and that's between the e of c to e and the e of e to o. okay? We also say it in things like uh o, where we actually put that explicit stop. And some languages actually do that explicitly, okay? A german actually does it on words that begin with a vowel. And most germans will do it in english. And you won't notice it because it's not wrong, and it makes it actually sound a little bit more correct speech. And of course, klingon has it as well, which is a important language to me. There's a whole space here. And not all of the consonants are here, but there are just some examples. And if you speak to a real phonologist like david mortensen, he can do them all, which is a little frightening, and probably a misspent youth in front of the mirror trying to do them all, but it's quite impressive. I can do some, but not all. Okay,",
        "transcript-corrected": "The vowels in the whole world, is that basically, the vowels, fundamentally okay, have got two frequencies in them, two formants, is the technical term for it. And there's somewhere between 700 and, sorry, 300 and 700 hertz and, uh, 300 and 2 000 hertz. And so these two tones that would appear differently in a fight. But we can take this chart, okay? And what we can do is point to places in that chart, and you could actually generate a vowel. And there are things online that would allow you to do it. And what languages do, humans and languages, the languages themselves don't really do that is partition the space in what we consider to be different vowels. And different languages will have different boundaries. In fact, normally you wouldn't generate anything near the boundaries because that would be too confusing. So what you would actually do is generate, sort of in the center of different partitions of that space. Now, some languages, including English, have got a sort of neutral vowel, which is called a schwa, which is basically, I don't care which of these vowels it is, it's somewhere in the middle, and it's pronounced uh okay. It's the unstressed version of the indefinite article in English. And contrasted with the it's in the word about okay. But also when we're speaking in unstressed specific places, we often use it, and we often use it instead of the real vowel, which often makes it hard for us to spell properly, because we don't know whether the word independent is independent or independent. And at least I don't, okay, because we actually reduce it to a schwa when we're speaking. But this space is there, and it's different for different languages. And it's different, even for different speakers in the same language. And there's often different different dialects of the language. And that's the vowels. Let's move on to the consonants. So the consonants are basically often things that are called astronauts. And they're often things which stop the airflow or affect the airflow. So they're not usually things that let all the air out, like vowels do. And they're basically classed in two dimensions. One is the place of articulation. And the place of articulation is sort of the important part. And what we do is we talk about the lips at the front, we talk about the teeth, we talk about behind the teeth, we talk about the top of the palate. We talk about slightly further back. And then we can get further back in the throat and even down the throat. Okay? So going left to right on this chart, we're moving from the front of the mouth down to the back of the mouth. And the first one that's listed here, okay, is stopped, or plosive stops, stop the air. Okay? And we often have voiced and unvoiced versions. So the one that's on the lips at the front is going to be, okay, actually, it's going to be rather than because I just voiced it to make it clear. And the other one is, okay. So you got a [music]. Okay. And that's to do with the mouth. And you can move back to the teeth. You can have tour and you can have d, you can move back. I'm going to skip the next two, and we move further back onto the velar. This is back at the top of the mouth. And this is, and in English, that's about all we have. Actually, because I'm a scout speaker, I've got another one that's further back and that's the one that's in the law, okay, the chai that isn't normally spoken outside Scotland. It's sort of Germanic, okay? So is actually that one that's further back. But actually, in Scots English, we've only got the unvoiced one, and we do not have the voiced one. But if we go across the north sea to the Netherlands, actually we go to Holland, because it's only in the north that has it. The south doesn't, and they have a voiced version. So a. and Sean is, uh, yeah, I'll get to that one. Sean, that is a. so if anybody's ever been to Amsterdam airport, you'll probably know that it's called skipple airport, Schipol, okay? And the first part of it means the ship, but actually the locals don't say skipped. They actually say circle, okay? So they've got this voiced version of ah, okay, which, which is a, okay. And there's a town near there called chronic an, and they use it around that. In fact, it's actually a way to identify whether some Dutch person is a local or not, about how they say ripple when they're actually speaking. So I do that and then they say to me, you're a phonologist who comes from Scotland, aren't you something? No, so it doesn't really work. Sean just pointed out in the chat, there's actually another one that's even further back. It's called the glottal stop. And that's one of these interesting ones that's actually nothing, makes no noise at all. But what you do is you stop the speech on the back of your throat. And we don't normally do this in English. It's not normally not thought as a phoneme, but we actually use it between vowels when it's confusable. So if you think about, uh, the chief executive officer of a company, we usually refer to them as a CEO. And when we say e o, we actually put a glottal stop between it. We don't say do we say ceo. And that's between the e of c to me and the e  me too. Okay? We also say it in things like, uh oh, where we actually put that explicit stop. And some languages actually do that explicitly, okay? A German actually does it in words that begin with a vowel. And most Germans will do it in English. And you won't notice it because it's not wrong, and it makes it actually sound a little bit more correct speech. And of course, Klingon has it as well, which is an important language to me. There's a whole space here. And not all of the consonants are here, but there are just some examples. And if you speak to a real phonologist like David Mortensen, he can do them all, which is a little frightening, and probably a misspent youth in front of the mirror trying to do them all, but it's quite impressive. I can do some, but not all. Okay,",
        "brief-summary": "Let's take a look at the vowels and the consonants."
    },
    {
        "start_timestamp": "00:32:56",
        "transcript": "Okay, as i say, the ip is great. It actually covers everything. But when you deal with a particular language, what often happens is you only want the phonemes for that language. And in most systems, speech systems that we do, people end up with an ascii representation of them. There's a thing called x sampa that lots of people use, but historically, in the us, people use this set that's often called the darpa bet because darpa speech recognition in the 70s and 80s used this. And here are all the vowels that are in american english, not my english, okay? And they don't quite work for me. I mean, definitely, the vowel that's in washington is rounded for me, but that's not true for the american english. But i'd like you to look at the two last ones, which, unfortunately, the one that's next to the foolish person at the end, rather than the person who's not empty that we have two vowels there. Okay. Now, in my dialect of english, which is technically lowland southeastern scottish, okay, we make no distinctions between that vowel. So f u l l and f o o l are pronounced exactly the same. In my dialect, they're both pronounced full. And it's at times like this, when i'm giving this lecture, i'm technically a full professor in carnegie mellon university, and i'm now desperately worried about ever seeing it written down, rather than being spoken to me. And so maybe i misinterpreted my full, my head of department when they told me that i was now a full professor, and i got the wrong one. And can i ask somebody in the audience to read full and fool? Okay. I'd like you to have an american accent, which almost certainly means, did you go to middle school in north america? Do we have anybody who did that? Yeah, what were the spellings again? I'm sorry. Okay, sean, so the two words at the bottom, f u l l and f o l uh, full, full and full. And they're the same for me too. I think the same for you. Are you from pittsburgh? Yeah. Oh, okay. So here's my next little story. Pittsburgh accent, okay, actually conflates them as well. And it's pretty much accepted that the reason that the pittsburgh ease accent conflates them is because the first english speakers who came here, it was french speaking. It was iroquois speaking. Before that, it was mingle speaking. Even before that, the first english speakers that came to pittsburgh were scottish. They were scottish miners. And so they've influenced the number of things in the language, even 250 years later. So i'm going to ask somebody who isn't from pittsburgh, and i think that's going to be harleen, actually. And, uh, yeah, for me it's full and full. Yeah. So you have full and fool. I can't do it properly. Thanks. Hardly. And it sort of doesn't matter in life if i go through life and i don't really confuse these words, okay? Remember that swimming pool and push and pull, i've got the same form. So occasionally i'll get confused about something, but in general that's okay. But don't worry, i'm going to show that the americans have got things that the rest of us probably have that the americans do not. Okay? So",
        "transcript-corrected": "Okay, as I say, the IP is great. It actually covers everything. But when you deal with a particular language, what often happens is you only want the phonemes for that language. And in most systems, speech systems that we do, people end up with an ASCII representation of them. There's a thing called x shampoo that lots of people use, but historically, in the U.S., people use this site that's often called the DARPA bet because DARPA speech recognition in the 70s and 80s used this. And here are all the vowels that are in American English, not my English, okay? And they don't quite work for me. I mean, definitely, the vowel that's in Washington is rounded for me, but that's not true for the American English. But I'd like you to look at the two last ones, which, unfortunately, the one that's next to the foolish person at the end, rather than the person who's not empty that we have two vowels there. Okay. Now, in my dialect of English, which is technically lowland southeastern Scottish, okay, we make no distinctions between that vowel. So f u l l and f o o l are pronounced exactly the same. In my dialect, they're both pronounced fully. And it's at times like this, when I'm giving this lecture, I'm technically a full professor at Carnegie Mellon university, and I'm now desperately worried about ever seeing it written down, rather than being spoken to me. And so maybe I misinterpreted my full, my head of department when they told me that I was now a full professor, and I got the wrong one. And can I ask somebody in the audience to read full and fool? Okay. I'd like you to have an American accent, which almost certainly means, did you go to middle school in north America? Do we have anybody who did that? Yeah, what were the spellings again? I'm sorry. Okay, Sean, so the two words at the bottom, f u l l and f o l uh, full, full and full. And they're the same for me too. I think the same for you. Are you from Pittsburgh? Yeah. Oh, okay. So here's my next little story. Pittsburgh accent, okay, actually conflates them as well. And it's pretty much accepted that the reason that the Pittsburgh ease accent conflates them is because the first English speakers who came here, it was French speaking. It was Iroquois speaker. Before that, it was mingled speaking. Even before that, the first English speakers that came to Pittsburgh were Scottish. They were Scottish miners. And so they've influenced the number of things in the language, even 250 years later. So I'm going to ask somebody who isn't from Pittsburgh, and I think that's going to be Harleen, actually. And, uh, yeah, for me, it's full and full. Yeah. So you have full and fool. I can't do it properly. Thanks. Hardly. And it sort of doesn't matter in life if I go through life and I don't really confuse these words, okay? Remember that swimming pool and push and pull, I've got the same form. So occasionally I'll get confused about something, but in general that's okay. But don't worry, I'm going to show that the Americans have got things that the rest of us probably have that the Americans do not. Okay? So",
        "brief-summary": "In our series of letters from African-American journalists, filmmaker and columnist Sean Hannity explains why he has an American accent."
    },
    {
        "start_timestamp": "00:36:30",
        "transcript": "Have that the americans do not. Okay, so i've already talked about stops, so stopping, it fricatives, or things like and [music]. Often the names for phonological forms contain examples of themselves, which is very nice. So stops have got a tip and a pip, which are both examples of stops. Fricatives have got a f in them, which is a fricative. Nasals, i've got a nasal in them. Okay. And glides have got a lot in them. Glides, sometimes called semivalves, are things like nml are, yeah. And what? Because it's sort of, they're a bit like vowels. And in fact, in some languages, they even our vowels. Notice this voicing distinction, because it's quite important. Not everybody does it. Not all languages do it. Not all languages care about it in all cases. And you can typically speak a language without getting it right, and it's fully understandable. And often dialects do this. And also remember, in whispering, in truth, whispering, there's no voicing going on. That's actually what you're doing, is you're stopping your larynx from vibrating.",
        "transcript-corrected": "Have that the Americans do not. Okay, so I've already talked about stops, so stopping, it fricatives, or things like and [music]. Often the names for phonological forms contain examples  themselves, which is very nice. So stop have got a tip and a pipe, which are both examples of stops. Fricatives have got a fin them, which is a fricative. Nasals, I've got a nasal in them. Okay. And glides have got a lot of them. Glides, sometimes called semivalves, are things like normal are, yeah. And what? Because it's sort of, they're a bit like vowels. And in fact, in some languages, they even our vowels. Notice this voicing distinction, because it's quite important. Not everybody does it. Not all languages do it. Not all languages care about it in all cases. And you can typically speak a language without getting it right, and it's fully understandable. And often dialects do this. And also remember, in whispering, in truth, whispering, there's no voicing going on. That's actually what you're doing, is you're stopping your larynx from vibrating.",
        "brief-summary": "In our series of letters from African journalists, film-maker and columnist Farai Sevenzo looks at the difference between stops and fricatives."
    },
    {
        "start_timestamp": "00:37:42",
        "transcript": "Larynx from vibrating. Okay, how many phonemes there are there in the language? Well, it sort of depends on how much distinction you do. Us english has about 43. uk english has about 44. us uk english, which is not what i speak uk english here. I mean southern english and london. Japanese only has 25. hindi has 81. india's a lot, okay? But you know, if you ask a phonologist, with an expert about the language, how many phonemes does a language have, they're gonna tell you lots of things. And at some point you just have to go and make a decision, that's enough, okay? And from the computational point of view, the answer really you want is, how many phonemes should i care about in order to be able to build a system that's sufficient for what i want to do, speech recognition, speech synthesis, without making errors, or without confusing or biasing against particular speakers of the language, being them native or nonnative.",
        "transcript-corrected": "Larynx from vibrating. Okay, how many phonemes there are there in the language? Well, it sort of depends on how much distinction you do. Us English has about 43. UK English has about 44. Us UK English, which is not what I speak UK English here. I mean southern English and London. Japanese only has 25. Hindi has 81. India's a lot, okay? But you know, if you ask a phonologist, with an expert about the language, how many phonemes does a language have, they're gonna tell you lots of things. And at some point you just have to go and make a decision, that's enough, okay? And from the computational point of view, the answer really you want is, how many phonemes should I care about in order to be able to build a system that's sufficient for what I want to do, speech recognition, speech synthesis, without making errors, or without confusing or biasing against particular speakers of the language, being them native or nonnative.",
        "brief-summary": "In our series of letters from African journalists, film-maker and columnist Ahmed Rashid looks at some of the most frequently asked questions about the continent."
    },
    {
        "start_timestamp": "00:38:42",
        "transcript": "Nonnative. Not all variation is phonetic, okay? Some of these things are just different ways of saying the same thing. They don't give you a different word. They're just a different way of doing it. So in scottish english, prevocalic before a vowel, the r sound is thrilled. See, trill is another example that's got the thing that it is, okay, the rolled r that's in thrill. Okay, actually, in scottish we don't do that. We will, we'll do that when we're drunk and trying to convince people that we're not english. And but what we'll do is we'll actually just do a very short, one tap of the tongue on the top of our mouth. So when we're saying things like iran, okay, very hard for me to do that. Spanish has it, okay, but us. English does not, okay? And us. English has got actually a very distinctive way of pronouncing r that really is quite different from almost all the other languages, all the other dialects of english and many other languages. It's got this er sound, which is really quite interesting. Now, british english, by british english, i mean all these foreigners in london, they actually have got a really different r as well. They've got a prevocalic r, okay, in words like ran. But the post for calico in a word like car, actually is silent. Well, it isn't completely silent, it affects the vowel before, so they don't say car, they say car. Okay, so it's actually, this is what's called a nonrhotic accent. Now, that happens in new york and in boston. And both of these accents do it partly because they're very old accents in in the us. And they're some of the oldest accents. And they're sort of copying what happened in southern england. And in the same way that fool and fool are the same in pittsburgh, that are copying scots that came here 250 years ago, while the new york and boston people are copying things and english speakers from 400, uh years ago. Now, sometimes these distinctions are give you a different word, and sometimes they don't. Okay, possibly the place where frodo goes in the lord of the rings to get rid of the ring. Okay? If you listen to everybody in the lord of the rings and in the movies and there's actually jrr token actually gives instructions on the pronunciation. Mordor actually has got rolled ours in it, okay? And he was doing that very explicitly. This is the thing issue from the standard british english, southern and english pronunciation, rather than mordor. And actually, they get pronounced, okay. And here's another one that's different between us, english and and british english. In fact, everybody else is english. And there's this thing called the flat. It's not phonetic in american english yet, but 50 years from now, it probably will be, okay. And that's the word water, okay? In proper english it's pronounced with the t in it, and that would be water. But that's not how americans say it. So for all of you nonnatives who came to the us, you're probably already aware that you're not supposed to say water. You're supposed to say water, okay? This is written in the darker bed is dx. And it's sort of required. If you don't do it, you can confuse people in american english, but it's not technically required yet. If you take an american and you put them up in front of a stage, in front of 300 people, and you get them into careful articulation mode, they'll say water. But if they're, if they're in the restaurant and they're asking for the glass of water, they're just gonna see water. Okay? And you should probably do that too, even if you don't. Okay?",
        "transcript-corrected": "Nonnative. Not all variations are phonetic, okay? Some of these things are just different ways of saying the same thing. They don't give you a different word. They're just a different way of doing it. So in Scottish, English, prevocalic before a vowel, the r sound is thrilled. See, trill is another example that's got the thing that it is, okay, the rolled r that's in thrill. Okay, actually, in Scottish we don't do that. We will, we'll do that when we're drunk and trying to convince people that we're not English. And but what we'll do is we'll actually just do a very short, one tap of the tongue on the top of our mouth. So when we're saying things like Iran, okay, very hard for me doing that. Spanish has it, okay, but we. English does not, okay? And us. English has got actually a very distinctive way of pronouncing r that really is quite different from almost all the other languages, all the other dialects of English and many other languages. It's got this are sound, which is really quite interesting. Now, British English, by British English, I mean all these foreigners in London, they actually have got a really different r as well. They've got a prevocalic r, okay, in words like running. But the post for calico in a word like the car, actually is silent. Well, it isn't completely silent, it affects the vowel before, so they don't say car, they say car. Okay, so it's actually, this is what's called a neurotic accent. Now, that happens to new York and in Boston. And both of these accents do it partly because they're very old accents in in the us. And they're some of the oldest accents. And they're sort of copying what happened in southern England. And in the same way that fool and fool are the same in Pittsburgh, that are copying Scots that came here 250 years ago, while the new York and Boston people are copying things and English speakers from 400, uh years ago. Now, sometimes these distinctions are giving you a different word, and sometimes they don't. Okay, possibly the place where Frodo goes in the lord of the rings to get rid of the ring. Okay? If you listen to everybody in the lord of the rings and in the movies and there's actually jrr token actually gives instructions on the pronunciation. Mordor actually has got rolled ours in it, okay? And he was doing that very explicitly. This is the thing issue of the standard British English, southern and English pronunciation, rather than murder. And actually, they get pronounced, okay. And here's another one that's different between us, English and British English. In fact, everybody else is English. And there's this thing called the flat. It's not phonetically in American English yet, but 50 years from now, it probably will be, okay. And that's the word water, okay? In proper English it's pronounced with the t in it, and that would be water. But that's not how Americans say it. So for all of you nonnatives who came to the us, you're probably already aware that you're not supposed to say water. You're supposed to say water, okay? This is written in the dark bead is dx. And it's sort of required. If you don't do it, you can confuse people in American English, but it's not technically required yet. If you take an American and you put them up in front of a stage, in front of 300 people, and you get them into a careful articulation mode, they'll say water. But if they're, if they're in the restaurant and they're asking for the glass of water, they're just gonna see water. Okay? And you should probably do that too, even if you don't. Okay?",
        "brief-summary": "So let's take a look at some of the different accents."
    },
    {
        "start_timestamp": "00:42:46",
        "transcript": "Okay, dialect and idiolect. So dialect is not well defined, whether that's a language or not. Idiolex is really what a particular person does in a particular context. You change the way you speak depending on whether you're talking to lots of people, talking to your friends a there could be mat links between different languages, different words that could be the same or different. I already told you about push and pull. I'm going to give you some more examples. There's also higher up the line where there's word choice of y'all, which used to be southern american, and it probably isn't anymore. It's perfectly acceptable through all of the us. Even though everybody doesn't use it, but people don't notice it as being marked. And it's the plural you. Traditionally, you is plural, and v and thou are the singular forms, but they've gone apart from a few dialects of english. But we also have things like politeness levels, where we choose things. And even then, we choose these things in in english as well. But we're talking about phonetics here, so there's lots of differences that are there aspirated",
        "transcript-corrected": "Okay, dialect and idiolect. So dialect is not well defined, whether that's a language or not. Idiolex is really what a particular person does in a particular context. You change the way you speak depending on whether you're talking to lots of people, talking to your friends a there could be mat links between different languages, different words that could be the same or different. I already told you  push and pull. I'm going to give you some more examples. There's also higher up the line where there's word choice of y'all, which used to be southern American, and it probably isn't anymore. It's perfectly acceptable through all of the us. Even though everybody doesn't use it, but people don't notice it as being marked. And it's the plural you. Traditionally, you are plural, and v and thou are the singular forms, but they've gone apart from a few dialects of English. But we also have things like politeness levels, where we choose things. And even then, we choose these things in in English as well. But we're talking about phonetics here, so there's lots of differences that are there aspirated",
        "brief-summary": "We're going to talk about dialect and idiolect."
    },
    {
        "start_timestamp": "00:43:50",
        "transcript": "Differences that are there aspirated stops, okay, which we generate in english all the time, but they're not phonetically different. And i'm going to show how you english speakers, actually, even the nonnatives amongst you, will probably do this, though the indians might not, because you're much more conscious about this. So in the northern indic languages, marathi, gujarati, hindi, there's a distinction between two. Actually, i can do this better with the, so between the and. Okay. And these sounds mean something different. So i'm going to look and go to ask backshot, uh, to give us an example. Do you one? Do you know what i'm talking about? Basically, with an h or without an h? Yeah, yeah. Do it again. Well, there is the anther, i guess, yeah. And doe and her. So there are four different things. So it's actually got four. You've also got a retroflex thing that happens when you move the tongue back and forward. So we don't care in english about this, but all of the northern and seminorthern, the telugu's speakers do this. The tamils don't have this so many. And malayalam speakers don't have this. But let me actually show you something about this. Aspirated, which is one of the distinctions that happen, basically means blowing air out, okay? And we do this in english. So if you put your hand in front of your mouth and say the word pot, okay, do that now. Okay, part the pa. you can feel the breath on your hand. Okay. Now i want you to do the same thing, but say the word spot. And what you'll notice is there's no air for the p, okay? Because in pot it's aspirated, and in spot it's not aspirated. And we just do this, and we don't even think about it. While all of the indians are going, well, duh, actually, or, depending on what way, how they actually think about it, because they've learned to explicitly do that. While speakers of english just do that. We already talked about r, and it's all of its variations. And we're probably all aware that japanese speakers don't make distinctions between l and r, which is actually not technically true. What they have is a continubetween l and r. and you're probably going, if you're not a japanese speaker, and wait, what? There is not a continuthese are very, very different. And the answer is no, they're a continuin fact, even in english, there's a number of cases where r's become l's. Okay? One of the casual contractions of the name harry or harold is hull with an l. and that's because arsenals are sort of the same in fast speech. Okay? And so people do that. Now we're going to move on to the next one, which is us english dialects. And these four words, all beginning with m, i'm going to be careful about what before i say them. So we have a girl's name, maybe slightly archaic girl's name. We have something to do with christmas, and we have something to do with weddings. Okay. And again, i'm going to go for one of our stan apologies. I keep picking the people who i actually know have got the right accent, but those that i know, so i'm gonna have to go to harleen again to, uh, read out these three words that are there, starting with them, mary, mary and mary. They're the same. For me, they're the same. There are a few dialects of american english, especially the further north you go, so michigan, uh, wisconsin, where you actually get into something that's more canadian, but you're not allowed to say that there's two. And some of you might have two. And in fact, the people in uh, philadelphia accent, i've got a fourth one that's the same. So in squirrel hill, we have a major, uh, thoroughfare where giant eagle is, that's called murray avenue. But for standard philadelphia accent, murray also falls into the same class as these. Okay. Now, what's interesting about this, in my dialect, english, all of the dialects in english, they've got three different vowels, mary, mary and mary. We never get confused about them. They're completely different. And this breaks some pun jokes in american english. But as punjokes are not really funny, i don't really think i'm losing out on anything. And also, it gives confusion sometimes. And i miss people's names when i hear them and i don't get it right, okay? Because i hear one and it's not, it's something else. Although i've also noticed, the longer i've lived here, i sometimes use the american vowel for new names that i've learned here, okay, or place names. And so i sometimes do that. So john, kerry, who stood as one of the candidates for presidency 10, 15 years ago. I think his name is kerry, rather than kerry, is what i would actually say, considering it's actually a scotsirish one. So as i said, full and full, pool and pool is the same for me. But i have a distinction between for and f o u r, and i have a different vowel there. So i have four and four, and have a different. When i reduce those in fast speech, they become the same, but i have a different vowel for them. And that happens in a number of examples. Okay, now, vowel length,",
        "transcript-corrected": "Differences that are there aspirated stops, okay, which we generate in English all the time, but they're not phonetically different. And I'm going to show how you English speakers, actually, even the negatives amongst you, will probably do this, though the Indians might not, because you're much more conscious about this. So in the northern Indic languages, Marathi, Gujarati, Hindi, there's a distinction between two. Actually, I can do this better with the, so between the and. Okay. And these sounds mean something different. So I'm going to look and go to ask buckshot, uh, to give us an example. Do you one? Do you know what I'm talking about? Basically, with an h or without a h? Yeah, yeah. Do it again. Well, there is the anther, I guess, yeah. And doe and her. So there are four different things. So it's actually got four. You've also got a retroflex thing that happens when you move the tongue back and forward. So we don't care in English about this, but all of the northern and seminorthern, the Telugus speakers do this. The Tamils don't have this so much. And Malayalam speakers don't have this. But let me actually show you something about this. Aspirated, which is one of the distinctions that happen, basically means blowing air out, okay? And we do this in English. So if you put your hand in front of your mouth and say the word pot, okay, do that now. Okay, part the pa. You can feel the breath on your hand. Okay. Now I want you to do the same thing, but say the word spot. And what you'll notice is there's no air for the p, okay? Because in the pot, it's aspirated, and in the spot it's not aspirated. And we just do this, and we don't even think about it. While all of the Indians are going, well, duh, actually, or, depending on what way, how they actually think about it, because they've learned to explicitly do that. While speakers of English just do that. We already talked about are, and it's all of its variations. And we're probably all aware that Japanese speakers don't make distinctions between l and r, which is actually not technically true. What they have is a continubetween l and r. And you're probably going, if you're not a Japanese speaker, and wait, what? There is not a continuous are very, very different. And the answer is no, they're a continuing fact, even in English, there's a number of cases where r's become l's. Okay? One of the casual contractions of the name harry or Harold is hull with an l. and that's because arsenals are sort of the same  fast speech. Okay? And so people do that. Now we're going to move on to the next one, which is us English dialects. And these four words, all beginning with me, I'm going to be careful about what before I tell them. So we have a girl's name, maybe slightly archaic girl's name. We have something to do with Christmas, and we have something to do with weddings. Okay. And again, I'm going to go for one of our stun apologies. I keep picking the people who I actually know have got the right accent, but those that I know, so I'm gonna have to go to Harleen again to, uh, read out these three words that are there, starting with them, Mary, Mary and Mary. They're the same. For me, they're the same. There are a few dialects of American English, especially the further north you go, so Michigan, uh, Wisconsin, where you actually get into something that's more Canadian, but you're not allowed to say that there's two. And some of you might have two. And in fact, the people in uh, Philadelphia accent, I've got a fourth one that's the same. So in squirrel hill, we have a major, uh, thoroughfare where giant eagle is, that's called Murray avenue. But for standard Philadelphia accent, Murray also falls into the same class as these. Okay. Now, what's interesting about this, in my dialect, English, all of the dialects in English, they've got three different vowels, Mary, Mary and Mary. We never get confused about them. They're completely different. And this breaks some pun jokes in American English. But  pancakes are not really funny, I don't really think I'm losing out on anything. And also, it gives confusion sometimes. And I miss people's names when I hear them and I don't get it right, okay? Because I hear one and it's not, it's something else. Although I've also noticed, the longer I've lived here, I sometimes use the American vowel for new names that I've learned here, okay, or place names. And so I sometimes do that. So John, Kerry, who stood as one of the candidates for presidency 10, 15 years ago. I think his name is Kerry, rather than Kerry, is what I would actually say, considering it's actually a Scots Irish one. So as I said, full and full, pool and pool are the same for me. But I have a distinction between four and f our, and I have a different vowel there. So I have four and four, and have a different. When I reduce those in fast speech, they become the same, but I have a different vowel for them. And that happens in a number of examples. Okay, now, vowel length,",
        "brief-summary": "In our series of letters from African journalists, film-maker and columnist Farai Sevenzo looks at some of the differences between English and Indian languages."
    },
    {
        "start_timestamp": "00:49:34",
        "transcript": "Now, vowel length doesn't really make much difference in english, but it does in some other languages, maybe bit. And beat our a vowel length difference. Some people argue that. But in japanese, vowel length is very important. So you have the word shujin, which means husband, and you have the word shujin, which means prisoner. A story that always allows me to remember this, i lived in japan for years, and my japanese is reasonable, it's not completely fluent. When you're speaking to people in japanese, you often refer to people by relationships rather than by names. So when i would meet my neighbor in the morning and say good morning and say, hello, i am. My neighbor worked at the same company as me, so i knew her relatively well, and and so did her husband, i would sometimes say to her, how's your husband? And so i would say to her something like the genki disco. And i'd get the vowel length wrong. So instead of saying, how's your husband, i would say, how's your prisoner? I am. Now the embarrassing thing about this is, some time later, i was in a discussion where this particular person was giving uh an example of how violent is important in japanese and how foreigners often get it wrong. And she used me as the example, and i was in the audience without actually identifying me. Well, she did save some guy with a long beard, but she wasn't going to identify it. And it's important, and you learn after a while. I'm relatively good about it and can recognize it without really thinking anymore. But it is interesting that you can't detect it to begin with. We don't just do these linear things with segments. We also can do things above the segmental form. Tones are an excellent example of this. All languages use the f0, the fundamental frequency, to do things like, well, we sing with it, but we also do focus. We also do things like whether it's a question or not, although not as much as what you think. We can use it for doing things like whether we're sure or unsure, whether finished, etc. And i'll show you some examples of that in a minute. But some languages, actually quite a lot of languages, use the tone to be able to distinguish between different words. So let's take mandarin chinese, because half of us speak mind they're in chinese, we think. And let's see what uh, we can do so if we take the phoneme and the vowel. Ah, so, ma, there are actually four different tones in mandarin chinese, and they just are varied on how the tone. So rather than me do it, i'm going to ask amanda and chinese speaker to give me the word ma with the four different tones. Who wants to do it? Okay, calvin, go ahead. Ma, ma, okay. Now, for english speakers or nontonal speakers, you probably just thought, well, they're different, but you really mean something different. So they mean, i not necessarily in this order, horse, they mean mother. Actually, it's the same word, ma, which exists in most languages. They mean something and a random noise. What's the other one, calvin, that i've forgotten about. You're muted. Which one? So what do they all mean? So they're horse, mother and two others. [music] means like sesame or sesame. Oh, yes, yes, yes, yes, yes. Ma, means to. And so these are different. But we also have things like clicks. Okay, so you can go and you can go the one, which i can't do. And the most famous language that has clicks in it is so, which is spoken by what's spoken by nelson mandela, and also spoken by trevor noah on the daily show. In fact, you can go and go and listen to videos of him teaching you how to do them. And actually, there are multiple types of clicks, which you probably didn't expect,",
        "transcript-corrected": "Now, vowel length doesn't really make much difference in English, but it does in some other languages, maybe a bit. And beat our a vowel length difference. Some people argue that. But in Japanese, vowel length is very important. So you have the word surgeon, which means husband, and you have the word surgeon, which means prisoner. A story that always allows me to remember this, I lived in Japan for years, and my Japanese is reasonable, it's not completely fluent. When you're speaking to people in Japanese, you often refer to people by relationships rather than by names. So when I would meet my neighbor in the morning and say good morning and say, hello, I am. My neighbor worked at the same company as me, so I knew her relatively well, and so did her husband, I would sometimes say to her, how's your husband? And so I would say to her something like the Genki disco. And I'd get the vowel length wrong. So instead of saying, how's your husband, I would say, how's your prisoner? I am. Now the embarrassing thing about this is, some time later, I was in a discussion where this particular person was giving, uh an example of how violence is important in Japanese and how foreigners often get it wrong. And she used me as the example, and I was in the audience without actually identifying me. Well, she did save some guy with a long beard, but she wasn't going to identify it. And it's important, and you learn after a while. I'm relatively good about it and can recognize it without really thinking anymore. But it is interesting that you can't detect it to begin with. We don't just do these linear things with segments. We also can do things above the segmental form. Tones are an excellent example of this. All languages use the f0, the fundamental frequency, to do things like, well, we sing with it, but we also do focus. We also do things like whether it's a question or not, although not as much as what you think. We can use it for doing things like whether we're sure or unsure, whether finished, etc. And I'll show you some examples of that in a minute. But some languages, actually quite a lot of languages, use the tone to be able to distinguish between different words. So let's take Mandarin Chinese, because half of us speak mind they're in Chinese, we think. And let's see what, uh, we can do so if we take the phoneme and the vowel. Ah, so, MA, there are actually four different tones in Mandarin Chinese, and they just are varied on how the tone. So rather than me do it, I'm going to ask Amanda and Chinese speaker to give me the word man with the four different tones. Who wants to do it? Okay, Calvin, go ahead. Ma, MA, okay. Now, for English speakers or nontonal speakers, you probably just thought, well, they're different, but you really mean something different. So they mean, I not necessarily in this order, horse, they mean mother. Actually, it's the same word, MA, which exists in most languages. They mean something and a random noise. What's the other one, Calvin, that I've forgotten about. You're muted. Which one? So what do they all mean? So they're horse, mother and two others. [Music] means like sesame or sesame. Oh, yes, yes, yes, yes, yes. Ma, means to. And so these are different. But we also have things like clicks. Okay, so you can go and you can go the one, which I can't do. And the most famous language that has clicked on it is so, which is spoken by what's spoken by Nelson Mandela, and also spoken by Trevor Noah on the daily show. In fact, you can go and go and listen to videos of him teaching you how to do them. And actually, there are multiple types of clicks, which you probably didn't expect,",
        "brief-summary": "In our series of letters from the BBC, BBC World News presenter Jeremy Paxman looks at the importance of vowel length in languages."
    },
    {
        "start_timestamp": "00:54:30",
        "transcript": "Clicks, which you probably didn't expect. Okay, i'm just going to skip that slide and i'm going to move on to prosody. So although we just talked about the fzero being important and you've got to get it right, you've got to be able to recognize it, otherwise it's going to be confusable. The tune, the underlying song that's in speech, actually makes a difference the duration of how long or short. We saw that that makes a difference phonetically, but we also change the speed of things that we're doing to help focus things, to help show where we are. Considering that this is a relative clause, we actually do lots of things like this. And phrasing, splitting things into chunks, often taking a breath between them, is another way for how to pass information. Okay,",
        "transcript-corrected": "Clicks, which you probably didn't expect. Okay, I'm just going to skip that slide and I'm going to move on to prosody. So although we just talked about the zero is important and you've got to get it right, you've got to be able to recognize it, otherwise it's going to be confusable. The tune, the underlying song that's in speech, actually makes a difference the duration of how long or short. We saw that that makes a difference phonetically, but we also change the speed of things that we're doing to help focus things, to help show where we are. Considering that this is a relative clause, we actually do lots of things like this. And phrasing, splitting things into chunks, often taking a breath between them, is another way for how to pass information. Okay,",
        "brief-summary": "Today we're going to talk about how to say the zero."
    },
    {
        "start_timestamp": "00:55:16",
        "transcript": "Okay, intonation. What we're actually doing is we're vibrating our larynx. That's the thing that's in our throat. It's the lump that's in our throat. For males, it's usually, but you have a lot of control, between about 80 to 140 times per second. For female, it's about 130 to 220 times a second. Again, you've got a lot of control until below and above it. But that's where the standard range is for children. Okay? It's even higher than what it is for females. And in this first approximation, it's got something to do with the length of the vocal tract, of how easy it is to get reverberation in the particular length. And at puberty, the male adam's apple in the larynx actually moves a little bit further down the throat. That's the breaking voice that happens, where a boys voice gets deeper. And this doesn't happen in female. Now, children, i've also got smaller heads because they're smaller, okay, so there's less room to get all the bits of stuff in there. And and so the shorter the vocal tract in general, the higher pitch that people are going to do. But people have lots of control over this. Okay? Actually, what happens is, in general, in a very general sense, the deeper a voice, the more authoritative it's perceived, and the higher, the less authoritative it's perceived. And this is probably really, really, really old in our evolution, and it's probably along the lines of, a big lion makes a deep roar, and it's really dangerous, while a little mouse makes a highpitched squeak and it's not dangerous at all. Okay? And so we've probably got this perception of deep is authoritative, dangerous, and highpitched is not. This might be why questions rise at the end, but it's hard to do the experiments to find out whether that's true. But rising intonation is often considered to be something about questions or unsureness, across all languages. Now, in american english, what's happened is, what's quite interesting, is female speech, the mean pitch of female speech in american english has dropped over the last 150 years to be quite low, in what would be the natural pitch range for women. And this has actually got so low that it becomes difficult for women to support their pitch all the time. And what happens is they end up at the bottom of their pitch range, and they end up doing what's called creaky voice. Okay. Now, i can't do that. Okay. But many american women, especially younger women, actually do this. And i'm going to ask you to look it up on the net and watch video about it. And it's a particular form of pulsed fzero. But it actually is. It's, it's dropping every second pitch, or not quite every second pitch. It's often perceived to be a little bit casual, so it might not happen in carefully performed speech, but it's pretty common. British english did not do that until about maybe 30 years ago, but now most people are doing it. This is rather interesting. When you find bilingual people who speak american english and something else, and women, they will often speak in their other language, say japanese, with a fully supported pitch that's substantially higher that when they're speaking american, they drop their pitch so that they get close to quickie voice. Okay, so it's quite an interesting thing that actually has happened. And it's social. It's not actually to do with the size of our heads. It's not actually to do with any true linguistic thing. It's a sociolinguistic thing that's happened relatively recently. And if you listen to recordings 50 plus years ago, you find it's very rare. But then recordings from 50 years ago are usually performance forms that they're not casual speech. Okay, so it can sometimes be hard to do that. Here's the example of fzero. Okay,",
        "transcript-corrected": "Okay, intonation. What we're actually doing is we're vibrating our larynx. That's the thing that's in our throat. It's the lump that's in our throat. For males, it's usually, but you have a lot of control, between about 80 to 140 times per second. For female, it's about 130 to 220 times a second. Again, you've got a lot of control until below and above it. But that's where the standard range is for children. Okay? It's even higher than what it is for females. And in this first approximation, it's got something to do with the length of the vocal tract, of how easy it is to get reverberation in the particular length. And at puberty, the male adam's apple in the larynx actually moves a little bit further down the throat. That's the breaking voice that happens, where a boy's voice gets deeper. And this doesn't happen in female. Now, children, I've also got smaller heads because they're smaller, okay, so there's less room to get all the bits of stuff in there. And and so the shorter the vocal tract in general, the higher pitch that people are going to do. But people have lots of control over this. Okay? Actually, what happens is, in general, in a very general sense, the deeper a voice, the more authoritative, it's perceived, and the higher, the less authoritative it's perceived. And this is probably really, really, really old in our evolution, and it's probably along the lines of, a big lion makes a deep roar, and it's really dangerous, while a little mouse makes a high pitched squeak and it's not dangerous at all. Okay? And so we've probably got this perception of deep is authoritative, dangerous, and high pitched is not. This might be why questions arise at the end, but it's hard to do the experiments to find out whether that's true. But rising intonation is often considered to be something about questions or unsureness, across all languages. Now, in American English, what's happened is, what's quite interesting, is female speech, the mean pitch of female speech in American English has dropped over the last 150 years to be quite low, in what would be the natural pitch range for women. And this has actually got so low that it becomes difficult for women to support their pitch all the time. And what happens is they end up at the bottom of their pitch range, and they end up doing what's called creaky voice. Okay. Now, I can't do that. Okay. But many American women, especially younger women, actually do this. And I'm going to ask you to look it up on the net and watch videos about it. And it's a particular form of pulsed zero. But it actually is. It's, it's dropping every second pitch, or not quite every second pitch. It's often perceived to be a little bit casual, so it might not happen in carefully performed speech, but it's pretty common. British English did not do that until about maybe 30 years ago, but now most people are doing it. This is rather interesting. When you find bilingual people who speak American English and something else, and women, they will often speak in their other language, say Japanese, with a fully supported pitch that's substantially higher that when they're speaking American, they drop their pitch so that they get close to quickie voice. Okay, so it's quite an interesting thing that actually has happened. And it's social. It's not actually to do with the size of our heads. It's not actually to do with any true linguistic thing. It's a sociolinguistic thing that's happened relatively recently. And if you listen to recordings 50 plus years ago, you find it's very rare. But then recordings from 50 years ago are usually performance forms that they're not casual speech. Okay, so it can sometimes be hard to do that. Here's the example of zero. Okay,",
        "brief-summary": "In our series of letters from British journalists, film-maker and columnist John Humphrys explains why intonation is often considered to be something about questions or unsureness, across all languages."
    },
    {
        "start_timestamp": "00:59:38",
        "transcript": "That. Here's the example of fzero. Okay, that i'm going to show you the information that's in it, but the things that we actually care about beyond the words. And what we've got is this line is representing the f zero over time, and it's representing the frequency of how the speakers larynx is going back and forward over time. So the person is saying the words along the bottom. Jeff connolly heads the boston finance commission. And what we're seeing is the person starts at 300. 300 is quite high for a male. They can do it, but 300 is quite high for a male. So this is probably a female speaker. Notice, though, it goes below 100 at the end, and that's quite low for a female speaker. So this is an authoritative female speaker. So it's probably a news reader, or somebody like a news newsreader, or reading a newsreader style. Okay? And i can get that by looking at it. Okay, next. Okay. If you look at the word finance, there's a little bump on the word finance. Okay? [music]. I can find my cursor, so you can see it right here. Okay, there's a word finance. And notice that there's not a bump on boston. Now, what happens when you speak, you put these are called pitch accents, on the important new information in speech. If you don't do that, it confuses people. It's not always necessary, but, you know, natural speakers will do this, and nonnative sometimes don't. It may confuse people. And but most, even nonnatives, will do this. In fact, most languages do something like this. So here we have a a bump on finance, and we do not have one on boston. That tells me that the word finance is an important piece of information in this sentence. Well, the word boston is not an important piece of information. So the person is not, who's reading this, is not telling me something about boston. They're telling me something about finance. So what they're saying is, jeff connolly heads the boston finance commission. They're not telling me, jeff conley heads the boston finance commission. So there's no contrasting boston with something else. So the person who's reading this is in boston, or they're in a context where boston is already acknowledged as part of the form. So i'm now going to play this. Okay, so you can actually hear it jeff connolly heads the boston finance commission, a watchdog agency created by the city charter. There's a second part there, where a watchdog agency committed. By the second chart, you see this other little rise here. This means that the person is not finished, and there's going to be more. So they don't just say, jeff connolly heads the boston finance commission. They say, jeff connolly heads the boston finance commission, a watchdog agency created by the city charter. Now, i'm cheating a little bit here. I know who said this. I know that they're actually from wbr bur in boston, so they're an npr news reader. They're actually a professor at the boston university in boston. And so i know that. But i'm highlighting these things that are in the intonation because they're important. And if you do not do that in speech synthesis, then you'll confuse the listener. You might not confuse them so much that they don't know what's going on, but it's easier if you do this. And likewise, if somebody speaks like that, they're telling you information about the about the information that they're giving you, okay? And that's what this says, okay.",
        "transcript-corrected": "That. Here's the example of zero. Okay, that I'm going to show you the information that's in it, but the things that we actually care about beyond the words. And what we've got is this line is representing the f zero over time, and it's representing the frequency of how the speaker's larynx is going back and forward over time. So the person is saying the words along the bottom. Jeff Connolly heads the Boston finance commission. And what we're seeing is the person starts at 300. 300 is quite high for a male. They can do it, but 300 is quite high for a male. So this is probably a female speaker. Notice, though, it goes below 100 at the end, and that's quite low for a female speaker. So this is an authoritative female speaker. So it's probably a news reader, or somebody like a news newsreader, or reading a newsreader style. Okay? And I can get that by looking at it. Okay, next. Okay. If you look at the word finance, there's a little bump on the word finance. Okay? [Music]. I can find my cursor, so you can see it right here. Okay, there's a word finance. And notice that there's not a bump on Boston. Now, what happens when you speak, you put these are called pitch accents, on the important new information in speech. If you don't do that, it confuses people. It's not always necessary, but, you know, natural speakers will do this, and nonnative sometimes don't. It may confuse people. And but most, even nonnatives, will do this. In fact, most languages do something like this. So here we have a a bump on finance, and we do not have one in Boston. That tells me that the word finance is an important piece of information in this sentence. Well, the word Boston is not an important piece of information. So the person is not, who's reading this, is not telling me anything about Boston. They're telling me something about finance. So what they're saying is, Jeff Connolly heads the Boston finance commission. They're not telling me, Jeff Conley heads the Boston finance commission. So there's no contrasting Boston with something else. So the person who's reading this is in Boston, or they're in a context where Boston is already acknowledged as part of the form. So I'm now going to play this. Okay, so you can actually hear it Jeff Connolly heads the Boston finance commission, a watchdog agency created by the city charter. There's a second part there, where a watchdog agency committed. By the second chart, you see this other little rise here. This means that the person is not finished, and there's going to be more. So they don't just say, Jeff Connolly heads the Boston finance commission. They say, Jeff Connolly heads the Boston finance commission, a watchdog agency created by the city charter. Now, I'm cheating a little bit here. I know who said this. I know that they're actually from Weber bar in Boston, so they're an npr news reader. They're actually a professor at the Boston university in Boston. And so I know that. But I'm highlighting these things that are in the intonation because they're important. And if you do not do that  speech synthesis, then you'll confuse the listener. You might not confuse them so much that they don't know what's going on, but it's easier if you do this. And likewise, if somebody speaks like that, they're telling you information about the about the information that they're giving you, okay? And that's what this says, okay.",
        "brief-summary": "So what I'm going to show you is how to tell who's reading this and who's reading it. So what they're saying is, Jeff Connolly heads the Boston finance commission."
    },
    {
        "start_timestamp": "01:03:16",
        "transcript": "Okay? And that's what this says. Okay. If we move further up the chain, and there are these things called words, which, of course, in a english we think are something to do with where we put the species between things. Until we give these complex forms of words, like los angeles. Is los angeles one word or two words, and it's got a space in the middle of it. It could be two words. It's actually one word because lexically it exists in your head, and you're pronouncing the loss in a different way, because you're saying it voiced as los angeles rather than los altos. And because also things like new york is also one word, even though we have a space in it. And we get other things that are really multiple words, even though we don't put species in them, especially longer forms. Uh, many languages don't put spaces between words. Tall chinese, thai, japanese, they don't use spaces yet. Most speakers have a fairly strong concept of a word. And we'd like to be able to deal with that when we're both doing recognition and we're doing synthesis and we're doing any form of understanding. English has very little morphology, as does chinese. And we have a few cases of inflectional light, walk, walked, walks. And we have some derivational morphology, like happiness and sadness. But other languages have got ridiculously large amount of a morphology that all words have got various forms. So here, written in the romanized form, we've got aruku rukimasukimashita. I find it quite hard to read the romanization, actually, nobody. You don't crimson. At the end, aruka means to walk. Ricky masters, playtime is the past tense of i wanted to walk a no, yes, it is. It is what i wanted to walk. And routine mass is the polite form of the potential that i can walk, or the person can walk. And all of these get used all the time, and they're all sort of the same word, but they're not quite and you have to be able to deal with the difference between those if you wanted to try to do understanding. And in speech, these things appear",
        "transcript-corrected": "Okay? And that's what this says. Okay. If we move further up the chain, and there are these things called words, which, of course, in an English we think are something to do with where we put the spaces between things. Until we give these complex forms of words, like Laos Angeles. Is los Angeles one word or two words, and it's got a space in the middle of it. It could be two words. It's actually one word because lexically it exists in your head, and you're pronouncing the loss in a different way, because you're saying it voiced as loss angels rather than lose altos. And because also things like new York is also one word, even though we have a space in it. And we get other things that are really multiple words, even though we don't put spaces in them, especially longer forms. Uh, many languages don't put spaces between words. Tall Chinese, Thai, Japanese, they don't use spaces yet. Most speakers have a fairly strong concept of a word. And we'd like to be able to deal with that when we're both doing recognition and we're doing synthesis and we're doing any form of understanding. English has a very little morphology, as does Chinese. And we have a few cases of inflectional light, walk, walked, walks. And we have some derivational morphology, like happiness and sadness. But other languages have got a ridiculously large amount of a morphology that all words have got various forms. So here, written in the romanized form, we've got aruku rukimasukimashita. I find it quite hard to read the romanization, actually, nobody. You don't crimson. At the end, aruka means to walk. Ricky masters, playtime is the past tense of I wanted to walk a no, yes, it is. It is what I wanted to walk. And routine mass is the polite form of the potential that I can walk, or the person can walk. And all of these get used all the time, and they're all sorts of the same word, but they're not quite and you have to be able to deal with the difference between those if you wanted to try to do understanding. And in speech, these things appear",
        "brief-summary": "In our series of letters from African journalists, film-maker and columnist Ricky Gervais looks at the different forms of words in English."
    },
    {
        "start_timestamp": "01:06:00",
        "transcript": "These things appear. And nearly finally, it's not just about the words. Is about how we say them. So when i say, can you pass the salt? It's not a question. The answer to it should not be yes or no. The answer should really be the act of passing the salt. It's a polite way of requesting that the person does something for you. So questions are often used as commands in english, as polite ways of doing okay. [music]. And the other thing is we can say things in different ways, which we sometimes mark in, the uh, with punctuation, but sometimes we don't. So the answer could be boston. The answer could be boston, or the answer could be boston. And we say these in different ways, but the text looks exactly the same way. So look at the sentence, i want to go to boston. Okay. There are multiple ways that you could say it, depending on what the previous question would be. Where do you want to go to? I want to go to boston. Okay, what? What? Uh, what did you say about boston? I want to go to boston. Okay, well, we've got a choice of places to go to. Uh, what do you want to do? I am i want to go to boston. Okay? And so depending on where you put emphasis in that sentence, it means something different, even though the text is exactly the same thing. And in dialogue systems, the humans speaking to the system may do that, and the system going back should actually do that too. Okay? And so i've talked about human speech",
        "transcript-corrected": "These things appear. And nearly finally, it's not just about the words. Is  how we tell them. So when I say, can you pass the salt? It's not a question. The answer to it should not be yes or no. The answer should really be the act of passing the salt. It's a polite way of requesting that the person does something for you. So questions are often used as commands in English, as polite ways of doing okay. [Music]. And the other thing is we can say things in different ways, which we sometimes mark in, the uh, with punctuation, but sometimes we don't. So the answer could be Boston. The answer could be Boston, or the answer could be Boston. And we say these in different ways, but the text looks exactly the same way. So look at the sentence, I want to go to Boston. Okay. There are multiple ways that you could say it, depending on what the previous question would be. Where do you want to go to? I want to go to Boston. Okay, what? What? Uh, what did you say about Boston? I want to go to Boston. Okay, well, we've got a choice of places to go to. Uh, what do you want to do? I am, I want to go to Boston. Okay? And so depending on where you put emphasis in that sentence, it means something different, even though the text is exactly the same thing. And in dialogue systems, the humans speaking to the system may do that, and the system going back should actually do that too. Okay? And so I've talked about human speech",
        "brief-summary": "In our series of letters from African journalists, film-maker and columnist Farai Sevenzo looks at how we tell the words we use."
    },
    {
        "start_timestamp": "01:07:44",
        "transcript": "And so i've talked about human speech production and perception, quite different from computers. We do not build physical objects and blow air through them, although there's some pretty cool things out there that try to build vocal tracks, but they're deeply frightening. Do not watch them before you go to sleep, if you find them on youtube. I talked about phrenology, the alphabet of speech, in these units. It's different, different languages, different distinctions. And remember, what we want to do is find the definition that's good for computer speech processing, and maybe that's not the same for linguistic definitions. And then we talked a little bit about intonation, and we'll talk more about that later, about how it's said, not just these isolated phonemes actually talking. Okay, that's it for today. Are there any questions? Sudan asks, what does this community in the curve of the fzero represent? That's actually a small and break, because the person actually maybe couldn't break, although sometimes, depending on how the fzero is drawn, the unvoiced regions which are relatively common or have discontinuities in it. Now, there are no reading assignments this week. And i think i mentioned before that there is uh a textbook. We don't follow it much, but it follows much of what this course is all about. And some of it's a little old now. And it's called a are introduced to speech and language processing. And it's often referred to as the microsoft book because it's written by a bunch of people at microsoft, though they're not all at microsoft anymore. Alex athero a c e r, it's in the slides for the first lecture, and is the first author. He's actually technical head of siri at apple now, but he used to be head of microsoft research and speech, microsoft research. Xd, wang shudong bang is now head of speech at microsoft, unless they changed it again, which they do almost all the time. And he used to be a professor at cmu. In fact, alex cerro was did his phd. At cmu as well. The slides from the first lecture have been posted, and if you go to the website that's linked to my page, that's where i'm putting the slides. I've not posted them on canvas or a in piazza, but if you go to that website, they are there. And i could click on them. Can somebody do that now? Okay, can you? Can you do that? For today's slides. Does it work? Okay, so i've just messed in some naming of things. Okay. Okay, i'll fix that. Tell me when that happens. I always put the slides up before the lecture because you can follow them on there. Much more importantly, you can go back and correct me when i say something stupid and wrong earlier, which is why we actually have them there. And yes, the recordings will be posted. I haven't done anything about that yet. They're going to be on youtube though. And i'll put links in that schedule website that's got linked that you've just found from my home page. Okay. Any other questions? Okay, remember, no lecture on friday. Okay, and no lecture on monday because monday's a holiday. It's labor day. Okay. And so we won't meet again until next wednesday afternoon, where we'll talk about computer speech rather than human speech. Okay. Okay. Thank you. You",
        "transcript-corrected": "And so I've talked about human speech production and perception, quite different from computers. We do not build physical objects and blow air through them, although there's some pretty cool things out there that try to build vocal tracks, but they're deeply frightening. Do not watch them before you go to sleep, if you find them on YouTube. I talked about phrenology, the alphabet of speech, in these units. It's different, different languages, different distinctions. And remember, what we want to do is find the definition that's good for computer speech processing, and maybe that's not the same for linguistic definitions. And then we talked a little bit about intonation, and we'll talk more about that later, about how it's said, not just these isolated phonemes actually talking. Okay, that's it for today. Are there any questions? Sudan asks, what does this community in the curve of the zero represent? That's actually a small and break, because the person actually maybe couldn't break, although sometimes, depending on how the zero is drawn, the unvoiced regions which are relatively common or have discontinuities in it. Now, there are no reading assignments this week. And I think I mentioned before that there is, uh a textbook. We don't follow it much, but it follows much of what this course is all about. And some of it's a little old now. And it's called a are introduced to speech and language processing. And it's often referred to as the Microsoft book because it's written by a bunch of people at Microsoft, though they're not all at Microsoft anymore. Alex either a c e, r, it's in the slides for the first lecture, and is the first author. He's actually technical head of Siri at apple now, but he used to be the head of Microsoft research and speech, Microsoft research. Xd, when the sudden bang is now head of speech at Microsoft, unless they changed it again, which they do almost all the time. And he used to be a professor at cmu. In fact, Alex Cerro did his PhD. At come as well. The slides from the first lecture have been posted, and if you go to the website that's linked to my page, that's where I'm putting the slides. I've not posted them on canvas or a in piazza, but if you go to that website, they are there. And I could click on them. Can anyone do that now? Okay, can you? Can you do that? For today's slides. Does it work? Okay, so I've just messed in some naming of things. Okay. Okay, I'll fix that. Tell me when that happens. I always put the slides up before the lecture because you can follow them on there. Much more importantly, you can go back and correct me when I say something stupid and wrong earlier, which is why we actually have them there. And yes, the recordings will be posted. I haven't done anything about that yet. They're going to be on YouTube though. And I'll put links on that schedule website that's got linked that you've just found from my home page. Okay. Any other questions? Okay, remember, no lecture on Friday. Okay, and no lecture on Monday because mondays' a holiday. It's labor day. Okay. And so we won't meet again until next Wednesday afternoon, where we'll talk about computer speech rather than human speech. Okay. Okay. Thank you. You",
        "brief-summary": "It's the second week of this course, and it's all about speech and language processing."
    }
]