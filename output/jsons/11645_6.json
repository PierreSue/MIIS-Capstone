{
    "ID": "11645_6",
    "name": "Database systems - Hash Table",
    "description": "This course is on the design and implementation of database management systems. Topics include data models (relational, document, key/value), storage models (n-ary, decomposition), query languages (SQL, stored procedures), storage architectures (heaps, log-structured), indexing (order preserving trees, hash tables), transaction processing (ACID, concurrency control), recovery (logging, checkpoints), query processing (joins, sorting, aggregation, optimization), and parallel architectures (multi-core, distributed). Case studies on open-source and commercial database systems are used to illustrate these techniques and trade-offs. The course is appropriate for students that are prepared to flex their strong systems programming skills.",
    "lecturerName": "Andrew Crotty",
    "lecturerAvatar": "11645.png",
    "time": "01:18:40",
    "youtube_link": "https://www.youtube.com/watch?v=f71kc4osCyM",
    "segments": [
        {
            "start_timestamp": "00:00:00",
            "title": "ADMINISTRIVIA",
            "text": "ADMINISTRIVIA\n\nis due Sunday, Sept 26 @ 11:59pm\n\nis due Sunday, Oct 3° @11:5°pm",
            "transcript": "[Applause] [Music], so today's lecture is going to be about hash tables and how they are used in a dbms. So before we get going of course, we have to talk about some of the administrative things uh project number one will be due on sunday september, 26th at as usual 1, 59 p.m, and homework number two uh, which is about indexes which uh we'll cover in in the next couple of lectures, is going to be released today, so it'll be up on the website and that will be due on sunday october 3rd, also at 11 59 pm just again reminder about the the plagiarism warning. Your project implementation has to be your own work, you're not allowed to copy source code from other students, other groups or on the internet, and please don't publish your implementations on github or otherwise make them publicly available. Because then you know that allows other people to go, track them down and and copy them. And again, if you're confused, you can take a look at the at the academic integrity policy or if you have a question about anything, please contact me or one of the tas or post on piazza and just ask for clarification, because it's better that you know we can address it beforehand rather than having to find out afterwards and then deal with it. Then the last thing.",
            "transcript-corrected": "[Applause] [Music], so today's lecture is going to be about hash tables and how they are used in a DBMS. So before we get going, of course, we have to talk about some of the administrative things, uh project number one will be due on Sunday, September, 26th at as usual 1, 59 p.m., and homework number two, uh, which is about indexes which, uh we'll cover in in the next couple of lectures, is going to be released today, so it'll be up on the website and that will be due on Sunday October 3rd, also at 11 59 pm just again reminder about the plagiarism warning. Your project implementation has to be your own work, you're not allowed to copy source code from other students, other groups or on the internet, and please don't publish your implementations on github or otherwise make them publicly available. Because then you know that allows other people to go, track them down and copy them. And again, if you're confused, you can take a look at the at the academic integrity policy or if you have a question about anything, please contact me or one of the toes or post on the piazza and just ask for clarification, because it's better that you know we can address it beforehand rather than having to find out afterwards and then deal with it. Then the last thing.",
            "summary_brief": "Welcome to the lecture series.",
            "summary_detailed": "Project number one will be due on Sunday, September, 26th at as usual 1, 59 p.m. homework number two, which is about indexes which, uh we'll cover in in the next couple of lectures, is going to be released today, so it'll be up on the website. Just again reminder about the plagiarism warning.",
            "key_concepts": {
                "project": {
                    "Score": "0.89920753",
                    "Summary": "A project (or program) is any undertaking, carried out individually or collaboratively and possibly involving research or design, that is carefully planned (usually by a project team, but sometimes by a project manager or by a project planner) to achieve a particular aim.An alternative view sees a project  managerially as a sequence of events: a \"set of interrelated tasks to be executed over a fixed period and within certain cost and other limitations\".A project may be a temporary (rather than permanent) social system (work system), possibly staffed by teams (within or across organizations) to accomplish particular tasks under time constraints.A project may form a part of wider programme management\nor function as an ad hoc system.Note that open-source software \"projects\" or artists' musical \"projects\" (for example) may lack defined team-membership, precise planning and/or time-limited durations.",
                    "URL": "https://en.wikipedia.org/wiki/Project"
                },
                "homework": {
                    "Score": "0.8609265",
                    "Summary": "Homework, or a homework assignment, is a set of tasks assigned to students by their teachers to be completed outside the classroom. Common homework assignments may include required reading, a writing or typing project, mathematical exercises to be completed, information to be reviewed before a test, or other skills to be practiced.\nThe effects of homework are debated. Generally speaking, homework does not improve academic performance among young children. Homework may improve academic skills among older students, especially lower-achieving students. However, homework also creates stress for students and parents, and reduces the amount of time that students can spend in other activities.",
                    "URL": "https://en.wikipedia.org/wiki/Homework"
                },
                "github": {
                    "Score": "0.8578642",
                    "Summary": "GitHub, Inc. is a provider of Internet hosting for software development and version control using Git. It offers the distributed version control and source code management (SCM) functionality of Git, plus its own features. It provides access control and several collaboration features such as bug tracking, feature requests, task management, continuous integration and wikis for every project. Headquartered in California, it has been a subsidiary of Microsoft since 2018.It is commonly used to host open-source projects. As of November 2021, GitHub reports having over 73 million developers  and more than 200 million repositories (including at least 28 million public repositories). It is the largest source code host as of November 2021.",
                    "URL": "https://en.wikipedia.org/wiki/GitHub"
                },
                "integrity": {
                    "Score": "0.8575544",
                    "Summary": "Integrity is the practice of being honest and showing a consistent and uncompromising adherence to strong moral and ethical principles and values.\nIn ethics, integrity is regarded as the honesty and truthfulness or accuracy of one's actions. Integrity can stand in opposition to hypocrisy, in that judging with the standards of integrity involves regarding internal consistency as a virtue, and suggests that parties holding within themselves apparently conflicting values should account for the discrepancy or alter their beliefs. The word integrity evolved from the Latin adjective integer, meaning whole or complete. In this context, integrity is the inner sense of \"wholeness\" deriving from qualities such as honesty and consistency of character. As such, one may judge that others \"have integrity\" to the extent that they act according to the values, beliefs and principles they claim to hold.",
                    "URL": "https://en.wikipedia.org/wiki/Integrity"
                },
                "question": {
                    "Score": "0.8558807",
                    "Summary": "A question is an utterance which typically functions as a request for information, which is expected to be provided in the form of an answer. Questions can thus be understood as a kind of illocutionary act in the field of pragmatics or as special kinds of propositions in frameworks of formal semantics such as alternative semantics or inquisitive semantics. Questions are often conflated with interrogatives, which are the grammatical forms typically used to achieve them. Rhetorical questions, for example, are interrogative in form but may not be considered true questions as they are not expected to be answered.",
                    "URL": "https://en.wikipedia.org/wiki/Question"
                },
                "plagiarism": {
                    "Score": "0.8528461",
                    "Summary": "Plagiarism is the representation of another author's language, thoughts, ideas, or expressions as one's own original work. In educational contexts, there are differing definitions of plagiarism depending on the institution. \nPlagiarism is considered a violation of academic integrity and a breach of journalistic ethics. It is subject to sanctions such as penalties, suspension, expulsion from school or work, substantial fines and even incarceration.Generally, plagiarism is not in itself a crime, but like counterfeiting fraud can be punished in a court for prejudices caused by copyright infringement, violation of moral rights, or torts. In academia and industry, it is a serious ethical offense. Plagiarism and copyright infringement overlap to a considerable extent, but they are not equivalent concepts, and many types of plagiarism do not constitute copyright infringement, which is defined by copyright law and may be adjudicated by courts.\nPlagiarism might not be the same in all countries. Some countries, such as India and Poland, consider plagiarism to be a crime, and there have been cases of people being imprisoned for plagiarizing. In other instances, plagiarism might be the complete opposite of \"academic dishonesty\"; in fact, in some countries the act of plagiarizing a professional's work is seen as flattering. Students who move to the United States and other Western countries from countries where plagiarism is not frowned upon often find the transition difficult.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Plagiarism"
                },
                "source code": {
                    "Score": "0.8436526",
                    "Summary": "In computing, source code is any collection of code, with or without comments, written using a human-readable programming language, usually as plain text. The source code of a program is specially designed to facilitate the work of computer programmers, who specify the actions to be performed by a computer mostly by writing source code. The source code is often transformed by an assembler or compiler into binary machine code that can be executed by the computer. The machine code might then be stored for execution at a later time. Alternatively, source code may be interpreted and thus immediately executed.\nMost application software is distributed in a form that includes only executable files. If the source code were included it would be useful to a user, programmer or a system administrator, any of whom might wish to study or modify the program.\nSource code is an instance of Code. Compare to Genetic code, Code of law and Language.",
                    "URL": "https://en.wikipedia.org/wiki/Source_code"
                },
                "applause": {
                    "Score": "0.8414813",
                    "Summary": "Applause (Latin applaudere, to strike upon, clap) is primarily a form of ovation or praise expressed by the act of clapping, or striking the palms of the hands together, in order to create noise. Audiences usually applaud after a performance, such as a musical concert, speech, or play, as a sign of enjoyment and approval.",
                    "URL": "https://en.wikipedia.org/wiki/Applause"
                },
                "academic integrity": {
                    "Score": "0.8378331",
                    "Summary": "Academic integrity is the moral code or ethical policy of academia. The term was popularized by the late Don McCabe (USA), who is considered to be the \"grandfather of academic integrity\".  Other prominent academic integrity scholars and advocates include Tracey Bretag (Australia), Cath Ellis (Australia), Sarah Elaine Eaton (Canada), Thomas Lancaster (UK),  and Foltýnek, Tomáš (Czechia) and Tricia Bertram Gallant (USA). Academic integrity supports the enactment of educational values through behaviours such as the  avoidance of cheating, plagiarism, and contract cheating, as well as the maintenance of academic standards; honesty and rigor in research and academic publishing.",
                    "URL": "https://en.wikipedia.org/wiki/Academic_integrity"
                },
                "implementation": {
                    "Score": "0.81495166",
                    "Summary": "Implementation is the realization of an application, or execution of a plan, idea, model, design, specification, standard, algorithm, or policy.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Implementation"
                },
                "lecture": {
                    "Score": "0.82201946",
                    "Summary": "A lecture (from the Greek lecture, meaning reading) is an oral presentation intended to present information or teach people about a particular subject, for example by a university or college teacher. Lectures are used to convey critical information, history, background, theories, and equations. A politician's speech, a minister's sermon, or even a business person’s sales presentation may be similar in form to a lecture.  Usually the lecturer will stand at the front of the room and recite information relevant to the lecture's content.\nThough lectures are much criticised as a teaching method, universities have not yet found practical alternative teaching methods for the large majority of their courses.  Critics point out that lecturing is mainly a one-way method of communication that does not involve significant audience participation but relies upon passive learning.  Therefore, lecturing is often contrasted to active learning. Lectures delivered by talented speakers can be highly stimulating; at the very least, lectures have survived in academia as a quick, cheap, and efficient way of introducing large numbers of students to a particular field of study.\nLectures have a significant role outside the classroom, as well. Academic and scientific awards routinely include a lecture as part of the honor, and academic conferences often center on \"keynote addresses\", i.e., lectures. The public lecture has a long history in the sciences and in social movements. Union halls, for instance, historically have hosted numerous free and public lectures on a wide variety of matters. Similarly, churches, community centers, libraries, museums, and other organizations have hosted lectures in furtherance of their missions or their constituents' interests. Lectures represent a continuation of oral tradition in contrast to textual communication in books and other media. Lectures may be considered a type of grey literature.",
                    "URL": "https://en.wikipedia.org/wiki/Lecture"
                },
                "number": {
                    "Score": "0.8311747",
                    "Summary": "A number is a mathematical object used to count, measure, and label. The original examples are the natural numbers 1, 2, 3, 4, and so forth. Numbers can be represented in language with number words. More universally, individual numbers can be represented by symbols, called numerals; for example, \"5\" is a numeral that represents the number five. As only a relatively small number of symbols can be memorized, basic numerals are commonly organized in a numeral system, which is an organized way to represent any number. The most common numeral system is the Hindu–Arabic numeral system, which allows for the representation of any number using a combination of ten fundamental numeric symbols, called digits. In addition to their use in counting and measuring, numerals are often used for labels (as with telephone numbers), for ordering (as with serial numbers), and for codes (as with ISBNs). In common usage, a numeral is not clearly distinguished from the number that it represents.\nIn mathematics, the notion of a number has been extended over the centuries to include 0, negative numbers, rational numbers such as one half \n  \n    \n      \n        \n          (\n          \n            \n              \n                1\n                2\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\tfrac {1}{2}}\\right)}\n  , real numbers such as the square root of 2 \n  \n    \n      \n        \n          (\n          \n            \n              2\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\sqrt {2}}\\right)}\n   and π, and complex numbers which extend the real numbers with a square root of −1 (and its combinations with real numbers by adding or subtracting its multiples). Calculations with numbers are done with arithmetical operations, the most familiar being addition, subtraction, multiplication, division, and exponentiation. Their study or usage is called arithmetic, a term which may also refer to number theory, the study of the properties of numbers.\nBesides their practical uses, numbers have cultural significance throughout the world. For example, in Western society, the number 13 is often regarded as unlucky, and \"a million\" may signify \"a lot\" rather than an exact quantity. Though it is now regarded as pseudoscience, belief in a mystical significance of numbers, known as numerology, permeated ancient and medieval thought. Numerology heavily influenced the development of Greek mathematics, stimulating the investigation of many problems in number theory which are still of interest today.During the 19th century, mathematicians began to develop many different abstractions which share certain properties of numbers, and may be seen as extending the concept. Among the first were the hypercomplex numbers, which consist of various extensions or modifications of the complex number system. In modern mathematics, number systems (sets) are considered important special examples of more general categories such as rings and fields, and the application of the term \"number\" is a matter of convention, without fundamental significance.",
                    "URL": "https://en.wikipedia.org/wiki/Number"
                },
                "student": {
                    "Score": "0.8235127",
                    "Summary": "A student is primarily a person enrolled in a school or other educational institution and who is under learning with goals of acquiring  knowledge, developing professions and achieving employment at desired field. In the broader sense, a student is anyone who applies themselves to the intensive intellectual engagement with some matter necessary to master it as part of some practical affair in which such mastery is basic or decisive.\nIn the United Kingdom and most commonwealth countries, the term \"student\" denotes those enrolled in secondary schools and higher (e.g., college or university); those enrolled in primary/elementary schools are called \"pupils\".",
                    "URL": "https://en.wikipedia.org/wiki/Student"
                },
                "hash table": {
                    "Score": "0.8183734",
                    "Summary": "In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index, also called a hash code, into an array of buckets or slots, from which the desired value can be found. During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored.\nIdeally, the hash function will assign each key to a unique bucket, but most hash table designs employ an imperfect hash function, which might cause hash collisions where the hash function generates the same index for more than one key. Such collisions are typically accommodated in some way.\nIn a well-dimensioned hash table, the average cost (number of instructions) for each lookup is independent of the number of elements stored in the table. Many hash table designs also allow arbitrary insertions and deletions of key–value pairs, at (amortized) constant average cost per operation.In many situations, hash tables turn out to be on average more efficient than search trees or any other table lookup structure. For this reason, they are widely used in many kinds of computer software, particularly for associative arrays, database indexing, caches, and sets.",
                    "URL": "https://en.wikipedia.org/wiki/Hash_table"
                },
                "website": {
                    "Score": "0.81495166",
                    "Summary": "A website (also written as web site) is a collection of web pages and related content that is identified by a common domain name and published on at least one web server. Notable examples are wikipedia.org, google.com, and amazon.com.\nAll publicly accessible websites collectively constitute the World Wide Web. There are also private websites that can only be accessed on a private network, such as a company's internal website for its employees.\nWebsites are typically dedicated to a particular topic or purpose, such as news, education, commerce, entertainment, or social networking. Hyperlinking between web pages guides the navigation of the site, which often starts with a home page.\nUsers can access websites on a range of devices, including desktops, laptops, tablets, and smartphones. The app used on these devices is called a web browser.",
                    "URL": "https://en.wikipedia.org/wiki/Website"
                },
                "people": {
                    "Score": "0.8080234",
                    "Summary": "A people is any plurality of persons considered as a whole.\nUsed in politics and law it is a term to refer to the collective or community of an ethnic group, a nation, to the public or common mass of people of a polity. As such it is a concept of human rights law, international law as well as constitutional law, particularly used for claims of popular sovereignty.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/People"
                }
            }
        },
        {
            "start_timestamp": "00:01:44",
            "title": "UPCOMING DATABASE TALKS",
            "text": "UPCOMING DATABASE TALKS\n\n= Today ets30pm\n\n= Monday, Sept 27% gi 30pm [t1 l e]\n= Monday, Oct #° gr 4:30pm bodo",
            "transcript": "[Music] is the database tech talks that that we're having this semester, so they take place mondays uh at 4, 30, right after class on zoom uh. Today's talk is going to be uh from someone from google napa next week, we'll have someone from tile db and then the the week after that, someone from bodo so again feel free if you're interested in the stuff to to check it out, join the zoom everyone's welcome and it's kind of a cool way to see how some of the the topics that we're covering in the course uh get applied in the real world. Uh there's one more thing. I I got an anonymous question before class. In the last class I mentioned that the the student that had the highest the most amount of uh extra credit points from the projects would receive a bus tub t-shirt, and I made the comment that uh it could potentially help when you're on the dating scene. I so the the question was about whether or not that was uh due to causation or correlation, and the answer is, I don't know: we've we've never collected any data on that. So I I honestly can't say so I think what we'll have to do this. This semester is whoever wins, uh, we'll just have to have you fill out some. You know survey or something at the end, so we can collect some data from before and after you have the shirt, so we can. You know for future sections of the course we can be more accurate about that. So I hope that addresses any any uh questions about that. So um.",
            "transcript-corrected": "[Music] is the database tech talks that that we're having this semester, so they take place Mondays uh at 4, 30, right after class on zoom uh. Today's talk is going to be, uh from someone from google Napa next week, we'll have someone from tile dB and then the week after that, someone from bodo so again feel free if you're interested in the stuff to to check it out, join the zoom everyone's welcome and it's kind of a cool way to see how some of the topics that we're covering in the course uh get applied in the real world. Oh, there's one more thing. I I got an anonymous question before the class. In the last class I mentioned that the student that had the highest, the most amount of uh, extra credit points from the projects would receive a bus tub t-shirt, and I made the comment that uh it could potentially help when you're on the dating scene. I so the question was about whether or not that was, uh due to causation or correlation, and the answer is, I don't know: we've we've never collected any data on that. So I I honestly can't say so, I think what we'll have to do this. This semester is whoever wins, uh, we'll just have to have you fill out some. You know survey or something at the end, so we can collect some data from before and after you have the shirt, so we can. You know, for future sections of the course we can be more accurate about that. So I hope that addresses any any, uh questions about that. So, um.",
            "summary_brief": "We're going to be doing a series of music talks.",
            "summary_detailed": "Zoom is the database tech talks that that we're having this semester, so they take place Mondays at 4, 30, right after class on zoom. Today's talk is going to be, uh from someone from google Napa next week, we'll have someone from tile dB and then the week after that, someone from bodo so again feel free if you're interested in the stuff to to check it out, join the zoom everyone's welcome.",
            "key_concepts": {
                "database": {
                    "Score": "0.88933027",
                    "Summary": "In computing, a database is an organized collection of data stored and accessed electronically from a computer system. Where databases are more complex they are often developed using formal design and modeling techniques.\nThe database management system (DBMS) is the software that interacts with end users, applications, and the database itself to capture and analyze the data. The DBMS software additionally encompasses the core facilities provided to administer the database. The sum total of the database, the DBMS and the associated applications can be referred to as a \"database system\". Often the term \"database\" is also used loosely to refer to any of the DBMS, the database system or an application associated with the database.\nComputer scientists may classify database-management systems according to the database models that they support. Relational databases became dominant in the 1980s. These model data as rows and columns in a series of tables, and the vast majority use SQL for writing and querying data. In the 2000s, non-relational databases became popular, referred to as NoSQL because they use different query languages.",
                    "URL": "https://en.wikipedia.org/wiki/Database"
                },
                "world": {
                    "Score": "0.88933027",
                    "Summary": "In its most general sense, the term \"world\" refers to the totality of entities, to the whole of reality or to everything that is. The nature of the world has been conceptualized differently in different fields. Some conceptions see the world as unique while others talk of a \"plurality of worlds\". Some treat the world as one simple object while others analyze the world as a complex made up of many parts. In scientific cosmology the world or universe is commonly defined as \"[t]he totality of all space and time; all that is, has been, and will be\". Theories of modality, on the other hand, talk of possible worlds as complete and consistent ways how things could have been. Phenomenology, starting from the horizon of co-given objects present in the periphery of every experience, defines the world as the biggest horizon or the \"horizon of all horizons\". In philosophy of mind, the world is commonly contrasted with the mind as that which is represented by the mind. Theology conceptualizes the world in relation to God, for example, as God's creation, as identical to God or as the two being interdependent. In religions, there is often a tendency to downgrade the material or sensory world in favor of a spiritual world to be sought through religious practice. A comprehensive representation of the world and our place in it, as is commonly found in religions, is known as a worldview. Cosmogony is the field that studies the origin or creation of the world while eschatology refers to the science or doctrine of the last things or of the end of the world.\nIn various contexts, the term \"world\" takes a more restricted meaning associated, for example, with the Earth and all life on it, with humanity as a whole or with an international or intercontinental scope. In this sense, world history refers to the history of humanity as a whole or world politics is the discipline of political science studying issues that transcend nations and continents. Other examples include terms such as \"world religion\", \"world language\", \"world government\", \"world war\", \"world population\", \"world economy\" or \"world championship\".",
                    "URL": "https://en.wikipedia.org/wiki/World"
                },
                "question": {
                    "Score": "0.8697017",
                    "Summary": "A question is an utterance which typically functions as a request for information, which is expected to be provided in the form of an answer. Questions can thus be understood as a kind of illocutionary act in the field of pragmatics or as special kinds of propositions in frameworks of formal semantics such as alternative semantics or inquisitive semantics. Questions are often conflated with interrogatives, which are the grammatical forms typically used to achieve them. Rhetorical questions, for example, are interrogative in form but may not be considered true questions as they are not expected to be answered.",
                    "URL": "https://en.wikipedia.org/wiki/Question"
                },
                "extra credits": {
                    "Score": "0.86053145",
                    "Summary": "Extra Credits is a video lesson series currently run by Matthew Krol and Geoffrey Zatkin, narrated by Matthew Krol, with artists Scott DeWitt, Nick DeWitt, David \"D\" Hueso, and Ali R. Throme and Jordan Martin and writers Robert Rath, R. Kevin Doyle and other staff members. Social Media is run by Kat Rider. The series of videos discusses topics pertinent to video game development and game studies, addressing the legitimacy of video games as art, and creating intellectual discourse on important issues in gaming culture.The series was developed directly from a series of lecture videos by animator Daniel Floyd, informally known as \"Video Games And...\", which ran sporadically from February 17, 2008 to April 16, 2010 with certain episodes written by Portnow.\nThe series originally aired on The Escapist from July 28, 2010 to August 10, 2011, before being split off over a financial dispute. Between September 7, 2011 and December 31, 2013, the show aired on PATV, a distribution channel hosted by Penny Arcade, whose downsizing of partner services after the latter date was cited as the reason for the show's subsequent \"move\" to YouTube, where the show is currently aired. In addition, the episodes have been syndicated on many websites, including ScrewAttack.",
                    "URL": "https://en.wikipedia.org/wiki/Extra_Credits"
                },
                "bus": {
                    "Score": "0.8552682",
                    "Summary": "A bus (contracted from omnibus, with variants multibus, motorbus, autobus, etc.) is a public transport road vehicle designed to carry significantly more passengers than the average cars or vans. Buses can have a capacity as high as 300 passengers, although the average bus usually carries between 30 to 100. The most common type is the single-deck rigid bus, with larger loads for double-decker and articulated buses, and smaller loads for midibuses and minibuses, while coaches are used for longer-distance services. Many types of buses, such as city transit buses and inter-city coaches, charge a fare. Other types, such as elementary or secondary school buses or shuttle buses within a post-secondary education campus, do not charge a fare. In many jurisdictions, bus drivers require a special large vehicle licence above and beyond a regular driving licence.\nBuses may be used for scheduled bus transport, scheduled coach transport, school transport, private hire, or tourism; promotional buses may be used for political campaigns and others are privately operated for a wide range of purposes, including rock and pop band tour vehicles.\nHorse-drawn buses were used from the 1820s, followed by steam buses in the 1830s, and electric trolleybuses in 1882. The first internal combustion engine buses, or motor buses, were used in 1895. Recently, interest has been growing in hybrid electric buses, fuel cell buses, and electric buses, as well as buses powered by compressed natural gas or biodiesel. As of the 2010s, bus manufacturing is increasingly globalised, with the same designs appearing around the world.",
                    "URL": "https://en.wikipedia.org/wiki/Bus"
                }
            }
        },
        {
            "start_timestamp": "00:03:34",
            "title": "ASSUMPTIONS",
            "text": "ASSUMPTIONS\n\nYou know the number of elements\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\nahead of time.\nEach key is unique. I We\nPerteet hash function. 1\n\nWs ve. then",
            "transcript": "In terms of the course today, we're going to talk about or start talking about how to support kind of the the dbms's execution engine to read and write data from pages, so kind of we've been talking about the the lower levels of the stack. Now we're going to move up the stack to uh this, this access methods, piece uh, we've already talked about disk manager and the buffer pool manager and how all that works uh. So now we're kind of right here in the middle and the two types of data structures. There are many others, especially if you take more advanced database courses or look into more advanced systems. There are many other types of data structures, pretty much the two fundamental ones and the ones we're going to cover in this course are hash tables and and trees. So today, today we're going to be talking about hash tables, so data structures can be used in a whole bunch of different places in the dbms and they're going to be used for a lot of different purposes. For example, they can be used to store internal metadata. We've seen some cases where we use different. You know either a page directory or a page table to kind of perform mappings between pages in their physical locations or tuples, and their physical locations we've seen kind of that use of them. They can be used for core data storage. So, for example, you could have you know, pages or groups of pages organized as hash tables. So you could have your actual table organized as in in some sort of data structure. They could be used as temporary data structures, so you think about it like during query execution. There are different operations where you might want to build a data structure on the fly and then just kind of use that temporarily and then it gets used for the duration of the query, uh and then thrown away. So, for example, during like a hash join uh and finally, uh we've talked a little bit about kind of how you can use data structures as table auxiliary table indexes. So you can kind of have your your core data storage in a table file and you can build an index on top of it to make accessing it a little bit easier, so kind of the the two key design decisions that we need to make when, when designing data structures are the data organization? How is the data you know physically laid out? What are the different trade-offs? We need to consider there as well as concurrency. So we've talked a lot about you know. If you have multiple concurrent transactions or queries running in the system, how can you uh ensure that that the data or data structures are accessed or not modified uh concurrently, causing problems with multiple access? So we're first going to focus kind of on this organization piece just to to simplify the discussion, we're going to assume everything for the most part uh. There will be a few cases where we discuss concurrency but for the most part, we're going to assume for now that everything's single threaded and then we'll talk kind of more about this multi-threaded stuff. When, when we discuss concurrency control in later lecture in the course so, as I said, today's lecture is going to be all about hash tables, so basically a hash table, I'm sure many of you may be familiar with it from you know a data structures course or an algorithms course or something, but basically a hash table implements an associative array from you know some some key to some values. So you have a set of keys. You want to map them to some set of values, so you give the hash table a key. It gives you back the corresponding value associated with that key. The way it does that is, it uses a hash function in order to compute uh, basically an index or an offset into some array for for a given key, and then you can retrieve the associated value with that key. So the space complexity for this is o n. It's scales with the size of the the number of keys that you're storing and the time complex, uh time complexity, depending on how we implement it. The average time complexity is one and the worst case, time complexity zone. We have to look at every single item in order to retrieve the find the key that we're looking for. So I you may know this. You know from from the theory perspective, but in practice a lot of times what we care about are the constants associated with this. So these these are are perfectly fine, uh complexity, assessments, for you know the the abstract idea of a hash table, but if you have, for example, on the order of a billion keys and there's a uh, you know look up overhead of one second per key or something, even though it's constant time that that you know one second adds up a billion times. So we really need to care not just about the the time complexity of these operations, but specifically about kind of the constants. The constant factors that go along with each lookup, so kind of the the easiest most basic hash table that you can uh think about is just to allocate. You know this giant array that has one slot for every element or key that you want to store so uh, for example, just think about the keys like integers and we have between 0 and n, and we want to you know slot each key into an individual slot. We can do this by modding the key by the number of elements that we're storing and then we can find the offset in the array. So, for example, let's say we have this these strings in here, so we have abc null def so forth. The way that we can can find these again is to to perform the hash that tells us brings us to the associated values stored with that key. So hash of the key modded by the number of elements in the array gives us the offset that that we're looking for so there are some assumptions that this simple model makes. The first is that you know the number of elements that you want to store ahead of time, some cases that might be true. You know you know, I have a billion elements. I have a million elements whatever it is. That's all I ever need to store in the hash table in a lot of cases. That might not be true, for example, if you think about a database table that, can you know grow arbitrarily large, so we may need to continue adding keys over time. Another assumption that's made here is that each key is unique, so you can't have, for example, duplicate keys, of course in sql, which is a bag or multi-set algebra. We allow these sorts of duplicate keys, so we that that assumption isn't isn't sufficient for for a lot of cases. And finally, this this kind of assumes a perfect hash function. So here, if key one doesn't equal key two, then the hash of key one isn't going to equal a hash of q2. So that means each hash function uniquely maps a key to some position in this uh array, which it's it's unrealistic uh to kind of devise sort of this. This perfect hash function, that's not going to have any collisions. So when, when we're thinking about designing a more practical hash table, we have sort of these these two design decisions that we have to make- and this is what a hash table is at its score. The first design decision is what type of hash function are we going to use. So how are we going to map the large key space, potentially a really large key space? If you have, you know really large, integers or strings or something? How can you map a very large key space into a much smaller domain, which is the array or or storage that you're storing it in uh? And finally, we want to have this kind of balance. This trade-off uh between being really fast to compute. So we can, you know, compute the hash really quickly versus having a lot of collisions. So you know if you, if you just take, for example, the identity function, that's really fast to compute. You don't have to do anything. You just return the key, but if you have a high number of duplicates in your data, then that's that's going to be end up with a lot of collisions in your your hash table. So that's kind of the first piece is the the hash function and then the second. The second piece really has to do with collisions, which is what what your hashing scheme is going to be. So how do you handle any collisions that are produced by your hash function and again kind of there's? This trade-off here in this case is between allocating a really large hash table. So you can trade off memory or disk depending on where, where your hash table lives, but you can kind of trade off space for additional instructions or performing additional work, compute time to to find and insert keys so kind of. In both of these cases, we have to consider away these trade-offs and a lot of the different schemes that we'll look at today will have different ways of balancing these uh different tradeoffs, so uh, the this whole lecture is going to be about. You know kind of all the different aspects of building uh hash tables, we're going to start again at the first, the first design decision, which is what your hash function is going to be, and then we'll look at different hashing schemes, first, static, hashing schemes, so those are fixed size tables that are allocated versus dynamic hashing schemes which try to trade off this. This larger, or you know, kind of batch allocation versus more incremental allocation of space for the hash table so again, kind of the the idea behind a hash function is that for any input key we want to return some integer representation of that key. So we could be taking a key uh as an integer uh, the keys could be integers. We want to return an integer that represents some. You know hashed version of that key. It could be a string where you use. You know the different characters in the string to somehow compute your hash function. It could be an arbitrary data type of bytes. So basically, what we want to do is just take this input key and somehow return a hashed integer representation of that. So you may be familiar with like cryptographic, hash functions, uh. We don't want to use those for this case cryptographic. Hash functions have a lot of properties that are nice for uh, cryptography or cryptographic use cases, but uh they're, pretty slow, usually, and- and we don't need those properties for uh implementing the the hash tables inside of dbms. So basically, what we want is a hash function that is really fast to execute, so we want to be able to get the hash of our keys quickly and has a low collision rate. We don't want. You know a lot of. We don't want the hash function to return the same hash values for many different keys. So this is just a few popular hash functions. Crc64 has been around for a while. There are. There are fast implementations of this for modern cpus. I think it was originally used in networking like error, detection, uh computing and checkserror detection and networking kind of the the uh number of hash functions. Uh, for this type of use case seems to have exploded in the last. I don't know, 15 or or 10 15 20 years. I think, because, as more things have moved into memory, it's become increasingly important to have kind of these fast hash functions with a few collisions. So a lot of effort has been has been put into this one. Popular one is murmur hash. There are several different versions uh by now, and there's like murmur. 3 now is the the most recent version, but that's kind of designed as a fast general purpose, hash function, a lot of systems use that, and then there are. There are several from google facebook and other companies like that that are kind of designed uh for different use cases. So, for example, the city hash is designed to be faster for shorter keys. You think, like you know, email addresses or something that are smaller than 64 bytes. That google has a use case for so uh. There are kind of all these different, more specialized hash functions, but murmur hash is is a pretty popular one. So just as a uh.",
            "transcript-corrected": "In terms of the course today, we're going to talk about or start talking about how to support kind of the dbmss execution engine to read and write data from pages, so kind of we've been talking about the lower levels of the stack. Now we're going to move up the stack to, uh this, this access method, piece uh, we've already talked about disk manager and the buffer pool manager and how all that works uh. So now we're kind of right here in the middle and the two types of data structures. There are many others, especially if you take more advanced database courses or look into more advanced systems. There are many other types of data structures, pretty much the two fundamental ones and the ones we're going to cover in this course are hash tables and trees. So today, today we're going to be talking about hash tables, so data structures can be used in a whole bunch of different places in the DBMS and they're going to be used for a lot of different purposes. For example, they can be used to store internal metadata. We've seen some cases where we use different. You know either a page directory or a page table to kind of performing mappings between pages in their physical locations or tuples, and their physical locations we've seen kind of that use of them. They can be used for core data storage. So, for example, you could have, you know, pages or groups of pages organized as hash tables. So you could have your actual table organized as in in some sort of data structure. They could be used as temporary data structures, so you think about it like during query execution. There are different operations where you might want to build a data structure on the fly and then just kind of use that temporarily and then it gets used for the duration of the query, uh and then thrown away. So, for example, during like a hash join uh and finally, uh, we've talked a little bit about kind of how you can use data structures as table auxiliary table indexes. So you can kind of have your your core data storage in a table file and you can build an index on top of it to make accessing it a little bit easier, so kind of the two key design decisions that we need to make when, when designing data structures are the data organization? How have the data you known physically laid out? What are the different trade-offs? We need to consider there as well as concurrency. So we've talked a lot about you know. If you have multiple concurrent transactions or queries running in the system, how can you, uh ensure that the data or data structures are accessed or not modified uh concurrently, causing problems with multiple access? So we're first going to focus kind of on this organization piece just to to simplify the discussion, we're going to assume everything for the most part uh. There will be a few cases where we discuss concurrency, but for the most part, we're going to assume for now that everything's single threaded and then we'll talk kind of more about this multi-threaded stuff. When, when we discuss concurrency control in later lecture in the course so, as I said, today's lecture is going to be all about hash tables, so basically a hash table, I'm sure many of you may be familiar with it from, you know a data structures course or an algorithms course or something, but basically a hash table implements an associative array from you know some some key to some values. So you have a set of keys. You want to map them to some set of values, so you give the hash table a key. It gives you back the corresponding value associated with that key. The way it does, that is, it uses a hash function in order to compute uh, basically an index or an offset into some array for for a given key, and then you can retrieve the associated value with that key. So the space complexity for this is so n. It's scales with the size of the number of keys that you're storing and the time complex, uh time complexity, depending on how we implement it. The average time complexity is one and the worst case, the time complexity zone. We have to look at every single item in order to retrieve the find the key that we're looking for. So I you may know this. You know from from the theory perspective, but in practice a lot of times what we care about are the constants associated with this. So these, these have been perfectly fine, uh complexity, assessments, for you know the abstract idea of a hash table, but if you have, for example, on the order of a billion keys and there's a uh, you know, look up overhead of one second per key or something, even though it's constant time that that you know one second adds up a billion times. So we really need to care not just about the time complexity of these operations, but specifically about the kind of the constants. The constant factors that go along with each lookup, so kind of the easiest, most basic hash table that you can uh think about is just to allocate. You know this giant array that has one slot for every element or key that you want to store so, uh, for example, just think about the keys like integers and we have between 0 and n, and we want to you to know slot each key into an individual slot. We can do this by Modding the key by the number of elements that we're storing and then we can find the offset in the array. So, for example, let's say we have this these strings in here, so we have ABC null def so forth. The way that we can find these again is to to perform the hash that tells us brings us to the associated values stored with that key. So hash of the key noted by the number of elements in the array gives us the offset that that we're looking for, so there are some assumptions that this simple model makes. The first is that you know the number of elements that you want to store ahead of time, some cases that might be true. You know you know, I have a billion elements. I have a million elements, whatever it is. That's all I ever need to store in the hash table in a lot of cases. That might not be true, for example, if you think about a database table that, can you know grow arbitrarily large, so we may need to continue adding keys over time. Another assumption that's made here is that each key is unique, so you can't have, for example, duplicate keys, of course, in SQL, which is a bag or multi-set algebra. We allow these sorts of duplicate keys, so we that that assumption isn't isn't sufficient for for a lot of cases. And finally, this kind of assumes a perfect hash function. So here, if key one doesn't equal key too, then the hash of key one isn't going to equal a hash of q2. So that means each hash function uniquely maps a key to some position in this, uh array, which it's it's unrealistic uh to kind of devise a sort of this. This perfect hash function, that's not going to have any collisions. So when, when we're thinking about designing a more practical hash table, we have sort of these these two design decisions that we have to make- and this is what a hash table is at its score. The first design decision is what type of hash function are we going to use. So how are we going to map the large key space, potentially a really large key space? If you have, you know, really large, integers or strings or something? How can you map a very large key space into a much smaller domain, which is the array or or storage that you're storing it in uh? And finally, we want to have this kind of balance. This trade-off uh between being really fast to compute. So we can, you know, compute the hash really quickly versus having a lot of collisions. So you know if you, if you just take, for example, the identity function, that's really fast to compute. You don't have to do anything. You just return the key, but if you have a high number of duplicates in your data, then that's that's going to be end up with a lot of collisions in your your hash table. So that's kind of the first piece is the hash function and then the second. The second piece really has to do with collisions, which is what your hashing scheme is going to be. So how do you handle any collisions that are produced by your hash function and again kind of there's? This trade-off here in this case is  allocating a really large hash table. So you can trade off memory or disk depending on where, where your hash table lives, but you can kind of trade off space for additional instructions or performing additional work, compute time to to find and insert keys so kind of. In both of these cases, we have to consider away these trade-offs and a lot of the different schemes that we'll look at today will have different ways of balancing these, uh different tradeoffs, so uh, the this whole lecture is going to be about. You know kind of all the different aspects of building, uh hash tables, we're going to start again at the first, the first design decision, which is what your hash function is going to be, and then we'll look at different hashing schemes, first, static, hashing schemes, so those are fixed size tables that are allocated versus dynamic hashing schemes which try to trade off this. This larger, or you know, kind of batch allocation versus more incremental allocation of space for the hash table so again, kind of the idea behind a hash function is that for any input key we want to return some integer representation of that key. So we could be taking a key uh as an integer uh, the keys could be integers. We want to return an integer that represents some. You know hashed version of that key. It could be a string where you use. You know the different characters in the string to somehow compute your hash function. It could be an arbitrary data type of bytes. So basically, what we want to do is just take this input key and somehow return a hashed integer representation of that. So you may be familiar with like cryptography, hash functions, uh. We don't want to use those for this case cryptographic. Hash functions have a lot of properties that are nice for uh, cryptography or cryptographic use cases, but uh, they're, pretty slow, usually, and- and we don't need those properties for uh implementing the hash tables inside of DBMS. So basically, what we want is a hash function that is really fast to execute, so we want to be able to get the hash of our keys quickly and has a low collision rate. We don't want. You know a lot about. We don't want the hash function to return the same hash values for many different keys. So this is just a few popular hash functions. Crc64 has been around for a while. There are. There are fast implementations of this for modern CPUs. I think it was originally used in networking like error, detection, uh computing and checks error detection and networking kind of the uh number of hash functions. Uh, for this type of use case seems to have exploded in the last. I don't know, 15 or or 10 15 20 years. I think, because, as more things have moved into memory, it's become increasingly important to have kind of these fast hash functions with a few collisions. So a lot of effort has been has been put into this one. Popular one is murmur hash. There are several different versions uh by now, and there's like a murmur. 3 now is the most recent version, but that's kind of designed as a fast general purpose, hash function, a lot of systems use that, and then there are. There are several from google Facebook and other companies like that that is kind of designing uh for different use cases. So, for example, the city hash is designed to be faster for shorter keys. You think, like you know, email addresses or something that is smaller than 64 bytes. That google has a use case for so uh. There is kind of all these different, more specialized hash functions, but murmur hash is is a pretty popular one. So just as a uh.",
            "summary_brief": "Today we're going to be talking about data structures.",
            "summary_detailed": "In terms of the course today, we're going to talk about or start talking about how to support kind of the dbmss execution engine to read and write data from pages. Today's lecture is going to be all about hash tables, so basically a hash table, I'm sure many of you may be familiar with it from, you know a data structures course or an algorithms course or something.",
            "key_concepts": {
                "hash function": {
                    "Score": "0.8844156",
                    "Summary": "A hash function is any function that can be used to map data of arbitrary size to fixed-size values. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes.  The values are usually used to index a fixed-size table called a hash table. Use of a hash function to index a hash table is called hashing or scatter storage addressing.\nHash functions and their associated hash tables are used in data storage and retrieval applications to access data in a small and nearly constant time per retrieval. They require an amount of storage space only fractionally greater than the total space required for the data or records themselves. Hashing is a computationally and storage space-efficient form of data access that avoids the non-linear access time of ordered and unordered lists and structured trees, and the often exponential storage requirements of direct access of state spaces of large or variable-length keys.\nUse of hash functions relies on statistical properties of key and function interaction: worst-case behaviour is intolerably bad with a vanishingly small probability, and average-case behaviour can be nearly optimal (minimal collision).Hash functions are related to (and often confused with) checksums, check digits, fingerprints, lossy compression, randomization functions, error-correcting codes, and ciphers. Although the concepts overlap to some extent, each one has its own uses and requirements and is designed and optimized differently. The hash functions differ from the concepts numbered mainly in terms of data integrity.",
                    "URL": "https://en.wikipedia.org/wiki/Hash_function"
                },
                "number": {
                    "Score": "0.89985454",
                    "Summary": "A number is a mathematical object used to count, measure, and label. The original examples are the natural numbers 1, 2, 3, 4, and so forth. Numbers can be represented in language with number words. More universally, individual numbers can be represented by symbols, called numerals; for example, \"5\" is a numeral that represents the number five. As only a relatively small number of symbols can be memorized, basic numerals are commonly organized in a numeral system, which is an organized way to represent any number. The most common numeral system is the Hindu–Arabic numeral system, which allows for the representation of any number using a combination of ten fundamental numeric symbols, called digits. In addition to their use in counting and measuring, numerals are often used for labels (as with telephone numbers), for ordering (as with serial numbers), and for codes (as with ISBNs). In common usage, a numeral is not clearly distinguished from the number that it represents.\nIn mathematics, the notion of a number has been extended over the centuries to include 0, negative numbers, rational numbers such as one half \n  \n    \n      \n        \n          (\n          \n            \n              \n                1\n                2\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\tfrac {1}{2}}\\right)}\n  , real numbers such as the square root of 2 \n  \n    \n      \n        \n          (\n          \n            \n              2\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\sqrt {2}}\\right)}\n   and π, and complex numbers which extend the real numbers with a square root of −1 (and its combinations with real numbers by adding or subtracting its multiples). Calculations with numbers are done with arithmetical operations, the most familiar being addition, subtraction, multiplication, division, and exponentiation. Their study or usage is called arithmetic, a term which may also refer to number theory, the study of the properties of numbers.\nBesides their practical uses, numbers have cultural significance throughout the world. For example, in Western society, the number 13 is often regarded as unlucky, and \"a million\" may signify \"a lot\" rather than an exact quantity. Though it is now regarded as pseudoscience, belief in a mystical significance of numbers, known as numerology, permeated ancient and medieval thought. Numerology heavily influenced the development of Greek mathematics, stimulating the investigation of many problems in number theory which are still of interest today.During the 19th century, mathematicians began to develop many different abstractions which share certain properties of numbers, and may be seen as extending the concept. Among the first were the hypercomplex numbers, which consist of various extensions or modifications of the complex number system. In modern mathematics, number systems (sets) are considered important special examples of more general categories such as rings and fields, and the application of the term \"number\" is a matter of convention, without fundamental significance.",
                    "URL": "https://en.wikipedia.org/wiki/Number"
                },
                "use case": {
                    "Score": "0.82267773",
                    "Summary": "In software and systems engineering, the phrase use case is a polyseme with two senses:\n\nA usage scenario for a piece of software; often used in the plural to suggest situations where a piece of software may be useful.\nA potential scenario in which a system receives an external request (such as user input) and responds to it.This article discusses the latter sense.\nA use case is a list of actions or event steps typically defining the interactions between a role (known in the Unified Modeling Language (UML) as an actor) and a system to achieve a goal. The actor can be a human or other external system. In systems engineering, use cases are used at a higher level than within software engineering, often representing missions or stakeholder goals. The detailed requirements may then be captured in the Systems Modeling Language (SysML) or as contractual statements.",
                    "URL": "https://en.wikipedia.org/wiki/Use_case"
                },
                "model": {
                    "Score": "0.9205821",
                    "Summary": "A model is an informative representation of an object, person or system. The term originally denoted the plans of a building in late 16th-century English, and derived via French and Italian ultimately from Latin modulus, a measure. \nRepresentational models can be broadly divided into the concrete (e.g. physical form) and the abstract (e.g. mathematical expressions describing behavioural patterns). Of particular importance in the modern context, conceptual models are central to philosophy of science, as almost every scientific theory effectively embeds some kind of model of the physical or human sphere. \nIn commerce, a model might instead reference a specific version or configuration of a product offering, rather than functioning as a representation of something else. \nIn taxonomic settings (e.g. biology, architecture, art) a model is sometimes a particular instance of a set of related entities (species, built structures, artistic compositions) chosen as a convenient reference point around which to build discourse; such a model is almost always chosen to typify some central tendency of the group, exemplify the group's defining characteristic, or reify the group's historical lineage. \nKinds of models include:\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Model"
                },
                "property": {
                    "Score": "0.91210973",
                    "Summary": "Property (Latin: Res privata) in the abstract is what belongs to or with something, whether as an attribute or as a component of said thing. In the context of this article, it is one or more components (rather than attributes), whether physical or incorporeal, of a person's estate; or so belonging to, as in being owned by, a person or jointly a group of people or a legal entity like a corporation or even a society. Depending on the nature of the property, an owner of property has the right to consume, alter, share, redefine, rent, mortgage, pawn, sell, exchange, transfer, give away or destroy it, or to exclude others from doing these things, as well as to perhaps abandon it; whereas regardless of the nature of the property, the owner thereof has the right to properly use it (as a durable, mean or factor, or whatever), or at the very least exclusively keep it.\nIn economics and political economy, there are three broad forms of property: private property, public property, and collective property (also called cooperative property). Property that jointly belongs to more than one party may be possessed or controlled thereby in very similar or very distinct ways, whether simply or complexly, whether equally or unequally. However, there is an expectation that each party's will (rather discretion) with regard to the property be clearly defined and unconditional, so as to distinguish ownership and easement from rent. The parties might expect their wills to be unanimous, or alternately every given one of them, when no opportunity for or possibility of dispute with any other of them exists, may expect his, her, its or their own will to be sufficient and absolute. The Restatement (First) of Property defines property as anything, tangible or intangible whereby a legal relationship between persons and the state enforces a possessory interest or legal title in that thing. This mediating relationship between individual, property and state is called a property regime.In sociology and anthropology, property is often defined as a relationship between two or more individuals and an object, in which at least one of these individuals holds a bundle of rights over the object. The distinction between \"collective property\" and \"private property\" is regarded as a confusion since different individuals often hold differing rights over a single object.Types of property include real property (the combination of land and any improvements to or on the land), personal property (physical possessions belonging to a person), private property (property owned by legal persons, business entities or individual natural persons), public property (state owned or publicly owned and available possessions) and intellectual property (exclusive rights over artistic creations, inventions, etc.), although the last is not always as widely recognized or enforced. An article of property may have physical and incorporeal parts. A title, or a right of ownership, establishes the relation between the property and other persons, assuring the owner the right to dispose of the property as the owner sees fit. The unqualified term \"property\" is often used to refer specifically to real property.",
                    "URL": "https://en.wikipedia.org/wiki/Property"
                },
                "system": {
                    "Score": "0.847416",
                    "Summary": "A system is a group of interacting or interrelated elements that act according to a set of rules to form a unified whole. A system, surrounded and influenced by its environment, is described by its boundaries, structure and purpose and expressed in its functioning. Systems are the subjects of study of systems theory.",
                    "URL": "https://en.wikipedia.org/wiki/System"
                },
                "core data": {
                    "Score": "0.90725243",
                    "Summary": "Core Data is an object graph and persistence framework provided by Apple in the macOS and iOS operating systems. It was introduced in Mac OS X 10.4 Tiger and iOS with iPhone SDK 3.0. It allows data organized by the relational entity–attribute model to be serialized into XML, binary, or SQLite stores. The data can be manipulated using higher level objects representing entities and their relationships. Core Data manages the serialized version, providing object lifecycle and object graph management, including persistence. Core Data interfaces directly with SQLite, insulating the developer from the underlying SQL.Just as Cocoa Bindings handle many of the duties of the controller in a model–view–controller design, Core Data handles many of the duties of the data model. Among other tasks, it handles change management, serializing to disk, memory footprint minimization and queries against the data.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Core_Data"
                },
                "data structure": {
                    "Score": "0.8963382",
                    "Summary": "In computer science, a data structure is a data organization, management, and storage format that enables efficient access and modification. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data, i.e., it is an algebraic structure about data.",
                    "URL": "https://en.wikipedia.org/wiki/Data_structure"
                },
                "location": {
                    "Score": "0.9030089",
                    "Summary": "In geography, location or place are used to denote a region (point, line, or area) on Earth’s surface or elsewhere. The term location generally implies a higher degree of certainty than place, the latter often indicating an entity with an ambiguous boundary, relying more on human or social attributes of place identity and sense of place than on geometry.",
                    "URL": "https://en.wikipedia.org/wiki/Location"
                },
                "collision": {
                    "Score": "0.8543846",
                    "Summary": "In physics, a collision is any event in which two or more bodies exert forces on each other in a relatively short time. Although the most common use of the word collision refers to incidents in which two or more objects collide with great force, the scientific use of the term implies nothing about the magnitude of the force.Some examples of physical interactions that scientists would consider collisions are the following:\n\nWhen an insect lands on a plant's leaf, its legs are said to collide with the leaf.\nWhen a cat strides across a lawn, each contact that its paws make with the ground is considered a collision, as well as each brush of its fur against a blade of grass.\nWhen a boxer throws a punch, their fist is said to collide with the opponent's body.\nWhen an astronomical object merges with a black hole, they are considered to collide.Some colloquial uses of the word collision are the following:\n\nA traffic collision involves at least one automobile.\nA mid-air collision occurs between airplanes.\nA ship collision accurately involves at least two moving maritime vessels hitting each other; the related term, allision, describes when a moving ship strikes a stationary object (often, but not always, another ship).In physics, collisions can be classified by the change in the total kinetic energy of the system before and after the collision:\n\nIf most or all of the total kinetic energy is lost (dissipated as heat, sound, etc. or absorbed by the objects themselves), the collision is said to be inelastic; such collisions involve objects coming to a full stop. An example of such a collision is a car crash, as cars crumple inward when crashing, rather than bouncing off of each other. This is by design, for the safety of the occupants and bystanders should a crash occur - the frame of the car absorbs the energy of the crash instead.\nIf most of the kinetic energy is conserved (i.e. the objects continue moving afterwards), the collision is said to be elastic. An example of this is a baseball bat hitting a baseball - the kinetic energy of the bat is transferred to the ball, greatly increasing the ball's velocity. The sound of the bat hitting the ball represents the loss of energy.\nAnd if all of the total kinetic energy is conserved (i.e. no energy is released as sound, heat, etc.), the collision is said to be perfectly elastic. Such a system is an idealization and cannot occur in reality, due to the second law of thermodynamics.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Collision"
                },
                "perfect hash function": {
                    "Score": "0.88898015",
                    "Summary": "In computer science, a perfect hash function h for a set S is a hash function that maps distinct elements in S to a set of m integers, with no collisions. In mathematical terms, it is an injective function.\nPerfect hash functions may be used to implement a lookup table with constant worst-case access time. A perfect hash function can, as any hash function, be used to implement hash tables, with the advantage that no collision resolution has to be implemented. In addition, if the keys are not the data and if it is known that queried keys will be valid, then the keys do not need to be stored in the lookup table, saving space.\nDisadvantages of perfect hash functions are that S needs to be known for the construction of the perfect hash function. Non-dynamic perfect hash functions need to be re-constructed if S changes. For frequently changing S dynamic perfect hash functions may be used at the cost of additional space. The space requirement to store the perfect hash function is in O(n).\nThe important performance parameters for perfect hash functions are the evaluation time, which should be constant, the construction time, and the representation size.",
                    "URL": "https://en.wikipedia.org/wiki/Perfect_hash_function"
                },
                "familiar": {
                    "Score": "0.88737667",
                    "Summary": "In European folklore of the medieval and early modern periods, familiars (sometimes referred to as familiar spirits) were believed to be supernatural entities that would assist witches and cunning folk in their practice of magic. According to records of the time, those alleging to have had contact with familiar spirits reported that they could manifest as numerous forms, usually as an animal, but sometimes as a human or humanoid figure, and were described as \"clearly defined, three-dimensional... forms, vivid with colour and animated with movement and sound\", as opposed to descriptions of ghosts with their \"smoky, undefined form[s]\".When they served witches, they were often thought to be malevolent, but when working for cunning folk they were often considered benevolent (although there was some ambiguity in both cases). The former were often categorized as demons, while the latter were more commonly thought of and described as fairies. The main purpose of familiars was to serve the witch or young witch, providing protection for them as they came into their new powers.Since the 20th century some magical practitioners, including adherents of the Neopagan religion of Wicca, use the concept of familiars, due to their association with older forms of magic. These contemporary practitioners use pets or wildlife, or believe that invisible versions of familiars act as magical aids.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Familiar"
                },
                "city": {
                    "Score": "0.88737667",
                    "Summary": "A city is a large human settlement. It can be defined as a permanent and densely settled place with administratively defined boundaries whose members work primarily on non-agricultural tasks. Cities generally have extensive systems for housing, transportation, sanitation, utilities, land use, production of goods, and communication. Their density facilitates interaction between people, government organisations and businesses, sometimes benefiting different parties in the process, such as improving efficiency of goods and service distribution.\nHistorically, city-dwellers have been a small proportion of humanity overall, but following two centuries of unprecedented and rapid urbanization, more than half of the world population now lives in cities, which has had profound consequences for global sustainability. Present-day cities usually form the core of larger metropolitan areas and urban areas—creating numerous commuters traveling towards city centres for employment, entertainment, and education. However, in a world of intensifying globalisation, all cities are to varying degrees also connected globally beyond these regions. This increased influence means that cities also have significant influences on global issues, such as sustainable development, global warming and global health. Because of these major influences on global issues, the international community has prioritized investment in sustainable cities through Sustainable Development Goal 11. Due to the efficiency of transportation and the smaller land consumption, dense cities hold the potential to have a smaller ecological footprint per inhabitant than more sparsely populated areas. Therefore, compact cities are often referred to as a crucial element of fighting climate change. However, this concentration can also have significant negative consequences, such as forming urban heat islands, concentrating pollution, and stressing water supplies and other resources.\nOther important traits of cities besides population include the capital status and relative continued occupation of the city. For example, country capitals such as Beijing, London, Mexico City, Moscow, Nairobi, New Delhi, Paris, Rome, Athens, Seoul, Tokyo, and Washington, D.C. reflect the identity and apex of their respective nations. Some historic capitals, such as Kyoto, maintain their reflection of cultural identity even without modern capital status. Religious holy sites offer another example of capital status within a religion, Jerusalem, Mecca, Varanasi, Ayodhya, Haridwar and Prayagraj each hold significance. The cities of Jericho, Faiyum, Damascus, Athens, Aleppo and Argos are among those laying claim to the longest continual inhabitation.",
                    "URL": "https://en.wikipedia.org/wiki/City"
                },
                "data storage": {
                    "Score": "0.8813673",
                    "Summary": "Data storage is the recording (storing) of information (data) in a storage medium. Handwriting, phonographic recording, magnetic tape, and optical discs are all examples of storage media. Some authors even propose that DNA is a natural data storage mechanism. Recording may be accomplished with virtually any form of energy. Electronic data storage requires electrical power to store and retrieve data. \nData storage in a digital, machine-readable medium is sometimes called digital data. Computer data storage is one of the core functions of a general-purpose computer. Electronic documents can be stored in much less space than paper documents. Barcodes and magnetic ink character recognition (MICR) are two ways of recording machine-readable data on paper.",
                    "URL": "https://en.wikipedia.org/wiki/Data_storage"
                },
                "data type": {
                    "Score": "0.8747806",
                    "Summary": "In computer science and computer programming, a data type or simply type is an attribute of data which tells the compiler or interpreter how the programmer intends to use the data. Most programming languages support basic data types of integer numbers (of varying sizes), floating-point numbers (which approximate real numbers), characters and Booleans. A data type constrains the values that an expression, such as a variable or a function, might take. This data type defines the operations that can be done on the data, the meaning of the data, and the way values of that type can be stored. A data type provides a set of values from which an expression (i.e. variable, function, etc.) may take its values.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Data_type"
                },
                "algorithm": {
                    "Score": "0.87295854",
                    "Summary": "In mathematics and computer science, an algorithm ( (listen)) is a finite sequence of well-defined instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations, data processing, automated reasoning, automated decision-making and other tasks. In contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.As an effective method, an algorithm can be expressed within a finite amount of space and time, and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.",
                    "URL": "https://en.wikipedia.org/wiki/Algorithm"
                },
                "implementation": {
                    "Score": "0.8723101",
                    "Summary": "Implementation is the realization of an application, or execution of a plan, idea, model, design, specification, standard, algorithm, or policy.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Implementation"
                },
                "organization": {
                    "Score": "0.8710945",
                    "Summary": "An organization, or organisation (Commonwealth English; see spelling differences), is an entity—such as a company, an institution, or an association—comprising one or more people and having a particular purpose.\nThe word is derived from the Greek word organon, which means tool or instrument, musical instrument, and organ.",
                    "URL": "https://en.wikipedia.org/wiki/Organization"
                },
                "error": {
                    "Score": "0.86943245",
                    "Summary": "An error (from the Latin error, meaning \"wandering\") is an action which is inaccurate or incorrect. In some usages, an error is synonymous with a mistake.\nIn statistics, \"error\" refers to the difference between the value which has been computed and the correct value. An error could result in failure or in a deviation from the intended performance or behavior.",
                    "URL": "https://en.wikipedia.org/wiki/Error"
                },
                "integer": {
                    "Score": "0.86251825",
                    "Summary": "An integer (from the Latin integer meaning \"whole\") is colloquially defined as a number that can be written without a fractional component. For example, 21, 4, 0, and −2048 are integers, while 9.75, 5+1/2, and √2 are not.\nThe set of integers consists of zero (0), the positive natural numbers (1, 2, 3, ...), also called whole numbers or counting numbers, and their additive inverses (the negative integers, i.e., −1, −2, −3, ...). The set of integers is often denoted by the boldface (Z) or blackboard bold \n  \n    \n      \n        (\n        \n          Z\n        \n        )\n      \n    \n    {\\displaystyle (\\mathbb {Z} )}\n   letter \"Z\"—standing originally for the German word Zahlen (\"numbers\").\n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n   is a subset of the set of all rational numbers \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  , which in turn is a subset of the real numbers \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  .  Like the natural numbers, \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n   is countably infinite.\nThe integers form the smallest group and the smallest ring containing the natural numbers. In algebraic number theory, the integers are sometimes qualified as rational integers to distinguish them from the more general algebraic integers. In fact, (rational) integers are algebraic integers that are also rational numbers.",
                    "URL": "https://en.wikipedia.org/wiki/Integer"
                },
                "several": {
                    "Score": "0.8655333",
                    "Summary": "",
                    "URL": "https://en.wikipedia.org/wiki/Several"
                },
                "address": {
                    "Score": "0.86528057",
                    "Summary": "An address is a collection of information, presented in a mostly fixed format, used to give the location of a building, apartment, or other structure or a plot of land, generally using political boundaries and street names as references, along with other identifiers such as house or apartment numbers and organization name. Some addresses also contain special codes, such as a postal code, to make identification easier and aid in the routing of mail.\nAddresses provide a means of physically locating a building.  They are used in identifying buildings as the end points of a postal system and as parameters in statistics collection, especially in census-taking and the insurance industry.\nAddress formats are different in different places, and unlike latitude and longitude coordinates, there is no simple mapping from an address to a location.",
                    "URL": "https://en.wikipedia.org/wiki/Address"
                },
                "individual": {
                    "Score": "0.86251825",
                    "Summary": "An individual is that which exists as a distinct entity. Individuality (or self-hood) is the state or quality of being an individual; particularly (in the case of humans) of being a person unique from other people and possessing one's own  needs or goals, rights and  responsibilities. The concept of an individual features in diverse fields, including biology, law, and philosophy.",
                    "URL": "https://en.wikipedia.org/wiki/Individual"
                },
                "array": {
                    "Score": "0.86157566",
                    "Summary": "An array is a systematic arrangement of similar objects, usually in rows and columns.\nThings called an array include:\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Array"
                },
                "concurrency control": {
                    "Score": "0.86141896",
                    "Summary": "In information technology and computer science,  especially in the fields of computer programming, operating systems, multiprocessors, and databases, concurrency control ensures that correct results for concurrent operations are generated, while getting those results as quickly as possible.\nComputer systems, both software and hardware, consist of modules, or components. Each component is designed to operate correctly, i.e., to obey or to meet certain consistency rules. When components that operate concurrently interact by messaging or by sharing accessed data (in memory or storage), a certain component's consistency may be violated by another component. The general area of concurrency control provides rules, methods, design methodologies, and theories to maintain the consistency of components operating concurrently while interacting, and thus the consistency and correctness of the whole system. Introducing concurrency control into a system means applying operation constraints which typically result in some performance reduction. Operation consistency and correctness should be achieved with as good as possible efficiency, without reducing performance below reasonable levels. Concurrency control can require significant additional complexity and overhead in a concurrent algorithm compared to the simpler sequential algorithm.\nFor example, a failure in concurrency control can result in data corruption from torn read or write operations.",
                    "URL": "https://en.wikipedia.org/wiki/Concurrency_control"
                },
                "tree": {
                    "Score": "0.8596199",
                    "Summary": "In botany, a tree is a perennial plant with an elongated stem, or trunk, supporting branches and leaves in most species. In some usages, the definition of a tree may be narrower, including only wood plants with secondary growth, plants that are usable as lumber or plants above a specified height. In wider definitions, the taller palms, tree ferns, bananas, and bamboos are also trees. Trees are not a taxonomic group but include a variety of plant species that have independently evolved a trunk and branches as a way to tower above other plants to compete for sunlight. Trees tend to be long-lived, some reaching several thousand years old. Trees have been in existence for 370 million years. It is estimated that there are some three trillion mature trees in the world.A tree typically has many secondary branches supported clear of the ground by the trunk. This trunk typically contains woody tissue for strength, and vascular tissue to carry materials from one part of the tree to another. For most trees it is surrounded by a layer of bark which serves as a protective barrier. Below the ground, the roots branch and spread out widely; they serve to anchor the tree and extract moisture and nutrients from the soil. Above ground, the branches divide into smaller branches and shoots. The shoots typically bear leaves, which capture light energy and convert it into sugars by photosynthesis, providing the food for the tree's growth and development.\nTrees usually reproduce using seeds. Flowers and fruit may be present, but some trees, such as conifers, instead have pollen cones and seed cones. Palms, bananas, and bamboos also produce seeds, but tree ferns produce spores instead.\nTrees play a significant role in reducing erosion and moderating the climate. They remove carbon dioxide from the atmosphere and store large quantities of carbon in their tissues. Trees and forests provide a habitat for many species of animals and plants. Tropical rainforests are among the most biodiverse habitats in the world. Trees provide shade and shelter, timber for construction, fuel for cooking and heating, and fruit for food as well as having many other uses. In parts of the world, forests are shrinking as trees are cleared to increase the amount of land available for agriculture. Because of their longevity and usefulness, trees have always been revered, with sacred groves in various cultures, and they play a role in many of the world's mythologies.",
                    "URL": "https://en.wikipedia.org/wiki/Tree"
                },
                "associative array": {
                    "Score": "0.8596199",
                    "Summary": "In computer science, an associative array, map, symbol table, or dictionary is an abstract data type composed of a collection of (key, value) pairs, such that each possible key appears at most once in the collection.  Not to be confused with Associative Processors\nOperations associated with this data type allow to:\nadd a pair to the collection;\nremove a pair from the collection;\nmodify an existing pair;\nlookup a value associated with a particular key.Implementing associative arrays poses the dictionary problem, a classic computer science problem: the task of designing a data structure that maintains a set of data during 'search', 'delete', and 'insert' operations.\nThe two major solutions to the dictionary problem are a hash table and a search tree.\nIn some cases it is also possible to solve the problem using directly addressed arrays, binary search trees, or other more specialized structures.\nMany programming languages include associative arrays as primitive data types, and they are available in software libraries for many others. Content-addressable memory is a form of direct hardware-level support for associative arrays.\nAssociative arrays have many applications including such fundamental programming patterns as memoization and the decorator pattern.The name does not come from the associative property known in mathematics. Rather, it arises from the fact that we associate values with keys.",
                    "URL": "https://en.wikipedia.org/wiki/Associative_array"
                },
                "access method": {
                    "Score": "0.85871637",
                    "Summary": "An access method is a function of a mainframe operating system that enables access to data on disk, tape or other external devices. Access methods were present in several mainframe operating systems since the late 1950s, under a variety of names; the name access method was introduced in 1963 in the IBM OS/360 operating system. Access methods provide an application programming interface (API) for programmers to transfer data to or from device, and could be compared to device drivers in non-mainframe operating systems, but typically provide a greater level of functionality.",
                    "URL": "https://en.wikipedia.org/wiki/Access_method"
                },
                "second": {
                    "Score": "0.85871637",
                    "Summary": "The second (symbol: s, also abbreviated: sec) is the base unit of time in the International System of Units (SI) (French: Système International d’unités), commonly understood and historically defined as 1⁄86400 of a day – this factor derived from the division of the day first into 24 hours, then to 60 minutes and finally to 60 seconds each. Analog clocks and watches often have sixty tick marks on their faces, representing seconds (and minutes), and a \"second hand\" to mark the passage of time in seconds.  Digital clocks and watches often have a two-digit seconds counter. The second is also part of several other units of measurement like meters per second for speed, meters per second per second for acceleration, and cycles per second for frequency.\n\nAlthough the historical definition of the unit was based on this division of the Earth's rotation cycle, the formal definition in the International System of Units (SI) is a much steadier timekeeper:The second is defined as being equal to the time duration of 9,192,631,770 periods of the radiation corresponding to the transition between the two hyperfine levels of the fundamental unperturbed ground-state of the caesium-133 atom.\nBecause the Earth's rotation varies and is also slowing very slightly, a leap second is added at irregular intervals to clock time to keep clocks in sync with Earth's rotation.\nMultiples of seconds are usually counted in hours and minutes. Fractions of a second are usually counted in tenths or hundredths. In scientific work, small fractions of a second are counted in milliseconds (thousandths), microseconds (millionths), nanoseconds (billionths), and sometimes smaller units of a second. An everyday experience with small fractions of a second is a 1-gigahertz microprocessor which has a cycle time of 1 nanosecond. Camera shutter speeds are often expressed in fractions of a second, such as 1⁄30 second or 1⁄1000 second.\nSexagesimal divisions of the day from a calendar based on astronomical observation have existed since the third millennium BC, though they were not seconds as we know them today. Small divisions of time could not be measured back then, so such divisions were mathematically derived. The first timekeepers that could count seconds accurately were pendulum clocks invented in the 17th century. Starting in the 1950s, atomic clocks became better timekeepers than Earth's rotation, and they continue to set the standard today.",
                    "URL": "https://en.wikipedia.org/wiki/Second"
                },
                "building": {
                    "Score": "0.85296994",
                    "Summary": "A building, or edifice, is a structure with a roof and walls standing more or less permanently in one place, such as a house or factory. Buildings come in a variety of sizes, shapes, and functions, and have been adapted throughout history for a wide number of factors, from building materials available, to weather conditions, land prices, ground conditions, specific uses, and aesthetic reasons. To better understand the term building compare the list of nonbuilding structures.\nBuildings serve several societal needs – primarily as shelter from weather, security, living space, privacy, to store belongings, and to comfortably live and work. A building as a shelter represents a physical division of the human habitat (a place of comfort and safety) and the outside (a place that at times may be harsh and harmful).\nEver since the first cave paintings, buildings have also become objects or canvasses of much artistic expression. In recent years, interest in sustainable planning and building practices has also become an intentional part of the design process of many new buildings and other structures.",
                    "URL": "https://en.wikipedia.org/wiki/Building"
                },
                "lecture": {
                    "Score": "0.8528803",
                    "Summary": "A lecture (from the Greek lecture, meaning reading) is an oral presentation intended to present information or teach people about a particular subject, for example by a university or college teacher. Lectures are used to convey critical information, history, background, theories, and equations. A politician's speech, a minister's sermon, or even a business person’s sales presentation may be similar in form to a lecture.  Usually the lecturer will stand at the front of the room and recite information relevant to the lecture's content.\nThough lectures are much criticised as a teaching method, universities have not yet found practical alternative teaching methods for the large majority of their courses.  Critics point out that lecturing is mainly a one-way method of communication that does not involve significant audience participation but relies upon passive learning.  Therefore, lecturing is often contrasted to active learning. Lectures delivered by talented speakers can be highly stimulating; at the very least, lectures have survived in academia as a quick, cheap, and efficient way of introducing large numbers of students to a particular field of study.\nLectures have a significant role outside the classroom, as well. Academic and scientific awards routinely include a lecture as part of the honor, and academic conferences often center on \"keynote addresses\", i.e., lectures. The public lecture has a long history in the sciences and in social movements. Union halls, for instance, historically have hosted numerous free and public lectures on a wide variety of matters. Similarly, churches, community centers, libraries, museums, and other organizations have hosted lectures in furtherance of their missions or their constituents' interests. Lectures represent a continuation of oral tradition in contrast to textual communication in books and other media. Lectures may be considered a type of grey literature.",
                    "URL": "https://en.wikipedia.org/wiki/Lecture"
                },
                "hash table": {
                    "Score": "0.83768207",
                    "Summary": "In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index, also called a hash code, into an array of buckets or slots, from which the desired value can be found. During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored.\nIdeally, the hash function will assign each key to a unique bucket, but most hash table designs employ an imperfect hash function, which might cause hash collisions where the hash function generates the same index for more than one key. Such collisions are typically accommodated in some way.\nIn a well-dimensioned hash table, the average cost (number of instructions) for each lookup is independent of the number of elements stored in the table. Many hash table designs also allow arbitrary insertions and deletions of key–value pairs, at (amortized) constant average cost per operation.In many situations, hash tables turn out to be on average more efficient than search trees or any other table lookup structure. For this reason, they are widely used in many kinds of computer software, particularly for associative arrays, database indexing, caches, and sets.",
                    "URL": "https://en.wikipedia.org/wiki/Hash_table"
                },
                "company": {
                    "Score": "0.8454181",
                    "Summary": "A company, abbreviated as co., is a legal entity representing an association of people, whether natural, legal or a mixture of both, with a specific objective. Company members share a common purpose and unite to achieve specific, declared goals. Companies take various forms, such as:\n\nvoluntary associations, which may include nonprofit organizations\nbusiness entities, whose aim is generating profit\nfinancial entities and banks\nprograms or educational institutions.A company can be created as a legal person so that the company itself has limited liability as members perform or fail to discharge their duty according to the publicly declared incorporation, or published policy. When a company closes, it may need to be liquidated to avoid further legal obligations.\nCompanies may associate and collectively register themselves as new companies; the resulting entities are often known as corporate groups.",
                    "URL": "https://en.wikipedia.org/wiki/Company"
                },
                "year": {
                    "Score": "0.842415",
                    "Summary": "A year is the orbital period of a planetary body, for example, the Earth, moving in its orbit around the Sun. Due to the Earth's axial tilt, the course of a year sees the passing of the seasons, marked by change in weather, the hours of daylight, and, consequently, vegetation and soil fertility. In temperate and subpolar regions around the planet, four seasons are generally recognized: spring, summer, autumn and winter. In tropical and subtropical regions, several geographical sectors do not present defined seasons; but in the seasonal tropics, the annual wet and dry seasons are recognized and tracked.\nA calendar year is an approximation of the number of days of the Earth's orbital period, as counted in a given calendar. The Gregorian calendar, or modern calendar, presents its calendar year to be either a common year of 365 days or a leap year of 366 days, as do the Julian calendars (see below). For the Gregorian calendar, the average length of the calendar year (the mean year) across the complete leap cycle of 400 years is 365.2425 days. In English, the abbreviations \"y\" and \"yr\" are commonly used (\"a\" is also used) for the unit of time, though its exact duration may be inconsistent.\nIn astronomy, the Julian year is a unit of time; it is defined as 365.25 days of exactly 86,400 seconds (SI base unit), totalling exactly 31,557,600 seconds in the Julian astronomical year.The word year is also used for periods loosely associated with, but not identical to, the calendar or astronomical year, such as the seasonal year, the fiscal year, the academic year, etc. Similarly, year can mean the orbital period of any planet; for example, a Martian year and a Venusian year are examples of the time a planet takes to transit one complete orbit. The term can also be used in reference to any long period or cycle, such as the Great Year.",
                    "URL": "https://en.wikipedia.org/wiki/Year"
                },
                "space complexity": {
                    "Score": "0.84171265",
                    "Summary": "The space complexity of an algorithm or a computer program is the amount of memory space required to solve an instance of the computational problem as a function of characteristics of the input. It is the memory required by an algorithm until it executes completely.Similar to time complexity, space complexity is often expressed asymptotically in big O notation, such as \n  \n    \n      \n        O\n        (\n        n\n        )\n        ,\n      \n    \n    {\\displaystyle O(n),}\n  \n\n  \n    \n      \n        O\n        (\n        n\n        log\n        ⁡\n        n\n        )\n        ,\n      \n    \n    {\\displaystyle O(n\\log n),}\n   \n  \n    \n      \n        O\n        (\n        \n          n\n          \n            α\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle O(n^{\\alpha }),}\n   \n  \n    \n      \n        O\n        (\n        \n          2\n          \n            n\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle O(2^{n}),}\n   etc., where n is a characteristic of the input influencing space complexity.",
                    "URL": "https://en.wikipedia.org/wiki/Space_complexity"
                },
                "time complexity": {
                    "Score": "0.83613205",
                    "Summary": "In computer science, the time complexity is the computational complexity that describes the amount of computer time it takes to run an algorithm. Time complexity is commonly estimated by counting the number of elementary operations performed by the algorithm, supposing that each elementary operation takes a fixed amount of time to perform. Thus, the amount of time taken and the number of elementary operations performed by the algorithm are taken to be related by a constant factor.\nSince an algorithm's running time may vary among different inputs of the same size, one commonly considers the worst-case time complexity, which is the maximum amount of time required for inputs of a given size. Less common, and usually specified explicitly, is the average-case complexity, which is the average of the time taken on inputs of a given size (this makes sense because there are only a finite number of possible inputs of a given size). In both cases, the time complexity is generally expressed as a function of the size of the input.: 226  Since this function is generally difficult to compute exactly, and the running time for small inputs is usually not consequential, one commonly focuses on the behavior of the complexity when the input size increases—that is, the asymptotic behavior of the complexity. Therefore, the time complexity is commonly expressed using big O notation, typically \n  \n    \n      \n        O\n        (\n        n\n        )\n      \n    \n    {\\displaystyle O(n)}\n  , \n  \n    \n      \n        O\n        (\n        n\n        log\n        ⁡\n        n\n        )\n      \n    \n    {\\displaystyle O(n\\log n)}\n  , \n  \n    \n      \n        O\n        (\n        \n          n\n          \n            α\n          \n        \n        )\n      \n    \n    {\\displaystyle O(n^{\\alpha })}\n  , \n  \n    \n      \n        O\n        (\n        \n          2\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle O(2^{n})}\n  , etc., where n is the size in units of bits needed to represent the input.\nAlgorithmic complexities are classified according to the type of function appearing in the big O notation. For example, an algorithm with time complexity \n  \n    \n      \n        O\n        (\n        n\n        )\n      \n    \n    {\\displaystyle O(n)}\n   is a linear time algorithm and an algorithm with time complexity \n  \n    \n      \n        O\n        (\n        \n          n\n          \n            α\n          \n        \n        )\n      \n    \n    {\\displaystyle O(n^{\\alpha })}\n   for some constant \n  \n    \n      \n        α\n        >\n        1\n      \n    \n    {\\displaystyle \\alpha >1}\n   is a polynomial time algorithm.",
                    "URL": "https://en.wikipedia.org/wiki/Time_complexity"
                },
                "tuple": {
                    "Score": "0.82893074",
                    "Summary": "In mathematics, a tuple is a finite ordered list (sequence) of elements.  An n-tuple is a sequence (or ordered list) of n elements, where n is a non-negative integer. There is only one 0-tuple, referred to as the empty tuple. An n-tuple is defined inductively using the construction of an ordered pair.\nMathematicians usually write tuples by listing the elements within parentheses \"( )\" and separated by commas; for example, (2, 7, 4, 1, 7) denotes a 5-tuple. Sometimes other symbols are used to surround the elements, such as square brackets \"[ ]\" or angle brackets \"⟨ ⟩\". Braces \"{ }\" are used to specify arrays in some programming languages but not in mathematical expressions, as they are the standard notation for sets. The term tuple can often occur when discussing other mathematical objects, such as vectors.\nIn computer science, tuples come in many forms. Most typed functional programming languages implement tuples directly as product types, tightly associated with algebraic data types, pattern matching, and destructuring assignment. Many programming languages offer an alternative to tuples, known as record types, featuring unordered elements accessed by label. A few programming languages combine ordered tuple product types and unordered record types into a single construct, as in C structs and Haskell records. Relational databases may formally identify their rows (records) as tuples.\nTuples also occur in relational algebra; when programming the semantic web  with the Resource Description Framework (RDF); in linguistics; and in philosophy.",
                    "URL": "https://en.wikipedia.org/wiki/Tuple"
                },
                "theory": {
                    "Score": "0.82555324",
                    "Summary": "A theory is a rational type of abstract thinking about a phenomenon, or the results of such thinking. The process of contemplative and rational thinking is often associated with such processes as observational study or research. Theories may be scientific, belong to a non-scientific discipline, or no discipline at all. Depending on the context, a theory's assertions might, for example, include generalized explanations of how nature works. The word has its roots in ancient Greek, but in modern use it has taken on several related meanings.\nIn modern science, the term \"theory\" refers to scientific theories, a well-confirmed type of explanation of nature, made in a way consistent with the scientific method, and fulfilling the criteria required by modern science. Such theories are described in such a way that scientific tests should be able to provide empirical support for it, or empirical contradiction (\"falsify\") of it. Scientific theories are the most reliable, rigorous, and comprehensive form of scientific knowledge, in contrast to more common uses of the word \"theory\" that imply that something is unproven or speculative (which in formal terms is better characterized by the word hypothesis). Scientific theories are distinguished from hypotheses, which are individual empirically testable conjectures, and from scientific laws, which are descriptive accounts of the way nature behaves under certain conditions.\nTheories guide the enterprise of finding facts rather than of reaching goals, and are neutral concerning alternatives among values.: 131  A theory can be a body of knowledge, which may or may not be associated with particular explanatory models. To theorize is to develop this body of knowledge.: 46 The word theory or \"in theory\" is sometimes used erroneously by people to explain something which they individually did not experience or test before. In those instances, semantically, it is being substituted for another concept, a hypothesis. Instead of using the word \"hypothetically\", it is replaced by a phrase: \"in theory\". In some instances the theory's credibility could be contested by calling it \"just a theory\" (implying that the idea has not even been tested). Hence, that word \"theory\" is very often contrasted to \"practice\" (from Greek praxis, πρᾶξις) a Greek term for doing, which is opposed to theory. A \"classical example\" of the distinction between \"theoretical\" and \"practical\" uses the discipline of medicine: medical theory involves trying to understand the causes and nature of health and sickness, while the practical side of medicine is trying to make people healthy. These two things are related but can be independent, because it is possible to research health and sickness without curing specific patients, and it is possible to cure a patient without knowing how the cure worked.",
                    "URL": "https://en.wikipedia.org/wiki/Theory"
                },
                "database": {
                    "Score": "0.82555324",
                    "Summary": "In computing, a database is an organized collection of data stored and accessed electronically from a computer system. Where databases are more complex they are often developed using formal design and modeling techniques.\nThe database management system (DBMS) is the software that interacts with end users, applications, and the database itself to capture and analyze the data. The DBMS software additionally encompasses the core facilities provided to administer the database. The sum total of the database, the DBMS and the associated applications can be referred to as a \"database system\". Often the term \"database\" is also used loosely to refer to any of the DBMS, the database system or an application associated with the database.\nComputer scientists may classify database-management systems according to the database models that they support. Relational databases became dominant in the 1980s. These model data as rows and columns in a series of tables, and the vast majority use SQL for writing and querying data. In the 2000s, non-relational databases became popular, referred to as NoSQL because they use different query languages.",
                    "URL": "https://en.wikipedia.org/wiki/Database"
                },
                "memory": {
                    "Score": "0.8231498",
                    "Summary": "Memory is the faculty of the brain by which data or information is encoded, stored, and retrieved when needed. It is the retention of information over time for the purpose of influencing future action. If past events could not be remembered, it would be impossible for language, relationships, or personal identity to develop. Memory loss is usually described as forgetfulness or amnesia.Memory is often understood as an informational processing system with explicit and implicit functioning that is made up of a sensory processor, short-term (or working) memory, and long-term memory. This can be related to the neuron.\nThe sensory processor allows information from the outside world to be sensed in the form of chemical and physical stimuli and attended to various levels of focus and intent. Working memory serves as an encoding and retrieval processor. Information in the form of stimuli is encoded in accordance with explicit or implicit functions by the working memory processor. The working memory also retrieves information from previously stored material.  Finally, the function of long-term memory is to store data through various categorical models or systems.Declarative, or explicit, memory is the conscious storage and recollection of data. Under declarative memory resides semantic and episodic memory. Semantic memory refers to memory that is encoded with specific meaning, while episodic memory refers to information that is encoded along a spatial and temporal plane. Declarative memory is usually the primary process thought of when referencing memory. Non-declarative, or implicit, memory is the unconscious storage and recollection of information. An example of a non-declarative process would be the unconscious learning or retrieval of information by way of procedural memory, or a priming phenomenon. Priming is the process of subliminally arousing specific responses from memory and shows that not all memory is consciously activated, whereas procedural memory is the slow and gradual learning of skills that often occurs without conscious attention to learning.Memory is not a perfect processor, and is affected by many factors. The ways by which information is encoded, stored, and retrieved can all be corrupted. Pain, for example, has been identified as a physical condition that impairs memory, and has been noted in animal models as well as chronic pain patients. The amount of attention given new stimuli can diminish the amount of information that becomes encoded for storage. Also, the storage process can become corrupted by physical damage to areas of the brain that are associated with memory storage, such as the hippocampus. Finally, the retrieval of information from long-term memory can be disrupted because of decay within long-term memory. Normal functioning, decay over time, and brain damage all affect the accuracy and capacity of the memory.",
                    "URL": "https://en.wikipedia.org/wiki/Memory"
                },
                "average": {
                    "Score": "0.8230023",
                    "Summary": "In colloquial language, an average is a single number taken as representative of a non-empty list of numbers. Different concepts of average are used in different contexts. Often \"average\" refers to the arithmetic mean, the sum of the numbers divided by how many numbers are being averaged. In statistics, mean, median, and mode are all known as measures of central tendency, and in colloquial usage any of these might be called an average value.",
                    "URL": "https://en.wikipedia.org/wiki/Average"
                },
                "smaller": {
                    "Score": "0.82138705",
                    "Summary": "Smaller were an English alternative rock, Britpop band from Liverpool, active during the 1990s. They had hits with \"Wasted\" and \"Is\" in 1996 and 1997.",
                    "URL": "https://en.wikipedia.org/wiki/Smaller"
                },
                "design": {
                    "Score": "0.82134944",
                    "Summary": "A design is a plan or specification for the construction of an object or system or for the implementation of an activity or process, or the result of that plan or specification in the form of a prototype, product or process. The verb to design expresses the process of developing a design. In some cases, the direct construction of an object without an explicit prior plan (such as in craftwork, some engineering, coding, and graphic design) may also be considered to be a design activity. The design usually has to satisfy certain goals and constraints, may take into account aesthetic, functional, economic, or socio-political considerations, and is expected to interact with a certain environment. Major examples of designs include architectural blueprints, engineering drawings, business processes, circuit diagrams, and sewing patterns.The person who produces a design is called a designer, which is a term generally used for people who work professionally in one of the various design areas—usually specifying which area is being dealt with (such as a fashion designer, product designer, web designer or interior designer), but also others such as architects and engineers. A designer's sequence of activities is called a design process, possibly using design methods. The process of creating a design can be brief (a quick sketch) or lengthy and complicated, involving considerable research, negotiation, reflection, modeling, interactive adjustment and re-design.",
                    "URL": "https://en.wikipedia.org/wiki/Design"
                },
                "cryptography": {
                    "Score": "0.81266516",
                    "Summary": "Cryptography, or cryptology (from Ancient Greek: κρυπτός, romanized: kryptós \"hidden, secret\"; and γράφειν graphein, \"to write\", or -λογία -logia, \"study\", respectively), is the practice and study of techniques for secure communication in the presence of adversarial behavior. More generally, cryptography is about constructing and analyzing protocols that prevent third parties or the public from reading private messages; various aspects in information security such as data confidentiality, data integrity, authentication, and non-repudiation are central to modern cryptography. Modern cryptography exists at the intersection of the disciplines of mathematics, computer science, electrical engineering, communication science, and physics. Applications of cryptography include electronic commerce, chip-based payment cards, digital currencies, computer passwords, and military communications.\nCryptography prior to the modern age was effectively synonymous with encryption, converting information from a readable state to unintelligible nonsense. The sender of an encrypted message shares the decoding technique only with intended recipients to preclude access from adversaries. The cryptography literature often uses the names Alice (\"A\") for the sender, Bob (\"B\") for the intended recipient, and Eve (\"eavesdropper\") for the adversary. Since the development of rotor cipher machines in World War I and the advent of computers in World War II, cryptography methods have become increasingly complex and its applications more varied.\nModern cryptography is heavily based on mathematical theory and computer science practice; cryptographic algorithms are designed around computational hardness assumptions, making such algorithms hard to break in actual practice by any adversary. While it is theoretically possible to break into a well-designed system, it is infeasible in actual practice to do so. Such schemes, if well designed, are therefore termed \"computationally secure\"; theoretical advances, e.g., improvements in integer factorization algorithms, and faster computing technology require these designs to be continually reevaluated, and if necessary, adapted. There exist information-theoretically secure schemes that provably cannot be broken even with unlimited computing power, such as the one-time pad, but these schemes are much more difficult to use in practice than the best theoretically breakable but computationally secure schemes.\nThe growth of cryptographic technology has raised a number of legal issues in the information age. Cryptography's potential for use as a tool for espionage and sedition has led many governments to classify it as a weapon and to limit or even prohibit its use and export. In some jurisdictions where the use of cryptography is legal, laws permit investigators to compel the disclosure of encryption keys for documents relevant to an investigation. Cryptography also plays a major role in digital rights management and copyright infringement disputes in regard to digital media.",
                    "URL": "https://en.wikipedia.org/wiki/Cryptography"
                },
                "email address": {
                    "Score": "0.8119029",
                    "Summary": "An email address identifies an email box to which messages are delivered. While early messaging systems used a variety of formats for addressing, today, email addresses follow a set of specific rules originally standardized by the Internet Engineering Task Force (IETF) in the 1980s, and updated by RFC 5322 and 6854. The term email address in this article refers to addr-spec in RFC 5322, not to address or mailbox; i.e., a raw address without a display-name.\nAn email address, such as john.smith@example.com, is made up from a local-part, the symbol @, and a domain, which may be a domain name or an IP address enclosed in brackets. Although the standard requires the local part to be case-sensitive,\nit also urges that receiving hosts deliver messages in a case-independent manner,\ne.g., that the mail system in the domain example.com treat John.Smith as equivalent to john.smith; some mail systems even treat them as equivalent to johnsmith. Mail systems often limit the users' choice of name to a subset of the technically permitted characters.\nWith the introduction of internationalized domain names, efforts are progressing to permit non-ASCII characters in email addresses.",
                    "URL": "https://en.wikipedia.org/wiki/Email_address"
                },
                "structure": {
                    "Score": "0.80818266",
                    "Summary": "A structure is an arrangement and organization of interrelated elements in a material object or system, or the object or system so organized. Material structures include man-made objects such as buildings and machines and natural objects such as biological organisms, minerals and chemicals. Abstract structures include data structures in computer science and musical form. Types of structure include a hierarchy (a cascade of one-to-many relationships), a network featuring many-to-many links, or a lattice featuring connections between components that are neighbors in space.",
                    "URL": "https://en.wikipedia.org/wiki/Structure"
                }
            }
        },
        {
            "start_timestamp": "00:17:20",
            "title": "HASH FUNCTION BENCHMARK",
            "text": "HASH FUNCTION BENCHMARK\n\nere sdehash Murmuriiash3 —Caytlhash\n\n \n\n \n\nTerm dash NNflasha\n28000\n1228\n64\naS 2 ho00 192\n= 32\nFS 14o00 antes\na . OO ene\nau\n3 a0 ‘\n5 -\na\n| Al 101 Val 201 AA\n\n \n\nKey Size (bytes)",
            "transcript": "You know kind of a high level comparison between the different functions I showed so these uh. It just shows the throughput uh in terms of how many, how many uh megabytes per second each hash function can execute you'll see crc64 is somewhere low along the bottom. It's pretty slow. There are uh, so the the the x-axis is the key size. The number of bytes uh that the in the key, uh and you'll see kind of these uh for for some of the functions you'll see kind of these spikes. Those are usually like if they're cache line, aligned or word aligned on the number of bytes you, you kind of get up there and then, when you're, you know one bite too far over the performance drops off uh. So kind of this is this: is the the a high level comparison to see kind of you know, depending on which hash function you choose? You can get a pretty different performance so.",
            "transcript-corrected": "You know kind of a high level comparison between the different functions I showed so these uh. It just shows the throughput uh in terms of how many, how many uh megabytes per second each hash function can execute you'll see crc64 is somewhere low along the bottom. It's pretty slow. There are, uh, so the the the x-axis is the key size. The number of bytes uh, that the in the key, uh and you'll see kind of these, uh for for some of the functions you'll see kind of these spikes. Those are usually like if they're cache line, aligned or word aligned on the number of bytes you, you kind of get up there and then, when you're, you know one bite too far over the performance drops off uh. So kind of this is this: is the a high level comparison to see kind of, you know, depending on which hash function you choose? You can get a pretty different performance so.",
            "summary_brief": "I'm going to show you a bit of a high level comparison between the different hash functions I showed.",
            "summary_detailed": "You know kind of a high level comparison between the different functions I showed so these uh. It just shows the throughput uh in terms of how many, how many uh megabytes per second each hash function can execute. There are, uh, so the the the x-axis is the key size. The number of bytes uh, that the in the key, uh and you'll see kind of these spikes.",
            "key_concepts": {
                "hash function": {
                    "Score": "0.8927837",
                    "Summary": "A hash function is any function that can be used to map data of arbitrary size to fixed-size values. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes.  The values are usually used to index a fixed-size table called a hash table. Use of a hash function to index a hash table is called hashing or scatter storage addressing.\nHash functions and their associated hash tables are used in data storage and retrieval applications to access data in a small and nearly constant time per retrieval. They require an amount of storage space only fractionally greater than the total space required for the data or records themselves. Hashing is a computationally and storage space-efficient form of data access that avoids the non-linear access time of ordered and unordered lists and structured trees, and the often exponential storage requirements of direct access of state spaces of large or variable-length keys.\nUse of hash functions relies on statistical properties of key and function interaction: worst-case behaviour is intolerably bad with a vanishingly small probability, and average-case behaviour can be nearly optimal (minimal collision).Hash functions are related to (and often confused with) checksums, check digits, fingerprints, lossy compression, randomization functions, error-correcting codes, and ciphers. Although the concepts overlap to some extent, each one has its own uses and requirements and is designed and optimized differently. The hash functions differ from the concepts numbered mainly in terms of data integrity.",
                    "URL": "https://en.wikipedia.org/wiki/Hash_function"
                },
                "size": {
                    "Score": "0.86260945",
                    "Summary": "Size in general is the magnitude or dimensions of a thing. More specifically, geometrical size (or spatial size) can refer to linear dimensions (length, width, height, diameter, perimeter), area, or volume. Size can also be measured in terms of mass, especially when assuming a density range.\n\nIn mathematical terms, \"size is a concept abstracted from the process of measuring by comparing a longer to a shorter\". Size is determined by the process of comparing or measuring objects, which results in the determination of the magnitude of a quantity, such as length or mass, relative to a unit of measurement. Such a magnitude is usually expressed as a numerical value of units on a previously established spatial scale, such as meters or inches.\nThe sizes with which humans tend to be most familiar are body dimensions (measures of anthropometry), which include measures such as human height and human body weight. These measures can, in the aggregate, allow the generation of commercially useful distributions of products that accommodate expected body sizes, as with the creation of clothing sizes and shoe sizes, and with the standardization of door frame dimensions, ceiling heights, and bed sizes. The human experience of size can lead to a psychological tendency towards size bias, wherein the relative importance or perceived complexity of organisms and other objects is judged based on their size relative to humans, and particularly whether this size makes them easy to observe without aid.",
                    "URL": "https://en.wikipedia.org/wiki/Size"
                },
                "key size": {
                    "Score": "0.8280732",
                    "Summary": "In cryptography, key size, key length, or key space refer to the number of bits in a key used by a cryptographic algorithm (such as a cipher).\nKey length defines the upper-bound on an algorithm's security (i.e. a logarithmic measure of the fastest known attack against an algorithm), since the security of all algorithms can be violated by brute-force attacks. Ideally, the lower-bound on an algorithm's security is by design equal to the key length (that is, the security is determined entirely by the keylength, or in other words, the algorithm's design does not detract from the degree of security inherent in the key length). Indeed, most symmetric-key algorithms are designed to have security equal to their key length. However, after design, a new attack might be discovered. For instance, Triple DES was designed to have a 168-bit key, but an attack of complexity 2112 is now known (i.e. Triple DES now only has 112 bits of security, and of the 168 bits in the key the attack has rendered 56 'ineffective' towards security). Nevertheless, as long as the security (understood as \"the amount of effort it would take to gain access\") is sufficient for a particular application, then it does not matter if key length and security coincide. This is important for asymmetric-key algorithms, because no such algorithm is known to satisfy this property; elliptic curve cryptography comes the closest with an effective security of roughly half its key length.",
                    "URL": "https://en.wikipedia.org/wiki/Key_size"
                },
                "second": {
                    "Score": "0.8785812",
                    "Summary": "The second (symbol: s, also abbreviated: sec) is the base unit of time in the International System of Units (SI) (French: Système International d’unités), commonly understood and historically defined as 1⁄86400 of a day – this factor derived from the division of the day first into 24 hours, then to 60 minutes and finally to 60 seconds each. Analog clocks and watches often have sixty tick marks on their faces, representing seconds (and minutes), and a \"second hand\" to mark the passage of time in seconds.  Digital clocks and watches often have a two-digit seconds counter. The second is also part of several other units of measurement like meters per second for speed, meters per second per second for acceleration, and cycles per second for frequency.\n\nAlthough the historical definition of the unit was based on this division of the Earth's rotation cycle, the formal definition in the International System of Units (SI) is a much steadier timekeeper:The second is defined as being equal to the time duration of 9,192,631,770 periods of the radiation corresponding to the transition between the two hyperfine levels of the fundamental unperturbed ground-state of the caesium-133 atom.\nBecause the Earth's rotation varies and is also slowing very slightly, a leap second is added at irregular intervals to clock time to keep clocks in sync with Earth's rotation.\nMultiples of seconds are usually counted in hours and minutes. Fractions of a second are usually counted in tenths or hundredths. In scientific work, small fractions of a second are counted in milliseconds (thousandths), microseconds (millionths), nanoseconds (billionths), and sometimes smaller units of a second. An everyday experience with small fractions of a second is a 1-gigahertz microprocessor which has a cycle time of 1 nanosecond. Camera shutter speeds are often expressed in fractions of a second, such as 1⁄30 second or 1⁄1000 second.\nSexagesimal divisions of the day from a calendar based on astronomical observation have existed since the third millennium BC, though they were not seconds as we know them today. Small divisions of time could not be measured back then, so such divisions were mathematically derived. The first timekeepers that could count seconds accurately were pendulum clocks invented in the 17th century. Starting in the 1950s, atomic clocks became better timekeepers than Earth's rotation, and they continue to set the standard today.",
                    "URL": "https://en.wikipedia.org/wiki/Second"
                },
                "high level": {
                    "Score": "0.84448534",
                    "Summary": "High Level is a town in Northern Alberta, Canada. It is located at the intersection of the Mackenzie Highway (Highway 35) and Highway 58, approximately 733 kilometres (455 mi) north of Edmonton and 725 kilometres (450 mi) south of Yellowknife, Northwest Territories. High Level is located within Mackenzie County and was founded in 1947. The town serves a trading area of approximately 20,000 people.",
                    "URL": "https://en.wikipedia.org/wiki/High_Level"
                },
                "number": {
                    "Score": "0.832003",
                    "Summary": "A number is a mathematical object used to count, measure, and label. The original examples are the natural numbers 1, 2, 3, 4, and so forth. Numbers can be represented in language with number words. More universally, individual numbers can be represented by symbols, called numerals; for example, \"5\" is a numeral that represents the number five. As only a relatively small number of symbols can be memorized, basic numerals are commonly organized in a numeral system, which is an organized way to represent any number. The most common numeral system is the Hindu–Arabic numeral system, which allows for the representation of any number using a combination of ten fundamental numeric symbols, called digits. In addition to their use in counting and measuring, numerals are often used for labels (as with telephone numbers), for ordering (as with serial numbers), and for codes (as with ISBNs). In common usage, a numeral is not clearly distinguished from the number that it represents.\nIn mathematics, the notion of a number has been extended over the centuries to include 0, negative numbers, rational numbers such as one half \n  \n    \n      \n        \n          (\n          \n            \n              \n                1\n                2\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\tfrac {1}{2}}\\right)}\n  , real numbers such as the square root of 2 \n  \n    \n      \n        \n          (\n          \n            \n              2\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\sqrt {2}}\\right)}\n   and π, and complex numbers which extend the real numbers with a square root of −1 (and its combinations with real numbers by adding or subtracting its multiples). Calculations with numbers are done with arithmetical operations, the most familiar being addition, subtraction, multiplication, division, and exponentiation. Their study or usage is called arithmetic, a term which may also refer to number theory, the study of the properties of numbers.\nBesides their practical uses, numbers have cultural significance throughout the world. For example, in Western society, the number 13 is often regarded as unlucky, and \"a million\" may signify \"a lot\" rather than an exact quantity. Though it is now regarded as pseudoscience, belief in a mystical significance of numbers, known as numerology, permeated ancient and medieval thought. Numerology heavily influenced the development of Greek mathematics, stimulating the investigation of many problems in number theory which are still of interest today.During the 19th century, mathematicians began to develop many different abstractions which share certain properties of numbers, and may be seen as extending the concept. Among the first were the hypercomplex numbers, which consist of various extensions or modifications of the complex number system. In modern mathematics, number systems (sets) are considered important special examples of more general categories such as rings and fields, and the application of the term \"number\" is a matter of convention, without fundamental significance.",
                    "URL": "https://en.wikipedia.org/wiki/Number"
                },
                "megabyte": {
                    "Score": "0.8294917",
                    "Summary": "The megabyte is a multiple of the unit byte for digital information. Its recommended unit symbol is MB.  The unit prefix mega is a multiplier of 1000000 (106) in the International System of Units (SI). Therefore, one megabyte is one million bytes of information. This definition has been incorporated into the International System of Quantities.\nHowever, in the computer and information technology fields, two other definitions are used that arose for historical reasons of convenience. A common usage has been to designate one megabyte as 1048576bytes (220 B), a measurement that conveniently expresses the binary multiples inherent in digital computer memory architectures. However, most standards bodies have deprecated this usage in favor of a set of binary prefixes, in which this quantity is designated by the unit mebibyte (MiB). In one context, the megabyte has been used to mean 1000×1024 (1024000) bytes.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Megabyte"
                }
            }
        },
        {
            "start_timestamp": "00:18:30",
            "title": "LINEAR PROBE HASHING —- DELETES",
            "text": "LINEAR PROBE HASHING —- DELETES\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n| val\nA\nC | val\nFind D\nE | val\nF | val\n| val",
            "transcript": "The the second piece to the hash table- and this is the the probably more complicated pieces- is what hashing scheme are you going to use so we'll talk kind of about three different approaches here? The first is called linear pro passion. The second is robin hood hashing and the third is cuckoo hashing, and this is again the the hashing scheme that you're going to use for how to resolve collisions so linear, probe hashing is also called open. Address hassan hashing, we'll see why uh in a second but uh. Basically, you think of it. You just have a single giant table of slots, so like a big array and the way that we're going to resolve collisions is by linearly searching forward in the array for the next free slot. So again, imagine you have two keys that hash to the same position: there's a collision there so in order to to find uh, if, if the first key that we've come across, isn't the key we're looking for then we're going to scan until we find the next key so kind of to to determine whether or not there's an element present we're going to hash the location in the index and then scan forward for it. And if, if we we get to a position, that's empty in our array, then we know we're done we're going to stop scanning so insertions and deletions are kind of just a generalization of how you do look up so we'll kind of walk through next. Just a basic example to kind of see how this works so again. Uh, let's say we want to hash these keys here, a through f and we have our allocated hash table. It's just a whole bunch of of buckets so that we'll you know hash the first ones we're going to store uh the hash. The hash value gives us uh position two in the table, so it's going to be a stored there, which is the key we're looking for as well as the value associated with uh a so the the you know. There are different ways you can do it, but one common way is to just store the keys, uh contiguous with the values, so these are both stored together in the hash table. So that way, when we want to go retrieve it, we can get the value back as soon as we find the key. So again, we can kind of go through this b, maybe hashes to the zeroth position. We store the key b as well as the value we can keep going. We get to see here. We see that there is a collision. So what c does is the hash maps, the key c to the same position as key a so the way we're going to resolve it? This is why it's called linear pro hashing. Is we just kind of scan linearly forward from the position that c should have been inserted until we find the next open position in the array? So kind of c ends up there and then, if we insert d uh, it's the same procedure d maps to the position, uh d maps to the position where c was inserted so now that slots full. So we have to scan forward until we find an empty slot for d, and you know so on so now we end up with e here. That's all the way back up where, where a was so we're going to kind of look at each next slot, you see c is in the next position, then d. So finally, e gets uh put at the bottom of the array. There and kind of again, with f f goes in or f should be inserted at f hashes to the position where e is stored and we get f stored. You know consecutively after e, so this is kind of the how the how the insertion procedure here works. It's really straightforward! Uh! You don't need to keep track of anything. Really you just hash to the position that uh you're you're supposed to be in. If there's already a key in that position, then you just scan forward until you find an empty slot to insert into and you don't need any like uh, you know latching or anything for this. You can just do like a an atomic compare and swap operation or parent set operation uh to insert into into the slot. And if you fail, you know, if your atomic operation fails, you go to the next slide. You can implement it with with latching, but you can equally implement it with just atomic instructions. Okay, so that's kind of the the insertion procedure. Uh does that? Does that make sense? Anyone have any questions about that part. Yes, so the question is what about quadratic caching, yeah, so uh, linear, linear, probing, is kind of the the simplest. One is just inserting consecutive elements uh. You could have in an arbitrary uh probing scheme for your hash table. Uh. You could do it like exponentially. You could do it quadratically. So you know. First, you check the first next first space. Then you check two four et cetera [Music]. It depends on the distribution of your keys and the insertion order of the keys so uh there. If, if you know information about that, there may be reasons uh to to choose different probing schemes. The the challenge with uh, non-linear probing, is again remember: uh, we've talked a lot about the cost of uh random access versus sequential access, so uh, if you have you know, let's say exponential: if you have uh to jump to the second and then the fourth and then the eighth and so on, then you can kind of uh wind up with these bad random access patterns, especially if you know with with just linear sequential scan. Not only is data. You know it's in consecutive, distorted pages, it's in consecutive pages. If it's stored in memory, then it could be in consecutive cache lines and there's also some pre-fetching that can go on. So it's usually a lot cheaper to do these kind of linear uh scans. So there are, there are other probing algorithms, but pretty much uh. Most of the time. I think, unless you know something about kind of the key distribution, then linear probing is is uh common? Yes, so the question is: why don't we need latching for this portion, so you you could implement the these insertions with latches. You could take a latch, I mean at the. In the most extreme case, you could take a latch in the whole data structure and insert one thing to prevent concurrent modifications you could take latches on individual bins or buckets in the hash table to prevent concurrent modification uh since since we're just inserting into an individual slot, so, like here f, wants to insert into this individual slot. You can just perform one atomic instruction to try and and set the f uh or to insert the f key into that slot and if, if the atomic like a like a compare and swap or compare and set function, so if you, if you compare it to empty and uh the the bucket, is empty. So in this case it's going to start out at e. That's not going to be empty you're going to move to the next one. So, let's say f now: issues the the compare and set for to insert itself- and maybe g comes along in the meantime and- and you know inserts g in there, so the the compare and set function is going to fail for f and then it will just move on to the next uh slot in the bin. That makes sense great any other questions. Yes, uh. Yes, so the question is: do the insertions wrap around and go back to the beginning if it reaches the end? The answer is yes, you can think about this like a circular buffer, so uh kind of you know as you're as you're going through here. If another key g came along uh and you get back to the beginning or sorry you got down to the end. Where f is you, you may need to wrap around back beginning and start start your scan from there so uh? If, if this fills up and we'll see that in a second, but if this, if the data structure fills up, then you're going to kind of complete an entire complete loop through the the hash table. So when you get back around to the position, the first position that you started in the position you hash to you know that the the hash table is full and you need to resize it. So we'll talk about that in a few slides. Are there any other questions, great okay, so the next, the next, so that that was inserts and uh lookups work sort of the same way. So now the piece that we need to to consider is deletion. So we want to remove a key from the hash table, let's say, for example, and remove key c so we'll delete that and we'll you know hash the val c. It brings us to uh uh position, slot number uh two and that's where a is stored. So we compare c to a that doesn't match so then we scan forward one we find c and then we can just delete c right. Does anyone see a problem with what I just did there? Yes right, so the the the the comment was that if you have another uh value that or another key that hashes to the position uh where a is stored, and then you know- let's say it's key e or or d and then you want to scan forward, then, what's going to happen, is you're going to see the empty slot and you're going to assume you're done right, that's exactly correct! So, for example, if we want to find key d now after we've performed this deletion, uh key d is going to hash into this empty slot and it's going to say, hey, there's, no, there's no key there. It's not! You know it's not my key d, it's not some other key and I need to scan forward now, there's just no key, so it thinks that d is not included in the hash table. Even though we can see you know, d is in the very next position. So the way we get around this is uh there. There are two strategies. The first approach is what's called using a tombstone, so you uh insert some tombstone value. It's just you know: some reserved value could be a bit flag, could be some reserved key value whatever. Basically, all it does. Its only purpose is to be inserted into that position where we removed c uh in order to let subsequent lookups know that there uh it's not an empty bin or not an empty slot, it's actually just a removed or deleted slot. Since we removed it, we don't care what the the value or the, what the key we don't care, what key used to be stored in there. All we care about is knowing that uh there there used to be some key stored in this position, so we don't. We don't terminate our uh forward scan early, so we can kind of see if we, if we have uh this lookup of d again it goes to the the slot with the tombstone, and it says: okay uh, I I know there's a tombstone here. I need to start scanning forward from this position. Then you, you find the next value d, so the the second approach that you can use to get around this is what's called movement. So it's basically like a compaction phase, so, for example, in this case, if we removed uh c, we can just kind of slide all of these other values up uh and now fill in you know the empty missing, uh uh hole that we created and now again we'll find d. We can hash in and find the value there. Yes, like say f was in its position because it should be there like. That's where it mapped. So the the question is: when we're performing the movement, the compaction uh. How do you know when to stop sliding things up because, for example, f might be in its uh correct slot, but something else might not be. That's the the you know next point I was going to make so kind of in this particular example: kind of the mappings work correctly. But if, for example, we had, you know an another uh key where in your example, f was in the correct position, what we would need to do is figure out. Okay, we can't slide f up because it maps to the correct area. So what this ends up doing is basically rehashing everything below where your compaction is so you perform for the slots uh below where you're compacting you want to perform that uh a rehashing to see if they're in the correct position, so it makes sense so, for example, uh let's say we want to move d up, we rehash d and you basically just reinsert it does that answer the question yeah, so the the the basically when you're doing this compaction, it triggers a rehashing of everything uh below the empty slot that you're uh reinserting. So, for example, in this case, if f uh was in the correct position at the bottom, then we, when we rehashed f it would just map to that position again it would we wouldn't move it up there. Any other questions about that. So again we have to. We have to uh kind of be be mindful about [Music], this being a circular buffer uh, which we we just mentioned. One of the previous questions. So when we were doing the the shifting or or sliding kind of we would have to look at b, which is at the top of of the array here and really it should be shifted down there since we're shifting everything up by one to fill in the slots and kind of as as uh. We just discussed this this. If we're hashing the key b, it's expected to be there but uh. When we're doing the shifting, we would have to move it up. So again, you have to kind of be careful. You can't always move all of the keys. You essentially have to do a rehashing of all of the keys and the partition that you're uh shifting okay, so uh. Another issue that can come up in in uh with the with the kind of basic or naive version of the hash table. Is you can't support? Remember non-unique keys so again, if we have this bag or multi-set algebra, how do we handle keys that are duplicates in the data set? So uh kind of one option is to have this separate linked list, which is just going to store basically a a list of all of the values that are related to a particular key. So you kind of de-duplicate the common keys and then just store all of the values in a value list. Basically so uh in this example uh the key xyz. There are three repeats of the key xyz each with different values and two repeats of the key abc with different values. So we can kind of store each of the keys once in our in our hash table, and then we just store this pointer to some value list that can store variable sized number of values, depending on how many, how many duplicates of the each key we have kind of the the other approach to this is that we can just store uh the duplicate key entries together in the hash table, and then we have to modify our our lookup algorithm a little bit, but basically kind of we can just get these uh values stored together in the hash tables. And then, when we go to do the lookups, we we can retrieve them, but that again requires us to modify the lookup algorithm to we have to scan until we find a an empty slot, because now we don't know when necessarily we're done, we have to keep scanning until we we could potentially find more keys. For example, if we're looking for the key xyz in this case there could be, you know, uh other xyz keys later in the hash table. We have to keep scanning until we find all of them. We can't stop after we found the first one, so there any questions about uh, non-unique keys. Yes, so the question is in the second approach: when you get back all of the when you get back the values for specific key, do you get back all of the values so uh? The answer is yes, but it actually applies to both approaches. So in the first approach, uh whatever it is, whether it's the first approach or the second approach, if you look up a key and there are multiple values associated, so what multiple values associated with the key means is that the keys are duplicated so you'll. If there are, if, if the key xyz is duplicated three times, you'll get back three values when you look up xyz and it doesn't matter if, if you're, storing it the first way in these value lists or if you're, storing it the second way, just kind of all together in the hash table, so the uh about the second, oh yeah. So the question is uh. When you have the the redundant keys all stored in the hash table, choice number two: when you do a lookup, do you have to scan through the whole hash table? Because you don't know when, like you don't know, you don't know when you're you're done. So it's not necessarily the whole hash table unless I guess the hash table's full, but you have to scan until you find an explicitly empty bin because you don't know uh like if, if there are guaranteed to be unique keys, you can stop as soon as you find the key you're looking for right. If there are duplicate keys, you don't know, I I mean it could be xyz and then abc 100 times and then another xyz again right. So you don't know when to stop until you hit one of these empty uh bins. So then you know that that your scanning is over. You don't have to go any further. Does it make sense right? Yes, so the question is: if you have duplicate keys, does the hash table uh always return the uh all of the values, or does it just return? The first one I I mean so I guess you you could implement it either way. Uh, probably what I would imagine uh it would look like is you'd get an iterator to like a an arbitrarily sized list of values and it could be one or it could be n. Yeah, I think that's a an implementation decision, uh that you'd have to make, depending on how you how you want the values, so you you could uh yeah, you could do it either way, but I think that the the thing to keep in mind is that when, when we're we're building these in a lot of cases, we can't guarantee that they're going to be unique keys. So we need to figure out some way to handle these. These variable size number of values for duplicate keys. Does that make sense great okay? Are there any other questions about this? Okay,.",
            "transcript-corrected": "The the second piece to the hash table- and this is the probably more complicated pieces- is what hashing scheme are you going to use so we'll talk kind of about three different approaches here? The first is called linear pro passion. The second is robin hood hashing and the third is cuckoo hashing, and this is again the hashing scheme that you're going to use  how to resolve collisions so linear, probe hashing is also called open. Address Hassan hashing, we'll see why uh in a second but uh. Basically, you think of it. You just have a single giant table of slots, so like a big array and the way that we're going to resolve collisions is by linearly searching forward in the array for the next free slot. So again, imagine you have two keys that hash to the same position: there's a collision there so in order to find uh, if, if the first key that we've come across, isn't the key we're looking for then we're going to scan until we find the next key so kind of to to determine whether or not there's an element present we're going to hash the location in the index and then scan forward for it. And if, if we we get into a position, that's empty in our array, then we know we're done we're going to stop scanning so insertions and deletions are kind of just a generalization of how you do look up so we'll kind of walk through next. Just a basic example to kind of see how this works so again. Uh, let's say we want to hash these keys here, a through f and we have our allocated hash table. It's just a whole bunch of of buckets so that we'll you know hash the first ones we're going to store uh the hash. The hash value gives us, uh position two in the table, so it's going to be a stored there, which is the key we're looking for as well as the value associated with uh a so the you know. There are different ways you can do it, but one common way is to just store the keys, uh contiguous with the values, so these are both stored together in the hash table. So that way, when we want to go retrieve it, we can get the value back as soon as we find the key. So again, we can kind of go through this b, maybe hashes to the zeroth position. We store the key b as well as the value we can keep going. We get to see here. We see that there is a collision. So what c does is the hash maps, the key c to the same position as key a so the way we're going to resolve it? This is why it's called linear pro hashing. Are we just kind of scan linearly forward from the position that c should have been inserted until we find the next open position in the array? So kind of c ends up there and then, if we insert duh, it's the same procedure d maps to the position, uh d maps to the position where c was inserted so now that slots full. So we have to scan forward until we find an empty slot ford, and you know soon so now we end up with me here. That's all the way back up where, where a was so we're going to kind of look at each next slot, you see c is in the next position, then d. So finally, we get uh put at the bottom of the array. There and kind of again, with f f goes in or if should be inserted at f hashes to the position where e is stored and we get f stored. You know consecutively  me, so this is kind of the how, the how the insertion procedure here works. It's really straightforward! Uh! You don't need to keep track of anything. Really, you just has to the position that uh, you're you're supposed to be in. If there's already a key in that position, then you just scan forward until you find an empty slot to insert into and you don't need any like uh, you know latching or anything for this. You can just do like at an atomic compare and swap operation or parent set operation uh to insert into into the slot. And if you fail, you know, if your atomic operation fails, you go to the next slide. You can implement it with with latching, but you can equally implement it with just atomic instructions. Okay, so that's kind of the insertion procedure. Uh, does that? Does that make sense? Anyone have any questions about that part. Yes, so the question is what about quadratic caching, yeah, so, uh, linear, linear, probing, is kind of the simplest. One is just inserting consecutive elements uh. You could have in an arbitrary uh probing scheme for your hash table. Uh. You could do it like exponentially. You could do it quadratically. So you know. First, you check the first next first space. Then you check two, four et cetera [Music]. It depends on the distribution of your keys and the insertion order of the keys so uh there. If, if you know information about that, there may be reasons uh to to choose different probing schemes. The the challenge with, uh, non-linear probing, is again, remember: uh, we've talked a lot about the cost of uh, random access versus sequential access, so uh, if you have you know, let's say exponential: if you have, uh to jump to the second and then the fourth and then the eighth and so on, then you can kind of uh, wind up with these bad random access patterns, especially if you know with with just linear sequential scan. Not only is data. You know it's in consecutive, distorted pages, it's  consecutive pages. If it's stored in memory, then it could be in consecutive cache lines and there's also some pre-fetching that can go on. So it's usually a lot cheaper to do these kind of linear uh scans. So there are, there are other probing algorithms, but pretty much uh. Most of the time. I think, unless you know something  kind of the key distribution, then linear probing is is uh common? Yes, so the question is: why don't we need latching for this portion, so you could implement the these insertions with latches. You could take a latch, I mean at the. In the most extreme case, you could take a latch in the whole data structure and insert one thing to prevent concurrent modifications you could take latches on individual bins or buckets in the hash table to prevent concurrent modification uh, since since we're just inserting into an individual slot, so, like here f, wants to insert into this individual slot. You can just perform one atomic instruction to try and set the f uh or to insert the f key into that slot and if, if the atomic like a like a compare and swap or compare and set function, so if you, if you compare it to empty and uh the bucket, is empty. So in this case, it's going to start out at e. That's not going to be empty you're going to move to the next one. So, let's say f now: issues the compare and set forward to insert itself- and maybe g comes along in the meantime and- and you know inserts g in there, so the compare and set function is going to fail for f and then it will just move on to the next uh slot in the bin. That makes sense great any other questions. Yes, uh. Yes, so the question is: do the insertions wrap around and go back to the beginning if it reaches the end? The answer is yes, you can think about this like a circular buffer, so, uh kind of, you know as you're as you're going through here. If another key g came along uh and you get back to the beginning or sorry you got down to the end. Where f is you, you may need to wrap around back beginning and start start your scan from there so uh? If, if this fills up and we'll see that in a second, but if this, if the data structure fills up, then you're going to kind of complete an entire complete loop through the hash table. So when you get back around to the position, the first position that you started in the position you hash for, you know that the hash table is full and you need to resize it. So we'll talk about that in a few slides. Are there any other questions, great okay, so the next, the next, so that was inserted and uh lookups work sort of the same way. So now the piece that we need to consider is deletion. So we want to remove a key from the hash table, let's say, for example, and remove key c so we'll delete that and we'll you know hash the Val c. It brings us to uh uh position, slot number uh two and that's where a is stored. So we compare c to a that doesn't match so, then we scan forward one we find c and then we can just delete c right. Does anyone see a problem with what I just did there? Yes, right, so the the the the comment was that if you have another, uh value that or another key that hashes to the position uh, where a is stored, and then you know- let's say it's key e or or d and then you want to scan forward, then, what's going to happen, is you're going to see the empty slot and you're going to assume you're done right, that's exactly correct! So, for example, if we want to find key d now after we've performed this deletion, uh, key d is going to hash into this empty slot and it's going to say, hey, there's, no, there's no key there. It's not! You know it's not my key d, it's not some other key and I need to scan forward now, there's just no key, so it thinks that d is not included in the hash table. Even though we can see you know, d is in the very next position. So the way we get around this is, uh there. There are two strategies. The first approach is what's called using a tombstone, so you, uh insert some tombstone value. It's just, you know: some reserved value could be a bit flag, could be some reserved key value whatever. Basically, all it does. Its only purpose is to be inserted into that position where we removed c uh in order to let subsequent lookups know that there, uh it's not an empty bin or not an empty slot, it's actually just a removed or deleted slot. Since we removed it, we don't care what the value or the, what the key we don't care, what key used to be stored in there. All we care about is knowing that, uh there, there used to be some key stored in this position, so we don't. We don't terminate our, uh forward scan early, so we can kind of see if we, if we have, uh this lookup of d again it goes into the slot with the tombstone, and it says: okay uh, I I know there's a tombstone here. I need to start scanning forward from this position. Then you, you find the next valued, so the second approach that you can use to get around this is what's called movement. So it's basically like a compaction phase, so, for example, in this case, if we removed uh c, we can just kind of slide all of these other values up, uh and now fill in you know the empty missing, uh uh hole that we created and now again we'll find d. We can hash in and find the value there. Yes, like saying f was in its position because it should be there like. That's where it mapped. So the question is: when we're performing the movement, the compaction uh. How do you know when to stop slicing things up because, for example, f might be in its uh, correct slot, but something else might not be. That's the you know next point I was going to make so kind of in this particular example: kind of the mappings work correctly. But if, for example, we had, you know an another, uh key where in your example, if was in the correct position, what we would need to do is figure out. Okay, we can't slide f up because it maps to the correct area. So what this ends up doing is basically rehashing everything below where your compaction is so you perform for the slots uh, below where you're compacting you want to perform that, uh a rehashing to see if they're in the correct position, so it makes sense, so, for example, uh, let's say we want to moved up, we rehash d and you basically just reinsert it does that answer the question yeah, so the the the basically when you're doing this compaction, it triggers a rehashing of everything uh below the empty slot that you're uh reinserting. So, for example, in this case, if f uh, was in the correct position at the bottom, then we, when we rehashed if it would just map to that position again it would we wouldn't move it up there. Any other questions about that. So again we have to. We have to, uh kind of been mindful about [Music], this being a circular buffer uh, which we we just mentioned. One of the previous questions. So when we were doing the shifting or or sliding kind  we would have to look at b, which is at the top of of the array here and really it should be shifted down there since we're shifting everything up by one to fill in the slots and kind of as as uh. We just discussed this this. If we're hashing the key, b, it's expected to be there but uh. When we're doing the shifting, we would have to move it up. So again, you have to kind of be careful. You can't always move all of the keys. You essentially have to do a rehashing of all of the keys and the partition that you're uh shifting okay, so uh. Another issue that can come up in in uh with the  the kind of basic or naive version of the hash table. Is you can't support? Remember non-unique keys so again, if we have this bag or multi-set algebra, how do we handle keys that are duplicates in the data set? So, uh kind of one option is to have this separate linked list, which is just going to store basically a list of all of the values that are related to a particular key. So you kind of de-duplicate the common keys and then just store all of the values in a value list. Basically so, uh in this example, uh the key xyz. There are three repeats of the key xyz each with different values and two repeats of the key ABC with different values. So we can kind of store each of the keys once in our in our hash table, and then we just store this pointer to some value list that can store variable sized number of values, depending on how many, how many duplicates of the each key we have kind of the other approach to this is that we can just store, uh the duplicate key entries together in the hash table, and then we have to modify our our lookup algorithm a little bit, but basically kind of we can just get these uh values stored together in the hash tables. And then, when we go to do the lookups, we we can retrieve them, but that again requires us to modify the lookup algorithm until we have to scan until we find a an empty slot, because now we don't know when necessarily we're done, we have to keep scanning until we we could potentially find more keys. For example, if we're looking for the key xyz in this case there could be, you know, uh other xyz keys later in the hash table. We have to keep scanning until we find all of them. We can't stop after we found the first one, so there any questions about, uh, non-unique keys. Yes, so the question is in the second approach: when you get back all of the when you get back the values of a specific key, do you get back all of the values so uh? The answer is yes, but it actually applies to both approaches. So in the first approach, uh, whatever it is, whether it's the first approach or the second approach, if you look up a key and there are multiple values associated, so what multiple values associated with the key means is that the keys are duplicated so you'll. If there are, if, if the key xyz is duplicated three times, you'll get back three values when you look up xyz and it doesn't matter if, if you're, storing it the first way in these value lists or if you're, storing it the second way, just kind of all together in the hash table, so the uh about the second, oh yeah. So the question is, uh. When you have the redundant keys all stored in the hash table, choice number two: when you do a lookup, do you have to scan through the whole hash table? Because you don't know when, like you don't know, you don't know when you're you're doing. So it's not necessarily the whole hash table unless, I guess the hash table full, but you have to scan until you find an explicitly empty bin because you don't know, uh like if, if there are guaranteed to be unique keys, you can stop as soon as you find the key you're looking for right. If there are duplicate keys, you don't know, I, I mean it could be xyz and then abs 100 times and then another xyz again right. So you don't know when to stop until you hit one of these empty uh bins. So then you know that your scanning is over. You don't have to go any further. Does it make sense, right? Yes, so the question is: if you have duplicate keys, makes the hash table uh always return the uh, all of the values, or does it just return? The first one I I mean so I guess you could implement it either way. Uh, probably what I would imagine uh, it would look like is you'd get an iterator to like a an arbitrarily sized list of values and it could be one or it could be n. Yeah, I think that's a an implementation decision, uh, that you'd have to make, depending on how you how you want the values, so you could, uh yeah, you could do it either way, but I think that the thing to keep in mind is that when, when we're we're building these in a lot of cases, we can't guarantee that they're going to be unique keys. So we need to figure out some way to handle these. These variable size numbers of values for duplicate keys. Does that make sense great okay? Are there any other questions about this? Okay,.",
            "summary_brief": "Let's start with the hash table.",
            "summary_detailed": "Hashing scheme is what you're going to use to resolve collisions so linear, probe hashing is also called open. Address Hassan hashing, we'll see why in a second but uh. Basically, you think of it. You just have a single giant table of slots, so like a big array and the way that we're going To resolve collisions is by linearly searching forward in the array.",
            "key_concepts": {
                "open position": {
                    "Score": "0.88885236",
                    "Summary": "In partner dancing, open position refers to positions in which partners are connected primarily at the hands as opposed to closer body contact, as in closed position.  The connection is through the hands, wrists, and fingers, and relies heavily on frame and the compression and tension of both partners' arms.  \nMany forms of dancing use the open position.  Modern Jive, East Coast Swing, West Coast Swing, Lindy Hop, and Latin are primary examples, but an open position is used in waltz, country, and other styles at times.",
                    "URL": "https://en.wikipedia.org/wiki/Open_position"
                },
                "data structure": {
                    "Score": "0.88885236",
                    "Summary": "In computer science, a data structure is a data organization, management, and storage format that enables efficient access and modification. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data, i.e., it is an algebraic structure about data.",
                    "URL": "https://en.wikipedia.org/wiki/Data_structure"
                },
                "question": {
                    "Score": "0.8238087",
                    "Summary": "A question is an utterance which typically functions as a request for information, which is expected to be provided in the form of an answer. Questions can thus be understood as a kind of illocutionary act in the field of pragmatics or as special kinds of propositions in frameworks of formal semantics such as alternative semantics or inquisitive semantics. Questions are often conflated with interrogatives, which are the grammatical forms typically used to achieve them. Rhetorical questions, for example, are interrogative in form but may not be considered true questions as they are not expected to be answered.",
                    "URL": "https://en.wikipedia.org/wiki/Question"
                },
                "location": {
                    "Score": "0.87319964",
                    "Summary": "In geography, location or place are used to denote a region (point, line, or area) on Earth’s surface or elsewhere. The term location generally implies a higher degree of certainty than place, the latter often indicating an entity with an ambiguous boundary, relying more on human or social attributes of place identity and sense of place than on geometry.",
                    "URL": "https://en.wikipedia.org/wiki/Location"
                },
                "strategy": {
                    "Score": "0.87153083",
                    "Summary": "Strategy (from Greek στρατηγία stratēgia, \"art of troop leader; office of general, command, generalship\") is a general plan to achieve one or more long-term or overall goals under conditions of uncertainty. In the sense of the \"art of the general\", which included several subsets of skills including military tactics, siegecraft, logistics etc., the term came into use in the 6th century C.E. in Eastern Roman terminology, and was translated into Western vernacular languages only in the 18th century. From then until the 20th century, the word \"strategy\" came to denote \"a comprehensive way to try to pursue political ends, including the threat or actual use of force, in a dialectic of wills\" in a military conflict, in which both adversaries interact.Strategy is important because the resources available to achieve goals are usually limited. Strategy generally involves, setting goals and priorities, determining actions to achieve the goals, and mobilizing resources to execute the actions. A strategy describes how the ends (goals) will be achieved by the means (resources). Strategy can be intended or can emerge as a pattern of activity as the organization adapts to its environment or competes. It involves activities such as strategic planning and strategic thinking.Henry Mintzberg from McGill University defined strategy as a pattern in a stream of decisions to contrast with a view of strategy as planning, while Henrik von Scheel defines the essence of strategy as the activities to deliver a unique mix of value – choosing to perform activities differently or to perform different activities than rivals. while Max McKeown (2011) argues that \"strategy is about shaping the future\" and is the human attempt to get to \"desirable ends with available means\". Dr. Vladimir Kvint defines strategy as \"a system of finding, formulating, and developing a doctrine that will ensure long-term success if followed faithfully.\" Complexity theorists define strategy as the unfolding of the internal and external aspects of the organization that results in actions in a socio-economic context.",
                    "URL": "https://en.wikipedia.org/wiki/Strategy"
                },
                "number": {
                    "Score": "0.8685794",
                    "Summary": "A number is a mathematical object used to count, measure, and label. The original examples are the natural numbers 1, 2, 3, 4, and so forth. Numbers can be represented in language with number words. More universally, individual numbers can be represented by symbols, called numerals; for example, \"5\" is a numeral that represents the number five. As only a relatively small number of symbols can be memorized, basic numerals are commonly organized in a numeral system, which is an organized way to represent any number. The most common numeral system is the Hindu–Arabic numeral system, which allows for the representation of any number using a combination of ten fundamental numeric symbols, called digits. In addition to their use in counting and measuring, numerals are often used for labels (as with telephone numbers), for ordering (as with serial numbers), and for codes (as with ISBNs). In common usage, a numeral is not clearly distinguished from the number that it represents.\nIn mathematics, the notion of a number has been extended over the centuries to include 0, negative numbers, rational numbers such as one half \n  \n    \n      \n        \n          (\n          \n            \n              \n                1\n                2\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\tfrac {1}{2}}\\right)}\n  , real numbers such as the square root of 2 \n  \n    \n      \n        \n          (\n          \n            \n              2\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\sqrt {2}}\\right)}\n   and π, and complex numbers which extend the real numbers with a square root of −1 (and its combinations with real numbers by adding or subtracting its multiples). Calculations with numbers are done with arithmetical operations, the most familiar being addition, subtraction, multiplication, division, and exponentiation. Their study or usage is called arithmetic, a term which may also refer to number theory, the study of the properties of numbers.\nBesides their practical uses, numbers have cultural significance throughout the world. For example, in Western society, the number 13 is often regarded as unlucky, and \"a million\" may signify \"a lot\" rather than an exact quantity. Though it is now regarded as pseudoscience, belief in a mystical significance of numbers, known as numerology, permeated ancient and medieval thought. Numerology heavily influenced the development of Greek mathematics, stimulating the investigation of many problems in number theory which are still of interest today.During the 19th century, mathematicians began to develop many different abstractions which share certain properties of numbers, and may be seen as extending the concept. Among the first were the hypercomplex numbers, which consist of various extensions or modifications of the complex number system. In modern mathematics, number systems (sets) are considered important special examples of more general categories such as rings and fields, and the application of the term \"number\" is a matter of convention, without fundamental significance.",
                    "URL": "https://en.wikipedia.org/wiki/Number"
                },
                "three times": {
                    "Score": "0.86994904",
                    "Summary": "Three Times (Chinese: 最好的時光; Zuìhǎo de shíguāng; lit. 'Best of Times') is a 2005 Taiwanese film directed by Hou Hsiao-hsien. It consists of three separate stories of romance, set in different eras, using the same lead actors, Shu Qi and Chang Chen. In \"A Time for Love,\" set in 1966, a soldier (Chang) meets an alluring pool-hall hostess (Shu). \"A Time for Freedom,\" set in 1911, focuses on a courtesan's relationship with a freedom fighter during the Japanese occupation of Taiwan. In \"A Time for Youth,\" set in 2005, a singer forsakes her female lover for a photographer with whom she's having an affair.\nThe film was nominated for the Palme d'Or at the 2005 Cannes Film Festival, won the Golden Apricot for Best Feature Film at the 2006 Yerevan International Film Festival, and received positive reviews. In 2017 The New York Times listed it as one of the 25 best films of the 21st century. It has been praised for its topical themes of communication, romance and relationships, with each linked symbolically to the era it takes place in.",
                    "URL": "https://en.wikipedia.org/wiki/Three_Times"
                },
                "previous question": {
                    "Score": "0.86941296",
                    "Summary": "In US parliamentary procedure, the previous question (also known as \"calling for the question\", \"calling the question\", \"close debate\", \"calling for a vote\", \"vote now\", or other similar forms) is generally used as a motion to end debate on a pending proposal and bring it to an immediate vote. The meaning of this specialized motion has nothing to do with any question previously considered by the assembly.\nIn the United States Senate and Commonwealth parliaments, a motion for \"cloture\", or \"closure\", is used instead to end debate. In those bodies, the \"previous question\" has a different use and is rarely used or not used at all.",
                    "URL": "https://en.wikipedia.org/wiki/Previous_question"
                },
                "unique key": {
                    "Score": "0.867427",
                    "Summary": "In Relational Database Management Systems, a unique key is a candidate key that is not the primary key of the relation. All the candidate keys of a relation can uniquely identify the records of the relation, but only one of them is used as the primary key of the relation. The remaining candidate keys are called unique keys because they can uniquely identify a record in a relation. Unique keys can consist of multiple columns. Unique Keys are also called alternate keys. Unique keys are an alternative to the primary key of the relation. Generally, the unique keys have a UNIQUE constraint.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Unique_key"
                },
                "collision": {
                    "Score": "0.8141859",
                    "Summary": "In physics, a collision is any event in which two or more bodies exert forces on each other in a relatively short time. Although the most common use of the word collision refers to incidents in which two or more objects collide with great force, the scientific use of the term implies nothing about the magnitude of the force.Some examples of physical interactions that scientists would consider collisions are the following:\n\nWhen an insect lands on a plant's leaf, its legs are said to collide with the leaf.\nWhen a cat strides across a lawn, each contact that its paws make with the ground is considered a collision, as well as each brush of its fur against a blade of grass.\nWhen a boxer throws a punch, their fist is said to collide with the opponent's body.\nWhen an astronomical object merges with a black hole, they are considered to collide.Some colloquial uses of the word collision are the following:\n\nA traffic collision involves at least one automobile.\nA mid-air collision occurs between airplanes.\nA ship collision accurately involves at least two moving maritime vessels hitting each other; the related term, allision, describes when a moving ship strikes a stationary object (often, but not always, another ship).In physics, collisions can be classified by the change in the total kinetic energy of the system before and after the collision:\n\nIf most or all of the total kinetic energy is lost (dissipated as heat, sound, etc. or absorbed by the objects themselves), the collision is said to be inelastic; such collisions involve objects coming to a full stop. An example of such a collision is a car crash, as cars crumple inward when crashing, rather than bouncing off of each other. This is by design, for the safety of the occupants and bystanders should a crash occur - the frame of the car absorbs the energy of the crash instead.\nIf most of the kinetic energy is conserved (i.e. the objects continue moving afterwards), the collision is said to be elastic. An example of this is a baseball bat hitting a baseball - the kinetic energy of the bat is transferred to the ball, greatly increasing the ball's velocity. The sound of the bat hitting the ball represents the loss of energy.\nAnd if all of the total kinetic energy is conserved (i.e. no energy is released as sound, heat, etc.), the collision is said to be perfectly elastic. Such a system is an idealization and cannot occur in reality, due to the second law of thermodynamics.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Collision"
                },
                "sequential access": {
                    "Score": "0.8535545",
                    "Summary": "Sequential access is a term describing a group of elements (such as data in a memory array or a disk file or on magnetic tape data storage) being accessed in a predetermined, ordered sequence. It is the opposite of random access, the ability to access an arbitrary element of a sequence as easily and efficiently as any other at any time.\nSequential access is sometimes the only way of accessing the data, for example if it is on a tape. It may also be the access method of choice, for example if all that is wanted is to process a sequence of data elements in order.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Sequential_access"
                },
                "information": {
                    "Score": "0.8535545",
                    "Summary": "Information is processed, organised and structured data. It provides context for data and enables decision making. For example, a single customer’s sale at a restaurant is data – this becomes information when the business is able to identify the most popular or least popular dish.More technically, information can be thought of as the resolution of uncertainty; it answers the question of \"What an entity is\" and thus defines both its essence and the nature of its characteristics. The concept of information has different meanings in different contexts. Thus the concept becomes synonymous to notions of constraint, communication, control, data, form, education, knowledge, meaning, understanding, mental stimuli, pattern, perception, proposition, representation, and entropy.\nInformation is associated with data. The difference is that information resolves uncertainty. Data can represent redundant symbols, but approaches information through optimal data compression.\nInformation can be transmitted in time, via data storage, and space, via communication and telecommunication. Information is expressed either as the content of a message or through direct or indirect observation. That which is perceived can be construed as a message in its own right, and in that sense, information is always conveyed as the content of a message.\nInformation can be encoded into various forms for transmission and interpretation (for example, information may be encoded into a sequence of signs, or transmitted via a signal). It can also be encrypted for safe storage and communication.\nThe uncertainty of an event is measured by its probability of occurrence. Uncertainty is inversely proportional to the probability of occurrence. Information theory takes advantage of this fact by concluding that more uncertain events require more information to resolve their uncertainty. The bit is a typical unit of information. It is 'that which reduces uncertainty by half'. Other units such as the nat may be used. For example, the information encoded in one \"fair\" coin flip is log2(2/1) = 1 bit, and in two fair coin flips is log2(4/1) = 2 bits. A 2011 Science article estimated that 97% of technologically stored information was already in digital bits in 2007, and that the year 2002 was the beginning of the digital age for information storage (with digital storage capacity bypassing analog for the first time).",
                    "URL": "https://en.wikipedia.org/wiki/Information"
                },
                "cuckoo": {
                    "Score": "0.8528167",
                    "Summary": "Cuckoos are birds in the Cuculidae  family, the sole taxon in the order Cuculiformes . The cuckoo family includes the common or European cuckoo, roadrunners, koels, malkohas, couas, coucals and anis. The coucals and anis are sometimes separated as distinct families, the Centropodidae and Crotophagidae respectively. The cuckoo order Cuculiformes is one of three that make up the Otidimorphae, the other two being the turacos and the bustards.\nThe cuckoos are generally medium-sized slender birds. Most species live in trees, though a sizeable minority are ground-dwelling. The family has a cosmopolitan distribution; the majority of species are tropical. Some species are migratory. The cuckoos feed on insects, insect larvae and a variety of other animals, as well as fruit. Some species are brood parasites, laying their eggs in the nests of other species and giving rise to the metaphor cuckoo's egg, but the majority of species raise their own young.\nCuckoos have played a role in human culture for thousands of years, appearing in Greek mythology as sacred to the goddess Hera. In Europe, the cuckoo is associated with spring, and with cuckoldry, for example in Shakespeare's Love's Labour's Lost. In India, cuckoos are sacred to Kamadeva, the god of desire and longing, whereas in Japan, the cuckoo symbolises unrequited love.",
                    "URL": "https://en.wikipedia.org/wiki/Cuckoo"
                },
                "commons": {
                    "Score": "0.84935623",
                    "Summary": "The commons is the cultural and natural resources accessible to all members of a society, including natural materials such as air, water, and a habitable earth. These resources are held in common, not owned privately. Commons can also be understood as natural resources that groups of people (communities, user groups) manage for individual and collective benefit. Characteristically, this involves a variety of informal norms and values (social practice) employed for a governance mechanism.\nCommons can be also defined as a social practice of governing a resource not by state or market but by a community of users that self-governs the resource through institutions that it creates.",
                    "URL": "https://en.wikipedia.org/wiki/Commons"
                },
                "subsequent": {
                    "Score": "0.8473225",
                    "Summary": "",
                    "URL": "https://en.wikipedia.org/wiki/Subsequent"
                },
                "mind": {
                    "Score": "0.8426671",
                    "Summary": "The mind is the set of faculties responsible for mental phenomena. Often the term is also identified with the phenomena themselves. These faculties include thought, imagination, memory, will and sensation. They are responsible for various mental phenomena, like perception, pain experience, belief, desire, intention and emotion. Various overlapping classifications of mental phenomena have been proposed. Important distinctions group them together according to whether they are sensory, propositional, intentional, conscious or occurrent. Minds were traditionally understood as substances but it is more common in the contemporary perspective to conceive them as properties or capacities possessed by humans and higher animals. Various competing definitions of the exact nature of the mind or mentality have been proposed. Epistemic definitions focus on the privileged epistemic access the subject has to these states. Consciousness-based approaches give primacy to the conscious mind and allow unconscious mental phenomena as part of the mind only to the extent that they stand in the right relation to the conscious mind. According to intentionality-based approaches, the power to refer to objects and to represent the world is the mark of the mental. For behaviorism, whether an entity has a mind only depends on how it behaves in response to external stimuli while functionalism defines mental states in terms of the causal roles they play. Central questions for the study of mind, like whether other entities besides humans have minds or how the relation between body and mind is to be conceived, are strongly influenced by the choice of one's definition.\nMind or mentality is usually contrasted with body, matter or physicality. The issue of the nature of this contrast and specifically the relation between mind and brain is called the mind-body problem. Traditional viewpoints included dualism and idealism, which consider the mind to be non-physical. Modern views often center around physicalism and functionalism, which hold that the mind is roughly identical with the brain or reducible to physical phenomena such as neuronal activity though dualism and idealism continue to have many supporters. Another question concerns which types of beings are capable of having minds (New Scientist 8 September 2018 p10). For example, whether mind is exclusive to humans, possessed also by some or all animals, by all living things, whether it is a strictly definable characteristic at all, or whether mind can also be a property of some types of human-made machines. Different cultural and religious traditions often use different concepts of mind, resulting in different answers to these questions. Some see mind as a property exclusive to humans whereas others ascribe properties of mind to non-living entities (e.g. panpsychism and animism), to animals and to deities. Some of the earliest recorded speculations linked mind (sometimes described as identical with soul or spirit) to theories concerning both life after death, and cosmological and natural order, for example in the doctrines of Zoroaster, the Buddha, Plato, Aristotle, and other ancient Greek, Indian and, later, Islamic and medieval European philosophers.\nPsychologists such as Freud and James, and computer scientists such as Turing developed influential theories about the nature of the mind. The possibility of nonbiological minds is explored in the field of artificial intelligence, which works closely in relation with cybernetics and information theory to understand the ways in which information processing by nonbiological machines is comparable or different to mental phenomena in the human mind. The mind is also sometimes portrayed as the stream of consciousness where sense impressions and mental phenomena are constantly changing.",
                    "URL": "https://en.wikipedia.org/wiki/Mind"
                },
                "choice": {
                    "Score": "0.83746076",
                    "Summary": "A choice is the range of different things from which a being can choose.  The arrival at a choice may incorporate motivators and models.  For example, a traveler might choose a route for a journey based on the preference of arriving at a given destination at a specified time. The preferred (and therefore chosen) route can then account for information such as the length of each of the possible routes, the amount of fuel in the vehicle, traffic conditions, etc.\nSimple choices might include what to eat for dinner or what to wear on a Saturday morning – choices that have relatively low-impact on the chooser's life overall. More complex choices might involve (for example) what candidate to vote for in an election, what profession to pursue, a life partner, etc. – choices based on multiple influences and having larger ramifications.\nFreedom of choice is generally cherished, whereas a severely limited or artificially restricted choice can lead to discomfort with choosing, and possibly an unsatisfactory outcome. In contrast, a choice with excessively numerous options may lead to confusion, reduced satisfaction, regret of the alternatives not taken, and indifference in an unstructured existence;: 63 \nand the illusion that choosing an object or a course, necessarily leads to the control of that object or course, can cause psychological problems.",
                    "URL": "https://en.wikipedia.org/wiki/Choice"
                },
                "iterator": {
                    "Score": "0.83694726",
                    "Summary": "In computer programming, an iterator is an object that enables a programmer to traverse a container, particularly lists. Various types of iterators are often provided via a container's interface. Though the interface and semantics of a given iterator are fixed, iterators are often implemented in terms of the structures underlying a container implementation and are often tightly coupled to the container to enable the operational semantics of the iterator. An iterator performs traversal and also gives access to data elements in a container, but does not itself perform iteration (i.e., not without some significant liberty taken with that concept or with trivial use of the terminology). An iterator is behaviorally similar to a database cursor. Iterators date to the CLU programming language in 1974.",
                    "URL": "https://en.wikipedia.org/wiki/Iterator"
                },
                "circular buffer": {
                    "Score": "0.83417964",
                    "Summary": "In computer science, a circular buffer, circular queue, cyclic buffer or ring buffer is a data structure that uses a single, fixed-size buffer as if it were connected end-to-end. This structure lends itself easily to buffering data streams.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Circular_buffer"
                },
                "unless": {
                    "Score": "0.8338482",
                    "Summary": "Unless, first published by Fourth Estate, an imprint of Harper Collins in 2002, is the final novel by Canadian writer Carol Shields. Semi-autobiographical, it was the capstone to Shields's writing career: she died shortly after its publication in 2003. The work was widely acclaimed and nominated for the Booker Prize, the Giller Prize, the Governor General's Award, the Orange Prize for Fiction, and received the Ethel Wilson Fiction Prize. In 2011, it was a finalist in the Canada Reads competition, where it was defended by actor Lorne Cardinal. Like many of her works (especially The Stone Diaries), Unless explores the extraordinary that lies within the ordinary lives of ordinary women.\nThe novel is narrated in first person by 44-year-old writer and translator, Reta Winters. The book proceeds as a linear series of reflections by Reta, elliptically coming to the thematic center of the story: the seemingly arbitrary decision of Reta's college-aged daughter Norah to drop out of university and live on the street with a cardboard sign affixed to her chest that reads \"Goodness\". Although the novel does not in any way proceed like a mystery, the reasons for Norah's departure from the normal world are Reta's primary motivation in writing. In parallel, her relationship with her French mentor (a Holocaust survivor and poet) drives much of her narration and view of herself.\nThe novel deals extensively with the role of women and in particular, women's literature. Late in the novel, Reta starts to break from herself and write in character as a disenfranchised female writer. The underlying theme is that the lives of women are underwritten, ignored, and dealt with as \"trivial\" by the literary establishment.\nThe novel also functions largely as an investigation into the role of writing in general (independent of gender). Reta's grief over her daughter's state makes her very inwardly focussed on the process of writing. A reflection of this is shown in the title of the book and the chapter titles. \"Unless\" and the chapter titles (\"therefore\", \"else\", \"instead\") are all words that are used to couch the fragmented manner in which life fits together. As Shields writes, \"A life is full of isolated events, but these events, if they are to form a coherent narrative, require odd pieces of language to link them together, little chips of grammar (mostly adverbs or prepositions) that are hard to define [...] words like therefore, else, other, also, thereof, therefore, instead, otherwise, despite, already, and not yet.\"\nThe novel was adapted into the 2016 film Unless, which stars Catherine Keener as Reta and Hannah Gross as Norah.On November 5, 2019, the BBC News listed Unless on its list of the 100 most influential novels.",
                    "URL": "https://en.wikipedia.org/wiki/Unless"
                },
                "algorithm": {
                    "Score": "0.8321312",
                    "Summary": "In mathematics and computer science, an algorithm ( (listen)) is a finite sequence of well-defined instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations, data processing, automated reasoning, automated decision-making and other tasks. In contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.As an effective method, an algorithm can be expressed within a finite amount of space and time, and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.",
                    "URL": "https://en.wikipedia.org/wiki/Algorithm"
                },
                "consecutive": {
                    "Score": "0.8299524",
                    "Summary": "",
                    "URL": "https://en.wikipedia.org/wiki/Consecutive"
                },
                "generalization": {
                    "Score": "0.8262094",
                    "Summary": "A generalization is a form of abstraction whereby common properties of specific instances are formulated as general concepts or claims. Generalizations posit the existence of a domain or set of elements, as well as one or more common characteristics shared by those elements (thus creating a conceptual model). As such, they are the essential basis of all valid deductive inferences (particularly in logic, mathematics and science), where the process of verification is necessary to determine whether a generalization holds true for any given situation.\nGeneralization can also be used to refer to the process of identifying the parts of a whole, as belonging to the whole. The parts, which might be unrelated when left on their own, may be brought together as a group, hence belonging to the whole by establishing a common relation between them.\nHowever, the parts cannot be generalized into a whole—until a common relation is established among all parts. This does not mean that the parts are unrelated, only that no common relation has been established yet for the generalization.\nThe concept of generalization has broad application in many connected disciplines, and might sometimes have a more specific meaning in a specialized context (e.g. generalization in psychology, generalization in learning).In general, given two related concepts A and B, A is a \"generalization\" of B (equiv., B is a special case of A) if and only if both of the following hold:\n\nEvery instance of concept B is also an instance of concept A.\nThere are instances of concept A which are not instances of concept B.For example, the concept animal is a generalization of the concept bird, since every bird is an animal, but not all animals are birds (dogs, for instance). For more, see Specialisation (biology).\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Generalization"
                },
                "linear probing": {
                    "Score": "0.82482606",
                    "Summary": "Linear probing  is a scheme in computer programming for resolving collisions in hash tables, data structures for maintaining a collection of key–value pairs and looking up the value associated with a given key. It was invented in 1954 by Gene Amdahl, Elaine M. McGraw, and Arthur Samuel and first analyzed in 1963 by Donald Knuth.\nAlong with quadratic probing and double hashing, linear probing is a form of open addressing. In these schemes, each cell of a hash table stores a single key–value pair. When the hash function causes a collision by mapping a new key to a cell of the hash table that is already occupied by another key, linear probing searches the table for the closest following free location and inserts the new key there. Lookups are performed in the same way, by searching the table sequentially starting at the position given by the hash function, until finding a cell with a matching key or an empty cell.\nAs Thorup & Zhang (2012) write, \"Hash tables are the most commonly used nontrivial data structures, and the most popular implementation on standard hardware uses linear probing, which is both fast and simple.\"\nLinear probing can provide high performance because of its good locality of reference, but is more sensitive to the quality of its hash function than some other collision resolution schemes. It takes constant expected time per search, insertion, or deletion when implemented using a random hash function, a 5-independent hash function, or tabulation hashing. Good results can also be achieved in practice with other hash functions such as MurmurHash.",
                    "URL": "https://en.wikipedia.org/wiki/Linear_probing"
                },
                "individual": {
                    "Score": "0.8238087",
                    "Summary": "An individual is that which exists as a distinct entity. Individuality (or self-hood) is the state or quality of being an individual; particularly (in the case of humans) of being a person unique from other people and possessing one's own  needs or goals, rights and  responsibilities. The concept of an individual features in diverse fields, including biology, law, and philosophy.",
                    "URL": "https://en.wikipedia.org/wiki/Individual"
                },
                "implementation": {
                    "Score": "0.82228273",
                    "Summary": "Implementation is the realization of an application, or execution of a plan, idea, model, design, specification, standard, algorithm, or policy.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Implementation"
                },
                "array": {
                    "Score": "0.81993854",
                    "Summary": "An array is a systematic arrangement of similar objects, usually in rows and columns.\nThings called an array include:\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Array"
                },
                "present": {
                    "Score": "0.81970227",
                    "Summary": "The present (or here and now) is the time that is associated with the events perceived directly and in the first time, not as a recollection (perceived more than once) or a speculation (predicted, hypothesis, uncertain). It is a period of time between the past and the future, and can vary in meaning from being an instant to a day or longer.\nIt is sometimes represented as a hyperplane in space-time, typically called \"now\", although modern physics demonstrates that such a hyperplane cannot be defined uniquely for observers in relative motion. The present may also be viewed as a duration (see specious present).",
                    "URL": "https://en.wikipedia.org/wiki/Present"
                },
                "second": {
                    "Score": "0.8162671",
                    "Summary": "The second (symbol: s, also abbreviated: sec) is the base unit of time in the International System of Units (SI) (French: Système International d’unités), commonly understood and historically defined as 1⁄86400 of a day – this factor derived from the division of the day first into 24 hours, then to 60 minutes and finally to 60 seconds each. Analog clocks and watches often have sixty tick marks on their faces, representing seconds (and minutes), and a \"second hand\" to mark the passage of time in seconds.  Digital clocks and watches often have a two-digit seconds counter. The second is also part of several other units of measurement like meters per second for speed, meters per second per second for acceleration, and cycles per second for frequency.\n\nAlthough the historical definition of the unit was based on this division of the Earth's rotation cycle, the formal definition in the International System of Units (SI) is a much steadier timekeeper:The second is defined as being equal to the time duration of 9,192,631,770 periods of the radiation corresponding to the transition between the two hyperfine levels of the fundamental unperturbed ground-state of the caesium-133 atom.\nBecause the Earth's rotation varies and is also slowing very slightly, a leap second is added at irregular intervals to clock time to keep clocks in sync with Earth's rotation.\nMultiples of seconds are usually counted in hours and minutes. Fractions of a second are usually counted in tenths or hundredths. In scientific work, small fractions of a second are counted in milliseconds (thousandths), microseconds (millionths), nanoseconds (billionths), and sometimes smaller units of a second. An everyday experience with small fractions of a second is a 1-gigahertz microprocessor which has a cycle time of 1 nanosecond. Camera shutter speeds are often expressed in fractions of a second, such as 1⁄30 second or 1⁄1000 second.\nSexagesimal divisions of the day from a calendar based on astronomical observation have existed since the third millennium BC, though they were not seconds as we know them today. Small divisions of time could not be measured back then, so such divisions were mathematically derived. The first timekeepers that could count seconds accurately were pendulum clocks invented in the 17th century. Starting in the 1950s, atomic clocks became better timekeepers than Earth's rotation, and they continue to set the standard today.",
                    "URL": "https://en.wikipedia.org/wiki/Second"
                },
                "pattern": {
                    "Score": "0.8153619",
                    "Summary": "A pattern is a regularity in the world, in human-made design, or in abstract ideas. As such, the elements of a pattern repeat in a predictable manner. A geometric pattern is a kind of pattern formed of geometric shapes and typically repeated like a wallpaper design.\nAny of the senses may directly observe patterns. Conversely, abstract patterns in science, mathematics, or language may be observable only by analysis. Direct observation in practice means seeing visual patterns, which are widespread in nature and in art. Visual patterns in nature are often chaotic, rarely exactly repeating, and often involve fractals. Natural patterns include spirals, meanders, waves, foams, tilings, cracks, and those created by symmetries of rotation and reflection. Patterns have an underlying mathematical structure; indeed, mathematics can be seen as the search for regularities, and the output of any function is a mathematical pattern. Similarly in the sciences, theories explain and predict regularities in the world.\nIn art and architecture, decorations or visual motifs may be combined and repeated to form patterns designed to have a chosen effect on the viewer. In computer science, a software design pattern is a known solution to a class of problems in programming. In fashion, the pattern is a template used to create any number of similar garments.",
                    "URL": "https://en.wikipedia.org/wiki/Pattern"
                },
                "hash table": {
                    "Score": "0.800812",
                    "Summary": "In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index, also called a hash code, into an array of buckets or slots, from which the desired value can be found. During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored.\nIdeally, the hash function will assign each key to a unique bucket, but most hash table designs employ an imperfect hash function, which might cause hash collisions where the hash function generates the same index for more than one key. Such collisions are typically accommodated in some way.\nIn a well-dimensioned hash table, the average cost (number of instructions) for each lookup is independent of the number of elements stored in the table. Many hash table designs also allow arbitrary insertions and deletions of key–value pairs, at (amortized) constant average cost per operation.In many situations, hash tables turn out to be on average more efficient than search trees or any other table lookup structure. For this reason, they are widely used in many kinds of computer software, particularly for associative arrays, database indexing, caches, and sets.",
                    "URL": "https://en.wikipedia.org/wiki/Hash_table"
                },
                "parent": {
                    "Score": "0.8078968",
                    "Summary": "A parent  is a caregiver of the offspring in their own species. In humans, a parent is the caretaker of a child (where \"child\" refers to offspring, not necessarily age). A biological parent is a person whose gamete resulted in a child, a male through the sperm, and a female through the ovum. Biological parents are first-degree relatives and have 50% genetic meet. A female can also become a parent through surrogacy. Some parents may be adoptive parents, who nurture and raise an offspring, but are not biologically related to the child. Orphans without adoptive parents can be raised by their grandparents or other family members.\n\nIt is not legal for parents to sell their kids, for profit or not, and be able to trade them against their will. \nA parent can also be elaborated as an ancestor removed one generation. With recent medical advances, it is possible to have more than two biological parents. Examples of third biological parents include instances involving surrogacy or a third person who has provided DNA samples during an assisted reproductive procedure that has altered the recipients' genetic material.The most common types of parents are mothers, fathers, step-parents, and grandparents. A mother is, \"a woman in relation to a child or children to whom she has given birth.\" The extent to which it is socially acceptable for a parent to be involved in their offspring's life varies from culture to culture, however one that exhibits too little involvement is sometimes said to exhibit child neglect, while one that is too involved is sometimes said to be overprotective, cosseting, nosey, or intrusive.",
                    "URL": "https://en.wikipedia.org/wiki/Parent"
                },
                "cost": {
                    "Score": "0.80104965",
                    "Summary": "In production, research, retail, and accounting, a cost is the value of money that has been used up to produce something or deliver a service, and hence is not available for use anymore. In business, the cost may be one of acquisition, in which case the amount of money expended to acquire it is counted as cost. In this case, money is the input that is gone in order to acquire the thing. This acquisition cost may be the sum of the cost of production as incurred by the original producer, and further costs of transaction as incurred by the acquirer over and above the price paid to the producer. Usually, the price also includes a mark-up for profit over the cost of production.\nMore generalized in the field of economics, cost is a metric that is totaling up as a result of a process or as a differential for the result of a decision.  Hence cost is the metric used in the standard modeling paradigm applied to economic processes.\nCosts (pl.) are often further described based on their timing or their applicability.",
                    "URL": "https://en.wikipedia.org/wiki/Cost"
                }
            }
        },
        {
            "start_timestamp": "00:40:14",
            "title": "ROBIN HOOD HASHING",
            "text": "ROBIN HOOD HASHING\n\n \n\n \n\n \n\n \n\n \n\n \n\n \n\n| val\nA\nB | val\nCc\nD | val\nK\nF",
            "transcript": "So uh that was linear pro patching the next one uh next hashing scheme, we're going to talk about is called robinhood hashing. It's named after uh robin hood. The outlaw from english folklore uh, who you may be familiar with he stole from the rich and and gave uh to the poor and kind of the the algorithm is, gets its name from from that kind of uh idea. So it's it's basically a variant of linear pro hashing, that's going to steal slots from rich keys and I'll explain what a rich key is in a minute and give them to poorer keys. So, basically, each key is going to track the number of positions that they are from where they should have been inserted in the hash table. So, if you think about on the previous slides, when you have a collision, sometimes we had to scan forward to find an empty slot to insert a key into so basically, each key is tracking the number of positions that you had to scan forward in order to find the empty slot and, what's going to happen, is on on insert in the the robinhood algorithm. A key will take the slot of another key if the first key is farther away from its optimal position than the second key, so we'll we'll kind of go through a visual example of this. I think it'll be easier to understand. So again we have these keys here and we have our our hash table, we're going to hash key a, and that goes at at offset two and what we're storing now, in addition to the key, a and the value, we're also storing this number of jumps from the first position, so a got inserted into exactly the spot where we, the hash function, said it should be inserted, so that has a value of zero. So now, our next key b again, we insert the key b as well as the associated value, as well as the number of jumps since the first position. So that's zero key c here well c and a have a collision, but in this case a is zero slots. Since it's uh a has a value of zero in its jump position c also has a value uh of zero in its jump position, they're equal. So when we're not going to replace ka we're going to move c down to this slot and we're going to insert it with a jump value of 1.. So we have this value 1 now, because c was inserted, one position away from where the hash function said it should be so d. Let's say hashes to this uh case here. We're going to see that c is has a jump position of one d: has a jump position of zero, so c is greater than d. We're not going to replace c we're going to insert d here with a jump position of one, and now we have e, which is going to hash, to let's say the slot where a is stored. So at this point a is equal to zero and e is equal to zero. So we're not going to replace a uh c is equal to one and e is equal to one, so we're not going to replace c. Now we see that d is equal to 1, which is richer or closer to where it should be, then e, which is now equal to 2, because we've had to do these two jumps from where we said e should be inserted. So in this case we're going to replace d with e and store uh, the the two jumps in the the jump position and then we're going to insert d right below it with also two jumps in the jump position. So now again, just to finish f comes along d. Has two f has zero, so f is going to go in that that bottom slot so kind of th. This algorithm is shown to like reduce the the variance in in the key displacement, so that means the number of jumps or the number of uh positions. The key uh. The insertion position is from where the hash function says it should be so it's it. It reduces the variance in the displacement relative to uh, linear hashing. All of this depends on you know when the keys arrive, so this this depends on the order that we inserted the keys if we inserted them in a different order. We'd get a different answer. Usually this this isn't very efficient in practice due to uh all of the branch missed predictions that you have with the comparisons and then the the excessive copying so usually in practice, uh people tend to implement just just plain linear, hashing uh, and then you know deal with the the uh less advantageous theoretical aspects, but this this is kind of how the the uh robin hood hashing scheme works. So are there any questions about this? I know it was a little bit complicated to walk through here, but any questions. Great okay, so we've seen linear probing, we've seen robin hood hashing uh.",
            "transcript-corrected": "So, uh that was linear pro patching the next one uh, next hashing scheme, we're going to talk about is called robin hood hashing. It's named after uh robin hood. The outlaw from English folklore uh, who you may be familiar with he stole from the rich and gave uh to the poor and kind of the algorithm is, gets its name from from that kind of uh idea. So it's it's basically a variant of linear pro hashing, that's going to steal slots from rich keys and I'll explain what a rich key is in a minute and give them to poorer keys. So, basically, each key is going to track the number of positions that they are from where they should have been inserted into the hash table. So, if you think about on the previous slides, when you have a collision, sometimes we had to scan forward to find an empty slot to insert a key into so basically, each key is tracking the number of positions that you had to scan forward in order to find the empty slot and, what's going to happen, is on on the insert in the robin hood algorithm. A key will take the slot of another key if the first key is farther away from its optimal position than the second key, so we'll we'll kind of go through a visual example of this. I think it'll be easier to understand. So again we have these keys here and we have our our hash table, we're going to hash key a, and that goes at at offset two and what we're storing now, in addition to the key, a and the value, we're also storing this number of jumps from the first position, so a got inserted into exactly the spot where we, the hash function, said it should be inserted, so that has a value of zero. So now, our next key b again, we insert the key b as well as the associated value, as well as the number of jumps since the first position. So that's zero key c here well c and a have a collision, but in this case a is zero slots. Since it's, uh a has a value of zero in its jump position c also has a value uh of zero in its jump position, they're equal. So when we're not going to replace ka we're going to move c down to this slot and we're going to insert it with a jump value of 1.. So we have this value 1 now, because c was inserted, one position away from where the hash function said it should be so d. Let's say hashes to this uh case here. We're going to see that c has a jump position of one d: has a jump position of zero, so c is greater than d. We're not going to replace a c we're going to insert d here with a jump position of one, and now we have e, which is going to hash, to let's say the slot where a is stored. So at this point a is equal to zero and e is equal to zero. So we're not going to replace a uh c is equal to one and e is equal to one, so we're not going to replace c. Now we see that d is equal to 1, which is richer or closer to where it should be, then e, which is now equal to 2, because we've had to do these two jumps from where we said we should be inserted. So in this case, we're going to replace with e and store, uh, the two jumps in the jump position and then we're going to insert d right below it  also two jumps in the jump position. So now again, just to finish f comes along d. Has two f has zero, so f is going to go into that that bottom slot so kind of the. This algorithm is shown to like reduce the variance in in the key displacement, so that means the number of jumps or the number of uh positions. The key uh. The insertion position is from where the hash function says it should be so it's it's. It reduces the variance in the displacement relative to, uh, linear hashing. All of this depends on you know when the keys arrive, so this this depends on the order that we inserted the keys if we inserted them in a different order. We'd get a different answer. Usually this this isn't very efficient in practice due to, uh all of the branch missed predictions that you have with the comparisons and then the excessive copying so usually in practice, uh, people tend to implement just just plain linear, hashing uh, and then you know deal with the uh less advantageous theoretical aspects, but this is kind of how the uh robin hood hashing scheme works. So are there any questions about this? I know it was a little bit complicated to walk through here, but any questions. Great, okay, so we've seen linear probing, we've seen robin hood hashing uh.",
            "summary_brief": "In the previous slides, we talked about linear pro patching the next hashing scheme, we're going to talk about linear pro patching the next hashing scheme, we're going to talk about linear pro patching the next hashing scheme, we're going to talk about linear pro patching the next hashing scheme, we",
            "summary_detailed": "Robin hood hashing is a variant of linear pro hashing, that's going to steal slots from rich keys and I'll explain what a rich key is in a minute. A key will take the slot of another key if the first key is farther away from its optimal position than the second key. This algorithm is shown to reduce the variance in in the key displacement.",
            "key_concepts": {
                "minutes": {
                    "Score": "0.9066932",
                    "Summary": "Minutes, also known as minutes of meeting (abbreviation MoM), protocols or, informally, notes, are the instant written record of a meeting or hearing. They typically describe the events of the meeting and may include a list of attendees, a statement of the issues considered by the participants, and related responses or decisions for the issues.",
                    "URL": "https://en.wikipedia.org/wiki/Minutes"
                },
                "familiar": {
                    "Score": "0.90630096",
                    "Summary": "In European folklore of the medieval and early modern periods, familiars (sometimes referred to as familiar spirits) were believed to be supernatural entities that would assist witches and cunning folk in their practice of magic. According to records of the time, those alleging to have had contact with familiar spirits reported that they could manifest as numerous forms, usually as an animal, but sometimes as a human or humanoid figure, and were described as \"clearly defined, three-dimensional... forms, vivid with colour and animated with movement and sound\", as opposed to descriptions of ghosts with their \"smoky, undefined form[s]\".When they served witches, they were often thought to be malevolent, but when working for cunning folk they were often considered benevolent (although there was some ambiguity in both cases). The former were often categorized as demons, while the latter were more commonly thought of and described as fairies. The main purpose of familiars was to serve the witch or young witch, providing protection for them as they came into their new powers.Since the 20th century some magical practitioners, including adherents of the Neopagan religion of Wicca, use the concept of familiars, due to their association with older forms of magic. These contemporary practitioners use pets or wildlife, or believe that invisible versions of familiars act as magical aids.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Familiar"
                },
                "algorithm": {
                    "Score": "0.9048034",
                    "Summary": "In mathematics and computer science, an algorithm ( (listen)) is a finite sequence of well-defined instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations, data processing, automated reasoning, automated decision-making and other tasks. In contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.As an effective method, an algorithm can be expressed within a finite amount of space and time, and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.",
                    "URL": "https://en.wikipedia.org/wiki/Algorithm"
                },
                "comparison": {
                    "Score": "0.9009544",
                    "Summary": "Comparison or comparing is the act of evaluating two or more things by determining the relevant, comparable characteristics of each thing, and then determining which characteristics of each are similar to the other, which are different, and to what degree. Where characteristics are different, the differences may then be evaluated to determine which thing is best suited for a particular purpose. The description of similarities and differences found between the two things is also called a comparison. Comparison can take many distinct forms, varying by field:\n\nTo compare is to bring two or more things together (physically or in contemplation) and to examine them systematically, identifying similarities and differences among them. Comparison has a different meaning within each framework of study. Any exploration of the similarities or differences of two or more units is a comparison. In the most limited sense, it consists of comparing two units isolated from each other.\nTo compare things, they must have characteristics that are similar enough in relevant ways to merit comparison. If two things are too different to compare in a useful way, an attempt to compare them is colloquially referred to in English as \"comparing apples and oranges.\" Comparison is widely used in society, in science and in the arts.",
                    "URL": "https://en.wikipedia.org/wiki/Comparison"
                },
                "name": {
                    "Score": "0.89617485",
                    "Summary": "A name is a term used for identification by an external observer. They can identify a class or category of things, or a single thing, either uniquely, or within a given context. The entity identified by a name is called its referent. A personal name identifies, not necessarily uniquely, a specific individual human. The name of a specific entity is sometimes called a proper name (although that term has a philosophical meaning as well) and is, when consisting of only one word, a proper noun. Other nouns are sometimes called \"common names\" or (obsolete) \"general names\". A name can be given to a person, place, or thing; for example, parents can give their child a name or a scientist can give an element a name.",
                    "URL": "https://en.wikipedia.org/wiki/Name"
                },
                "second": {
                    "Score": "0.89599085",
                    "Summary": "The second (symbol: s, also abbreviated: sec) is the base unit of time in the International System of Units (SI) (French: Système International d’unités), commonly understood and historically defined as 1⁄86400 of a day – this factor derived from the division of the day first into 24 hours, then to 60 minutes and finally to 60 seconds each. Analog clocks and watches often have sixty tick marks on their faces, representing seconds (and minutes), and a \"second hand\" to mark the passage of time in seconds.  Digital clocks and watches often have a two-digit seconds counter. The second is also part of several other units of measurement like meters per second for speed, meters per second per second for acceleration, and cycles per second for frequency.\n\nAlthough the historical definition of the unit was based on this division of the Earth's rotation cycle, the formal definition in the International System of Units (SI) is a much steadier timekeeper:The second is defined as being equal to the time duration of 9,192,631,770 periods of the radiation corresponding to the transition between the two hyperfine levels of the fundamental unperturbed ground-state of the caesium-133 atom.\nBecause the Earth's rotation varies and is also slowing very slightly, a leap second is added at irregular intervals to clock time to keep clocks in sync with Earth's rotation.\nMultiples of seconds are usually counted in hours and minutes. Fractions of a second are usually counted in tenths or hundredths. In scientific work, small fractions of a second are counted in milliseconds (thousandths), microseconds (millionths), nanoseconds (billionths), and sometimes smaller units of a second. An everyday experience with small fractions of a second is a 1-gigahertz microprocessor which has a cycle time of 1 nanosecond. Camera shutter speeds are often expressed in fractions of a second, such as 1⁄30 second or 1⁄1000 second.\nSexagesimal divisions of the day from a calendar based on astronomical observation have existed since the third millennium BC, though they were not seconds as we know them today. Small divisions of time could not be measured back then, so such divisions were mathematically derived. The first timekeepers that could count seconds accurately were pendulum clocks invented in the 17th century. Starting in the 1950s, atomic clocks became better timekeepers than Earth's rotation, and they continue to set the standard today.",
                    "URL": "https://en.wikipedia.org/wiki/Second"
                },
                "copying": {
                    "Score": "0.8947021",
                    "Summary": "Copying is the duplication of information or an artifact based on an instance of that information or artifact, and not using the process that originally generated it. With analog forms of information, copying is only possible to a limited degree of accuracy, which depends on the quality of the equipment used and the skill of the operator. There is some inevitable generation loss, deterioration and accumulation of \"noise\" (random small changes) from original to copy when copies are made. This deterioration accumulates with each generation. With digital forms of information, copying is perfect. Copy and paste is frequently used by a computer user when they select and copy an area of text or content.\nMost high-accuracy copying techniques use the principle that there will be only one type of possible interpretation for each reading of data and only one possible way to write an interpretation of data or data classes.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Copying"
                },
                "hash table": {
                    "Score": "0.8934037",
                    "Summary": "In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index, also called a hash code, into an array of buckets or slots, from which the desired value can be found. During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored.\nIdeally, the hash function will assign each key to a unique bucket, but most hash table designs employ an imperfect hash function, which might cause hash collisions where the hash function generates the same index for more than one key. Such collisions are typically accommodated in some way.\nIn a well-dimensioned hash table, the average cost (number of instructions) for each lookup is independent of the number of elements stored in the table. Many hash table designs also allow arbitrary insertions and deletions of key–value pairs, at (amortized) constant average cost per operation.In many situations, hash tables turn out to be on average more efficient than search trees or any other table lookup structure. For this reason, they are widely used in many kinds of computer software, particularly for associative arrays, database indexing, caches, and sets.",
                    "URL": "https://en.wikipedia.org/wiki/Hash_table"
                },
                "richer": {
                    "Score": "0.87876475",
                    "Summary": "Richer, or Richers, is a surname, and may refer to:\n\nBob Richer (born 1951), ice hockey defenceman, played for the Buffalo Sabres\nClaude Lavoie Richer, Canadian skier at the 1952 Winter Olympics\nEdmond Richer, French theologian\nHerbert Richers, film and dubbing producer\nRobert Richers, English politician in the 16th century\nJulian Richer, founded British hi-fi retailers Richer Sounds\nLyse Richer, Canadian administrator and music teacher\nRobert Richer\nStéphane Richer (ice hockey defenceman)\nStéphane Richer (ice hockey forward)\nJean RicherIt may also refer to:\n\nRicher, Manitoba\nRicherus, monk of St. Remi at Reims\n\"Richers\", a pejorative for rich people (who all happen to be black) in the South Park episode \"Here Comes the Neighborhood\"",
                    "URL": "https://en.wikipedia.org/wiki/Richer"
                },
                "advantageous": {
                    "Score": "0.87471366",
                    "Summary": "Advantageous is a 2015 American science fiction drama film directed by Jennifer Phang and written by Jacqueline Kim and Jennifer Phang. The film stars Jacqueline Kim, James Urbaniak, Freya Adams, Ken Jeong, Jennifer Ehle, and Samantha Kim. The film was released exclusively to Netflix on June 23, 2015.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Advantageous"
                },
                "prediction": {
                    "Score": "0.87169003",
                    "Summary": "A prediction (Latin præ-, \"before,\" and dicere, \"to say\"), or forecast, is a statement about a future event or data. They are often, but not always, based upon experience or knowledge. There is no universal agreement about the exact difference from \"estimation\"; different authors and disciplines ascribe different connotations.\nAlthough future events are necessarily uncertain, so guaranteed accurate information about the future is impossible. Prediction can be useful to assist in making plans about possible developments; Howard H. Stevenson writes that prediction in business \"is at least two things: Important and hard.\"",
                    "URL": "https://en.wikipedia.org/wiki/Prediction"
                },
                "folklore": {
                    "Score": "0.86479974",
                    "Summary": "Folklore is the expressive body of culture shared by a particular group of people; it encompasses the traditions common to that culture, subculture or group. This includes oral traditions such as tales, proverbs and jokes. They include material culture, ranging from traditional building styles to handmade toys common to the group. Folklore also includes customary lore, taking actions for folk beliefs, the forms and rituals of celebrations such as Christmas and weddings, folk dances and initiation rites. Each one of these, either singly or in combination, is considered a folklore artifact. Just as essential as the form, folklore also encompasses the transmission of these artifacts from one region to another or from one generation to the next. Folklore is not something one can typically gain in a formal school curriculum or study in the fine arts. Instead, these traditions are passed along informally from one individual to another either through verbal instruction or demonstration. The academic study of folklore is called folklore studies or folkloristics, and it can be explored at undergraduate, graduate and Ph.D. levels.",
                    "URL": "https://en.wikipedia.org/wiki/Folklore"
                },
                "linear probing": {
                    "Score": "0.86455244",
                    "Summary": "Linear probing  is a scheme in computer programming for resolving collisions in hash tables, data structures for maintaining a collection of key–value pairs and looking up the value associated with a given key. It was invented in 1954 by Gene Amdahl, Elaine M. McGraw, and Arthur Samuel and first analyzed in 1963 by Donald Knuth.\nAlong with quadratic probing and double hashing, linear probing is a form of open addressing. In these schemes, each cell of a hash table stores a single key–value pair. When the hash function causes a collision by mapping a new key to a cell of the hash table that is already occupied by another key, linear probing searches the table for the closest following free location and inserts the new key there. Lookups are performed in the same way, by searching the table sequentially starting at the position given by the hash function, until finding a cell with a matching key or an empty cell.\nAs Thorup & Zhang (2012) write, \"Hash tables are the most commonly used nontrivial data structures, and the most popular implementation on standard hardware uses linear probing, which is both fast and simple.\"\nLinear probing can provide high performance because of its good locality of reference, but is more sensitive to the quality of its hash function than some other collision resolution schemes. It takes constant expected time per search, insertion, or deletion when implemented using a random hash function, a 5-independent hash function, or tabulation hashing. Good results can also be achieved in practice with other hash functions such as MurmurHash.",
                    "URL": "https://en.wikipedia.org/wiki/Linear_probing"
                },
                "english folklore": {
                    "Score": "0.8614299",
                    "Summary": "English folklore consists of the myths and legends of England, including the English region's mythical creatures, traditional recipes, urban legends, and folktales. English folklore encompasses the traditional Robin Hood tales, the Brythonic-inspired Arthurian legend, and the more contemporary urban legends and monsters such as the Beast of Bodmin Moor. English folklore takes a heavy influence from Pagan tradition, with a number of figures, legends, and creatures being adapted from the pre-Christian traditions of the region. This Pagan influence means that English folklore generally differs between regions in the country, however some myths pervade most of the country.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/English_folklore"
                },
                "question": {
                    "Score": "0.86058426",
                    "Summary": "A question is an utterance which typically functions as a request for information, which is expected to be provided in the form of an answer. Questions can thus be understood as a kind of illocutionary act in the field of pragmatics or as special kinds of propositions in frameworks of formal semantics such as alternative semantics or inquisitive semantics. Questions are often conflated with interrogatives, which are the grammatical forms typically used to achieve them. Rhetorical questions, for example, are interrogative in form but may not be considered true questions as they are not expected to be answered.",
                    "URL": "https://en.wikipedia.org/wiki/Question"
                },
                "hash function": {
                    "Score": "0.85302526",
                    "Summary": "A hash function is any function that can be used to map data of arbitrary size to fixed-size values. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes.  The values are usually used to index a fixed-size table called a hash table. Use of a hash function to index a hash table is called hashing or scatter storage addressing.\nHash functions and their associated hash tables are used in data storage and retrieval applications to access data in a small and nearly constant time per retrieval. They require an amount of storage space only fractionally greater than the total space required for the data or records themselves. Hashing is a computationally and storage space-efficient form of data access that avoids the non-linear access time of ordered and unordered lists and structured trees, and the often exponential storage requirements of direct access of state spaces of large or variable-length keys.\nUse of hash functions relies on statistical properties of key and function interaction: worst-case behaviour is intolerably bad with a vanishingly small probability, and average-case behaviour can be nearly optimal (minimal collision).Hash functions are related to (and often confused with) checksums, check digits, fingerprints, lossy compression, randomization functions, error-correcting codes, and ciphers. Although the concepts overlap to some extent, each one has its own uses and requirements and is designed and optimized differently. The hash functions differ from the concepts numbered mainly in terms of data integrity.",
                    "URL": "https://en.wikipedia.org/wiki/Hash_function"
                },
                "linear hashing": {
                    "Score": "0.85182446",
                    "Summary": "Linear hashing (LH) is a dynamic data structure which implements a hash table and grows or shrinks one bucket at a time. It was invented by Witold Litwin in 1980.  It has been analyzed by Baeza-Yates and Soza-Pollman. \nIt is the first in a number of schemes known as dynamic hashing\n \nsuch as Larson's Linear Hashing with Partial Extensions, \n\nLinear Hashing with Priority Splitting,\n\nLinear Hashing with Partial Expansions and Priority Splitting,\n\nor Recursive Linear Hashing.\nThe file structure of a dynamic hashing data structure adapts itself to changes in the size of the file, so expensive periodic file reorganization is avoided. A Linear Hashing file expands by splitting\na pre-determined bucket into two and contracts by merging two predetermined buckets into one. The trigger for a reconstruction depends on the flavor of the scheme; it could be an overflow at a bucket or  load factor (number of records over the number of buckets) moving outside of a predetermined range.Linear Hashing has also been made into a scalable distributed data structure, LH*. In LH*, each bucket resides at a different server.\n LH* itself has been expanded to provide data availability in the presence of\nfailed buckets.\n Key based operations (inserts, deletes, updates, reads) in LH and \nLH* take maximum constant time independent of the number of buckets and hence of records.",
                    "URL": "https://en.wikipedia.org/wiki/Linear_hashing"
                },
                "first position": {
                    "Score": "0.8388457",
                    "Summary": "First Position is a 2011 American documentary film. It follows six young dancers preparing for the Youth America Grand Prix in New York City, an annual competition for dancers ages 9–19 to earn a place at an elite ballet company or school. Directed by Bess Kargman, it features Michaela DePrince, Aran Bell, Gaya Bommer-Yemini, Miko Fogarty, Jules Fogarty, Joan Sebastian Zamora and Rebecca Houseknecht as they intensively train and prepare for what could be the turning point of their lives.\nThe title 'First Position' is taken from one of the five standard positions of the feet in classical ballet.\nKargman was a first-time director who had studied dance herself.  \"I ended up quitting my job to make this film, my first film, and I thought maybe by choosing a topic that was quite dear to me and that I had lived for a number of years growing up—maybe I’d be able to do this story justice.\" The film features renowned dancers and choreographers from all over the world including Nadine Bommer, Denys Ganio,  Élisabeth Platel, Raymond Lukens, and Youth America Grand Prix's founder Larissa Saveliev.",
                    "URL": "https://en.wikipedia.org/wiki/First_Position"
                },
                "number": {
                    "Score": "0.8318525",
                    "Summary": "A number is a mathematical object used to count, measure, and label. The original examples are the natural numbers 1, 2, 3, 4, and so forth. Numbers can be represented in language with number words. More universally, individual numbers can be represented by symbols, called numerals; for example, \"5\" is a numeral that represents the number five. As only a relatively small number of symbols can be memorized, basic numerals are commonly organized in a numeral system, which is an organized way to represent any number. The most common numeral system is the Hindu–Arabic numeral system, which allows for the representation of any number using a combination of ten fundamental numeric symbols, called digits. In addition to their use in counting and measuring, numerals are often used for labels (as with telephone numbers), for ordering (as with serial numbers), and for codes (as with ISBNs). In common usage, a numeral is not clearly distinguished from the number that it represents.\nIn mathematics, the notion of a number has been extended over the centuries to include 0, negative numbers, rational numbers such as one half \n  \n    \n      \n        \n          (\n          \n            \n              \n                1\n                2\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\tfrac {1}{2}}\\right)}\n  , real numbers such as the square root of 2 \n  \n    \n      \n        \n          (\n          \n            \n              2\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\sqrt {2}}\\right)}\n   and π, and complex numbers which extend the real numbers with a square root of −1 (and its combinations with real numbers by adding or subtracting its multiples). Calculations with numbers are done with arithmetical operations, the most familiar being addition, subtraction, multiplication, division, and exponentiation. Their study or usage is called arithmetic, a term which may also refer to number theory, the study of the properties of numbers.\nBesides their practical uses, numbers have cultural significance throughout the world. For example, in Western society, the number 13 is often regarded as unlucky, and \"a million\" may signify \"a lot\" rather than an exact quantity. Though it is now regarded as pseudoscience, belief in a mystical significance of numbers, known as numerology, permeated ancient and medieval thought. Numerology heavily influenced the development of Greek mathematics, stimulating the investigation of many problems in number theory which are still of interest today.During the 19th century, mathematicians began to develop many different abstractions which share certain properties of numbers, and may be seen as extending the concept. Among the first were the hypercomplex numbers, which consist of various extensions or modifications of the complex number system. In modern mathematics, number systems (sets) are considered important special examples of more general categories such as rings and fields, and the application of the term \"number\" is a matter of convention, without fundamental significance.",
                    "URL": "https://en.wikipedia.org/wiki/Number"
                },
                "branch": {
                    "Score": "0.82993454",
                    "Summary": "A branch, sometimes called a ramus in botany, is a woody structural member connected to but not part of the central trunk of a tree (or sometimes a shrub). Large branches are known as boughs and small branches are known as twigs. The term twig often refers to a terminus, while bough refers only to branches coming directly from the trunk.\nDue to a broad range of species of trees, branches and twigs can be found in many different shapes and sizes. While branches can be nearly horizontal, vertical, or diagonal, the majority of trees have upwardly diagonal branches. A number of mathematical properties are associated with tree branchings; they are natural examples of fractal patterns in nature, and, as observed by Leonardo da Vinci, their cross-sectional areas closely follow the da Vinci branching rule.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Branch"
                },
                "collision": {
                    "Score": "0.81271344",
                    "Summary": "In physics, a collision is any event in which two or more bodies exert forces on each other in a relatively short time. Although the most common use of the word collision refers to incidents in which two or more objects collide with great force, the scientific use of the term implies nothing about the magnitude of the force.Some examples of physical interactions that scientists would consider collisions are the following:\n\nWhen an insect lands on a plant's leaf, its legs are said to collide with the leaf.\nWhen a cat strides across a lawn, each contact that its paws make with the ground is considered a collision, as well as each brush of its fur against a blade of grass.\nWhen a boxer throws a punch, their fist is said to collide with the opponent's body.\nWhen an astronomical object merges with a black hole, they are considered to collide.Some colloquial uses of the word collision are the following:\n\nA traffic collision involves at least one automobile.\nA mid-air collision occurs between airplanes.\nA ship collision accurately involves at least two moving maritime vessels hitting each other; the related term, allision, describes when a moving ship strikes a stationary object (often, but not always, another ship).In physics, collisions can be classified by the change in the total kinetic energy of the system before and after the collision:\n\nIf most or all of the total kinetic energy is lost (dissipated as heat, sound, etc. or absorbed by the objects themselves), the collision is said to be inelastic; such collisions involve objects coming to a full stop. An example of such a collision is a car crash, as cars crumple inward when crashing, rather than bouncing off of each other. This is by design, for the safety of the occupants and bystanders should a crash occur - the frame of the car absorbs the energy of the crash instead.\nIf most of the kinetic energy is conserved (i.e. the objects continue moving afterwards), the collision is said to be elastic. An example of this is a baseball bat hitting a baseball - the kinetic energy of the bat is transferred to the ball, greatly increasing the ball's velocity. The sound of the bat hitting the ball represents the loss of energy.\nAnd if all of the total kinetic energy is conserved (i.e. no energy is released as sound, heat, etc.), the collision is said to be perfectly elastic. Such a system is an idealization and cannot occur in reality, due to the second law of thermodynamics.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Collision"
                }
            }
        },
        {
            "start_timestamp": "00:45:52",
            "title": "OBSERVATION",
            "text": "OBSERVATION\n\nThe previous hash tables require the DBMS to\nknow the number of elements it wants to store.\n\n= Otherwise, it must rebuild the table Hit needs to\n\ngrow éshrink in size,",
            "transcript": "The next one we're gonna talk about is called cuckoo, hashing uh, it's basically just an alternative way to deal with collisions relative to [Music] the other two. Basically, the the key ideas that we're going to use. Instead of one hash table, a single hash table we're going to use multiple hash tables, each with either a different hash function or some different hash seed that that will give us different hash mappings for keys in each of the tables that we have so on. Insert what we're going to do is check every table and pick any one of them that has a free slot for us to do. The insertion, if no table is a free slot, then we're going to go through this eviction process until we get all of the keys where they need to go and again we'll go through a visual example of this. I think it'll be a little bit easier to understand. But what you end up with is the lookups and the deletions are always 0-1, because we only have to look at one location per hash table so rather than uh kind of having to do these scans. We only end up looking in one location per hash table for each hash table that we have, if you're wondering where the name comes from uh. It's named after the the cuckoo bird uh, which type where some of the species will lay their eggs in another bird's nest, and then the birds when they hatch kick the the other eggs out of the nest or the other, the other baby birds out of the nest. It's a little uh gruesome. But that's that's where the name comes from so basically uh. What what we're trading off here is we're making rights more expensive. So we have to do this multiple hashing in order to have faster reads. So that's the trade-off. That's going on here. So in the visual example for simplicity, we're just gonna show two hash tables uh. In practice. It's usually more, I think, uh the default for the the lib cuckoo one, which I showed the the open source implementation from cmu uh is three three tables get used, but uh here is just two for ease of illustration. So uh imagine again here we wanna insert a so. We have these two tables each with its own hash functions. What we're going to do is evaluate uh, the hash of a twice so hash function, one of a hash function, two of a and that's going to map to two different positions in in these hash tables. So let's say we're going to stick a and in hash table 1, because the slot's empty, so we insert the key a and the value. Now, let's come to key b, we want to insert key b. We again do hash function, one for the first hash table. Hash function, two for the second hash table and we get these two positions. Let's say so. We have a collision in hash table one for key b. We already have key a stored in that slot. So what we're going to do is insert b into hash table number two, because the slot's empty, so a wound up in hash table number one b wound up in hash table number two now key c comes along and again we do the same two hash functions. Let's say we find out that key c maps to this position in the first hash table and to uh with that that has uh key a already stored there and it also maps to the position in the second hash table that has key b stored there. So what do we do? We have two collisions. We don't know where there's there's nowhere, that's empty for us to insert it so we're going to have to choose one of the values to replace. So, let's replace uh the key b in hash table number two. So we're going gonna kick out key uh b and insert key c there. So now we have to do something with key b, so we're gonna rerun hash one, because we removed it from hash table two: we're gonna rerun hash 1 on key b. That's going to tell us to go to this slot where key a is currently stored. So now we have to kick out key a from hash table, 1, replace it with key b, and now we end up here with with uh key a we have to find a place for that to go uh since we removed it from hash table, one we'll go and try and insert it in hash table two. So that's going to hash us uh to this position, which is empty and key a can, can go in there. Yes, so the question is: what happens if you end up in sort of a loop where uh, for example, the hash two of a goes back to the position c uh? So the answer is that uh, you need some kind of a check to see if uh you're in this sort of loop. So are you back to the key that you started with? If that's the case, then what you need to do is rehash everything. So either you you know, grow the size of the hash tables. You could add another another table. You could change your hash functions whatever it is, but kind of you. If, if you run into this case, where there's nowhere left to uh insert a key, then you have to to rehash all of the keys to find to make sure that uh every key fits somewhere in some hash table in an empty slot. Yes, so the question is: if you're in this sort of loop, do you have to keep track of the uh your path through the the insertions to figure out uh, if you're in? If you have a cycle in the the path, I I don't think so, I think you can just keep track of if you've returned to the the key that you started or I guess so, actually are you just trying all the tables yeah? So I think I I was trying to think. If you could end up with a like a local cycle like uh, you know a and b keep I guess it would depend on implementation, yeah yeah. I think I think you should just be able to see if you are end up back at the key that you started with again, because then you'll know that there's no kind of mapping there's no like there's no way of arranging them or distributing them in different tables. That will get you for in this case, it's a b and c that will get you those values distributed. So I think I think you can just keep track of you know whatever key you were inserting, in this case the key c, and if, if you ever wind up back there, then you know that that there's no way of arranging the keys that is going to work. Yes, sorry, so the question is in the worst case, you might end up redoing all the tables in all the elements right. So the question is in the worst case, can you end up going kind of going through and and kicking out and replacing all of the elements and all of the tables? And then in the end you realize anyway, that there's no distribution. Yes, that can happen so in the I guess. In the worst case, you end up kind of with this uh total rebalancing anyway, and if, if you kind of have to go through the whole process of doing I guess uh, there may be some fear. I I'm not familiar with with all the theory behind this, but there may be some theory about you know the number of expected collisions that you end up with in a rebalancing, depending on the size of the hash tables number of hash tables and like the overlap in the the collisions, but that's certainly a possibility. Yes, are there any other questions? Okay, so one observation that you might make is that uh all of the uh previous hash tables that we talked about require the dbms to to know the number of elements that it wants to store in advance. So when we allocate this array, we allocate a fixed size n and that's that's how many elements we can store and then to grow or shrink the array we kind of have to rebuild everything from scratch. We have to rehash all the elements to make sure they go to the correct bins or buckets in the next, the resized array. So sometimes this assumption holds sometimes you can know this so, for example, like during query processing, if you're doing something like a hash join, then you can know or maybe estimate or have an upper bound on the number of keys that are going to be, or the number of distinct keys that are going to show up in your query. But there are a lot of times that you, this assumption, might not hold. So, for example, if you have like just the the base table storage, your data can grow arbitrarily large, so you could always be inserting new keys, uh and over time that might fill up your hash table and and you're out of room. So you have to kind of rebuild it from scratch. So, ideally, what we'd like is a way to for those lighter cases where we don't know, uh the the ultimate size of the hash table, the number of keys that we need to store we'd, like ideally, some way to grow or shrink the table incrementally without having to completely rebuild it. So that's kind of where this idea of dynamic hash tables comes in where they're resizing themselves on demand and we're going to talk about three uh different ways of doing this uh chain: hashing, extendable, hashing and linear hashing. So the the first approach is called chain hashing. Basically we're going to maintain a linked list of buckets for each slot in the hash table and we're going to resolve collisions by by placing all elements with the same hash key into the same bucket. So sometimes it's called like a bucketed hash table. This is this is probably the most common one and the one most most people are familiar with. You can grow the hash table infinitely uh just by adding new buckets to the the linked list, and you only need to take a latch or use some. You know atomic operation like a lock free operation to store a new entry or extend the list, and you can still use kind of tombstones in this case, but it's it's much easier to deal with because nothing needs to be rehashed, so you can add and remove elements keys from the hash table without having to worry about this. This, like forward scanning problem that we had with the the static hash table so I'll, show an example of this, and I think this this will make sense. So we have uh these buckets allocated here again we have our keys and we have this thing called uh, the bucket pointer array or just think of it, like a slot array, that's going to map slots to these buckets that we have stored. So in this case let's say we want to insert key a so we're going to hash it to the first bin or a slot in the bucket pointer slot array, and that tells us to go into this bucket here. So a goes in b goes, let's say in the zeroth bucket there. Let's say c also goes into this bucket with that a is stored in so essentially, I've allocated enough room for two keys key value pairs in there, and now we have key d well, the problem: is it we're out of room here in the bucket with a and c in it? So all we all we need to do is kind of allocate another bucket and we we just create basically a linked list where now we've updated this first bucket with a pointer to the next bucket uh in the linked list, and these buckets can be arbitrarily sized, I mean in the simplest case it could just be a bucket of size one. So you have this kind of linked list chain of individual values for a particular slot in the slot array. In this case it's 2 it could be larger, they could be like a page size or something, and basically we can just fill up these buckets as we go along until until we run out of room and then we just add a new bucket and connect the pointer to the next bucket in the linked list. So then, you know f goes down there, so this is pretty straightforward. Does anyone have any questions about this? Yes, so the question is uh instead of a linked list. What if you had a tree? That would be fine. I think there's there's no semantic difference other than whatever algorithm you have for searching your your buckets after they come up, so you could maintain a tree. You could maintain another hash table, uh whatever, but then every time you know you add some layer of complexity like that. There's additional overhead in now, instead of just uh inserting something at the end, you know whatever the next bucket is at the end of the linked list. You now need to maintain a tree and you might have to rebalance the tree, so it's sorted or whatever like that right. So uh, there's trade-offs here this. This gives you pretty low overhead uh inserts you just append something to the end. You don't have to uh worry too much about the internals of the the bucket layout [Music]. So the question is the length of the bucket pointers list fixed. Yes, the length is fixed. So, what's going to happen is, as you increase the number of buckets, you may need to reallocate that uh uh array to get larger the the the problem we'll talk about kind of rebalancing later, but if you, if you just keep the number of buckets fixed and keep adding uh in this, this uh linked list fashion here, then you can grow arbitrarily large without having to to change your bucket pointers, so kind of uh. There's again, this trade-off between fast inserts versus now. If I, if I need to go hash to, let's say you know, I insert a million more values and they all go in the same bucket as a c etc. Then, in order to find anything, you're gonna have to scan this really long linked list. So again, there's this trade-off between kind of uh, faster inserts without having to rehash every any everything and then look up performance. So we'll we'll see in some of the other schemes how they get around that. Yes, sorry, I didn't get the second part uh. So the question is: is it easier to implement a concurrent hash table data structure using chain hashing versus linear probing? [Music]? I I I I don't see any fundamental or I can't think of any fundamental reason why it would be. I guess you can amortize the cost of an insert like you can do these inserts here the same way, so you could just use an atomic. If you want to you know six something in the last slot there you could just use an atomic compare and swap, and then you know when you when once e gets in now you need to for your next insert. You need to expand the length of the linked list in the uh linear, probing case, uh, you're, sort of doing the same thing right, you're you're for every slot. Just doing an atomic check to see is the slot empty. If not then move on to the next one. If it is, then you can insert so I I don't. I mean yeah, I'm not I'm not sure that there would be any inherent advantage to either one of the concurrent settings. Yes, so the question is what about the cash performance so, like the cpu cache you mean, are you asking? How does the cash performance of this approach compare to one of the other like the anywhere right? So the the comment is that, because it's a linked list, it could be random. Random accesses the the nodes could be anywhere in the linked list, so you might have a bunch of skipping around. That's true. I think you can so in in the linear probing case you just have to scan forward. In this case you have these linked lists with the pointers you need to follow uh. I there are ways that you can work around it. So, for example, uh, if you, if you make these these buckets like a large yeah. So if it's like a large size like let's say a a page size or something, then instead of you know having individual linked list nodes, you have to traverse you're now traversing, something that's like four kilobytes or something big or it could be even larger. You can make them arbitrarily large, then there's a trade-off between wasting space and allocation, so kind of there are a lot of trade-offs you have to consider. You could also probably do something with like pre-fetching. If you know that you're you're scanning to the end of the page, you have to go. Get the next uh linked list node in the list. You could issue some kind of prefetching instruction to get that loaded for you, so it's ready for when you need it great, okay, so.",
            "transcript-corrected": "The next one we're gonna talk about is called cuckoo, hashing uh, it's basically just an alternative way to deal with collisions relative to [Music] the other two. Basically, the key ideas that we're going to use. Instead of one hash table, a single hash table, we're going to use multiple hash tables, each with either a different hash function or some different hash seed that that will give us different hash mappings for keys in each of the tables that we have so on. Insert what we're going to do is check every table and pick any one of them that has a free slot for us to do. The insertion, if no table is a free slot, then we're going to go through this eviction process until we get all of the keys where they need to go and again we'll go through a visual example of this. I think it'll be a little bit easier to understand. But what you end up with is the lookups and the deletions are always 0-1, because we only have to look at one location per hash table so rather than uh kind of having to do these scans. We only end up looking at one location per hash table for each hash table that we have, if you're wondering where the name comes from uh. It's named after the cuckoo bird uh, which type where some of the species will lay their eggs in another bird's nest, and then the birds when they hatch kick the other eggs out of the nest or the other, the other baby birds out of the nest. It's a little, uh gruesome. But that's that's where the name comes from so basically uh. What what we're trading off here is we're making rights more expensive. So we have to do this multiple hashing in order to have faster read. So that's the trade-off. That's going on here. So in the visual example for simplicity, we're just gonna show two hash tables uh. In practice. It's usually more, I think, uh the default for the lib cuckoo one, which I showed the open source implementation from cmu uh is three three tables get used, but uh here is just two for ease of illustration. So, uh imagine again here we wanna insert a so. We have these two tables each with its own hash functions. What we're going to do is evaluate uh, the hash of a twice so hash function, one of a hash function, two of a and that's going to map to two different positions in at these hash tables. So let's say we're going to stick a and in hash table 1, because the slot's empty, so we insert the key a and the value. Now, let's come to key, b, we want to insert key b. We again do hash function, one for the first hash table. Hash function, two for the second hash table and we get these two positions. Let's say so. We have a collision in hash table one for key b. We already have key a stored in that slot. So what we're going to do is insert b into hash table number two, because the slot's empty, so a wound up in hash table number one b wound up in hash table number two now key c comes along and again we do the same two hash functions. Let's say we find out that key c maps to this position in the first hash table and to, uh with that that has uh, key an already stored there and it also maps to the position in the second hash table that has key b stored there. So what do we do? We have two collisions. We don't know where there's there's nowhere, that's empty for us to insert it so we're going to have to choose one of the values to replace. So, let's replace uh the key bin hash table number two. So we're going gonna kick out key uh band insert key c there. So now we have to do something with key, b, so we're gonna rerun hash one, because we removed it from hash table two: we're gonna rerun hash 1 on key b. That's going to tell us to go into this slot where key a is currently stored. So now we have to kick out key a from the hash table, 1, replace it with key, b, and now we end up here with with, uh key a we have to find a place for that to go uh, since we removed it from the hash table, one we'll go and try and insert it in hash table two. So that's going to hash us, uh to this position, which is empty and key a can, can go in there. Yes, so the question is: what happens if you end up in sort of a loop where, uh, for example, the hash two of a goes back to the position c uh? So the answer is that, uh, you need some kind of a check to see if uh, you're in this sort of loop. So are you back to the key that you started with? If that's the case, then what you need to do is rehash everything. So either you you know, grow the size of the hash tables. You could add another another table. You could change your hash functions whatever it is, but kind of you. If, if you run into this case, where there's nowhere left to, uh insert a key, then you have to rehash all of the keys to find to make sure that uh every key fits somewhere in some hash table in an empty slot. Yes, so the question is: if you're in this sort of loop, do you have to keep track of the uh your path through the insertions to figure out uh, if you're in? If you have a cycle in the path, I, I don't think so, I think you can just keep track of if you've returned to the key that you started or I guess so, actually are you just trying all the tables yeah? So I think I I was trying to think. If you could end up with a like a local cycle like, uh, you know a and b keep I guess it would depend on the implementation, yeah yeah. I think I think you should just be able to see if you are end up back at the key that you started with again, because then you'll know that there's no kind of mapping there's no like there's no way of arranging them or distributing them in different tables. That will get you for in this case, it's a b and c that will get you those values distributed. So I think I think you can just keep track of you know whatever key you were inserting, in this case the key c, and if, if you ever wind up back there, then you know that there's no way of arranging the keys that is going to work. Yes, sorry, so the question is in the worst case, you might end up redoing all the tables in all the elements right. So the question is in the worst case, can you end up going kind of going through and kicking out and replacing all of the elements and all of the tables? And then in the end you realize anyway, that there's no distribution. Yes, that can happen so in the I guess. In the worst case, you end up kind of with this, uh total rebalancing anyway, and if, if you kind of have to go through the whole process of doing I guess uh, there may be some fear. I I'm not familiar with with all the theory behind this, but there may be some theory about, you know the number of expected collisions that you end up with in a rebalancing, depending on the size of the hash table number of hash tables and like the overlap in the collisions, but that's certainly a possibility. Yes, are there any other questions? Okay, so one observation that you might make is that, uh all of the uh previous hash tables that we talked about requiring the DBMS to to know the number of elements that it wants to store in advance. So when we allocate this array, we allocate a fixed size n and that's that's how many elements we can store and then to grow or shrink the array we kind of have to rebuild everything from scratch. We have to rehash all the elements to make sure they go to the correct bins or buckets in the next, the resized array. So sometimes this assumption holds sometimes you can know this so, for example, like during query processing, if you're doing something like a hash join, then you can know or maybe estimate or have an upper bound on the number of keys that are going to be, or the number of distinct keys that are going to show up in your query. But there are a lot of times that you, this assumption, might not hold. So, for example, if you have like just the base table storage, your data can grow arbitrarily large, so you could always be inserting new keys, uh and over time that might fill up your hash table and you're out of the room. So you have to kind of rebuild it from scratch. So, ideally, what we'd like is a way to for those lighter cases where we don't know, uh the ultimate size of the hash table, the number of keys that we need to store we'd, like ideally, some way to grow or shrink the table incrementally without having to completely rebuild it. So that's kind of where this idea of dynamic hash tables comes in where they're resizing themselves on demand and we're going to talk about three uh, different ways of doing this uh chain: hashing, extendable, hashing and linear hashing. So the first approach is called a chain hashing. Basically, we're going to maintain a linked list of buckets for each slot in the hash table and we're going to resolve collisions by by placing all elements with the same hash key into the same bucket. So sometimes it's called like a bucketed hash table. This is this is probably the most common one and the one most most people are familiar with. You can grow the hash table infinitely uh, just by adding new buckets to the linked list, and you only need to take a latch or use some. You know atomic operation like a lock free operation to store a new entry or extend the list, and you can still use kind of tombstones in this case, but it's it's much easier to deal with because nothing needs to be rehashed, so you can add and remove elements keys from the hash table without having to worry about this. This, like forward scanning problem that we had with the static hash table so I'll, show an example of this, and I think this will make sense. So we have, uh these buckets allocated here again we have our keys and we have this thing called uh, the bucket pointer array or just think of it, like a slot array, that's going to map slots to these buckets that we have stored. So in this case, let's say we want to insert key a so we're going to hash it to the first bin or a slot in the bucket pointer slot array, and that tells us to go into this bucket here. So a goes in b goes, let's say in the zeroth bucket there. Let's say c also goes into this bucket with that a is stored in, so essentially, I've allocated enough room for two keys, key value pairs in there, and now we have key do well, the problem: is it we're out of room here in the bucket with a and c in it? So all us all we need to do is kind of allocating another bucket and we we just create basically a linked list where now we've updated this first bucket with a pointer to the next bucket uh in the linked list, and these buckets can be arbitrarily sized, I mean in the simplest case it could just be a bucket  size one. So you have this kind of linked list chain of individual values for a particular slot in the slot array. In this case, it's 2 it could be larger, they could be like a page size or something, and basically we can just fill up these buckets as we go along until until we run out of the room and then we just add a new bucket and connect the pointer to the next bucket in the linked list. So then, you know f goes down there, so this is pretty straightforward. Does anyone have any questions about this? Yes, so the question is, uh instead of a linked list. What if you had a tree? That would be fine. I think there's there's no semantic difference other than whatever algorithm you have for searching your your buckets after they come up, so you could maintain a tree. You could maintain another hash table, uh, whatever, but then every time you know you add some layer of complexity like that. There's an additional overhead in now, instead of just, uh inserting something at the end, you know, whatever the next bucket is at the end of the linked list. You now need to maintain a tree and you might have to rebalance the tree, so it's sorted or whatever like that right. So, uh, there's trade-offs here this. This gives you pretty low overhead uh inserts you just append something to the end. You don't have to, uh worry too much about the internals of the bucket layout [Music]. So the question is the length of the bucket pointers list fixed. Yes, the length is fixed. So, what's going to happen is, as you increase the number of buckets, you may need to reallocate that, uh uh array to get larger the the the problem we'll talk about kind of rebalancing later, but if you, if you just keep the number of buckets fixed and keep adding uh in this, this uh linked list fashion here, then you can grow arbitrarily large without having to change your bucket pointers, so kind of uh. There's again, this trade-off between fast inserts versus now. If I, if I need to go hash to, let's say you know, I insert a million more values and they all go in the same bucket as a c etc. Then, in order to find anything, you're gonna have to scan this really long linked list. So again, there's this trade-off between kind of uh, faster inserts without having to rehash every any everything and then look up performance. So we'll we'll see in some of the other schemes how they get around that. Yes, sorry, I didn't get the second part uh. So the question is: is it easier to implement a concurrent hash table data structure using chain hashing versus linear probing? [Music]? I I I I don't see any fundamental or I can't think of any fundamental reason why it would be. I guess you can amortize the cost of an insert like you can do these inserts here the same way, so you could just use an atomic. If you want to, you know six something in the last slot there you could just use an atomic compare and swap, and then you know when you when once we gets in now you need to for your next insert. You need to expand the length of the linked list in the uh linear, probing case, uh, you're, sort of doing the same thing right, you're you're for every slot. Just doing an atomic check to see is the slot empty. If not, then move on to the next one. If it is, then you can insert so I I don't. I mean, yeah, I'm not I'm not sure that there would be any inherent advantage to either one of the concurrent settings. Yes, so the question is what about the cash performance so, like the CPU cache you mean, are you asking? How does the cash performance of this approach compare to one of the other like the anywhere right? So the comment is that, because it's a linked list, it could be random. Random accesses the nodes could be anywhere in the linked list, so you might have a bunch of skipping around. That's true. I think you can so in in the linear probing case you just have to scan forward. In this case you have these linked lists with the pointers you need to follow uh. I there are ways that you can work around it. So, for example, uh, if you, if you make these these buckets like a large yeah. So if it's like a large size like, let's say a a page size or something, then instead of, you know, having individual linked list nodes, you have to traverse you're now traversing, something that's like four kilobytes or something big or it could be even larger. You can make them arbitrarily large, then there's a trade-off between wasting space and allocation, so kind  there is a lot of trade-offs you have to consider. You could also probably do something  like pre-fetching. If you know that you're you're scanning to the end of the page, you have to go. Get the next, uh linked list node in the list. You could issue some kind of preaching, instruction to get that loaded for you, so it's ready for when you need it great, okay, so.",
            "summary_brief": "Today we're going to talk about a new hashing algorithm.",
            "summary_detailed": "The next one we're gonna talk about is called cuckoo, hashing. It's basically just an alternative way to deal with collisions relative to [Music] the other two. Instead of one hash table, a singleHash table, we're going to use multiple hash tables, each with either a different hash function or some different hash seed.",
            "key_concepts": {
                "observation": {
                    "Score": "0.88531065",
                    "Summary": "Observation is the active acquisition of information from a primary source. In living beings, observation employs the senses. In science, observation can also involve the perception and recording of data via the use of scientific instruments. The term may also refer to any data collected during the scientific activity. Observations can be qualitative, that is, only the absence or presence of a property is noted, or quantitative if a numerical value is attached to the observed phenomenon by counting or measuring.",
                    "URL": "https://en.wikipedia.org/wiki/Observation"
                },
                "hash table": {
                    "Score": "0.8023775",
                    "Summary": "In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index, also called a hash code, into an array of buckets or slots, from which the desired value can be found. During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored.\nIdeally, the hash function will assign each key to a unique bucket, but most hash table designs employ an imperfect hash function, which might cause hash collisions where the hash function generates the same index for more than one key. Such collisions are typically accommodated in some way.\nIn a well-dimensioned hash table, the average cost (number of instructions) for each lookup is independent of the number of elements stored in the table. Many hash table designs also allow arbitrary insertions and deletions of key–value pairs, at (amortized) constant average cost per operation.In many situations, hash tables turn out to be on average more efficient than search trees or any other table lookup structure. For this reason, they are widely used in many kinds of computer software, particularly for associative arrays, database indexing, caches, and sets.",
                    "URL": "https://en.wikipedia.org/wiki/Hash_table"
                },
                "size": {
                    "Score": "0.8428453",
                    "Summary": "Size in general is the magnitude or dimensions of a thing. More specifically, geometrical size (or spatial size) can refer to linear dimensions (length, width, height, diameter, perimeter), area, or volume. Size can also be measured in terms of mass, especially when assuming a density range.\n\nIn mathematical terms, \"size is a concept abstracted from the process of measuring by comparing a longer to a shorter\". Size is determined by the process of comparing or measuring objects, which results in the determination of the magnitude of a quantity, such as length or mass, relative to a unit of measurement. Such a magnitude is usually expressed as a numerical value of units on a previously established spatial scale, such as meters or inches.\nThe sizes with which humans tend to be most familiar are body dimensions (measures of anthropometry), which include measures such as human height and human body weight. These measures can, in the aggregate, allow the generation of commercially useful distributions of products that accommodate expected body sizes, as with the creation of clothing sizes and shoe sizes, and with the standardization of door frame dimensions, ceiling heights, and bed sizes. The human experience of size can lead to a psychological tendency towards size bias, wherein the relative importance or perceived complexity of organisms and other objects is judged based on their size relative to humans, and particularly whether this size makes them easy to observe without aid.",
                    "URL": "https://en.wikipedia.org/wiki/Size"
                },
                "number": {
                    "Score": "0.87215734",
                    "Summary": "A number is a mathematical object used to count, measure, and label. The original examples are the natural numbers 1, 2, 3, 4, and so forth. Numbers can be represented in language with number words. More universally, individual numbers can be represented by symbols, called numerals; for example, \"5\" is a numeral that represents the number five. As only a relatively small number of symbols can be memorized, basic numerals are commonly organized in a numeral system, which is an organized way to represent any number. The most common numeral system is the Hindu–Arabic numeral system, which allows for the representation of any number using a combination of ten fundamental numeric symbols, called digits. In addition to their use in counting and measuring, numerals are often used for labels (as with telephone numbers), for ordering (as with serial numbers), and for codes (as with ISBNs). In common usage, a numeral is not clearly distinguished from the number that it represents.\nIn mathematics, the notion of a number has been extended over the centuries to include 0, negative numbers, rational numbers such as one half \n  \n    \n      \n        \n          (\n          \n            \n              \n                1\n                2\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\tfrac {1}{2}}\\right)}\n  , real numbers such as the square root of 2 \n  \n    \n      \n        \n          (\n          \n            \n              2\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\sqrt {2}}\\right)}\n   and π, and complex numbers which extend the real numbers with a square root of −1 (and its combinations with real numbers by adding or subtracting its multiples). Calculations with numbers are done with arithmetical operations, the most familiar being addition, subtraction, multiplication, division, and exponentiation. Their study or usage is called arithmetic, a term which may also refer to number theory, the study of the properties of numbers.\nBesides their practical uses, numbers have cultural significance throughout the world. For example, in Western society, the number 13 is often regarded as unlucky, and \"a million\" may signify \"a lot\" rather than an exact quantity. Though it is now regarded as pseudoscience, belief in a mystical significance of numbers, known as numerology, permeated ancient and medieval thought. Numerology heavily influenced the development of Greek mathematics, stimulating the investigation of many problems in number theory which are still of interest today.During the 19th century, mathematicians began to develop many different abstractions which share certain properties of numbers, and may be seen as extending the concept. Among the first were the hypercomplex numbers, which consist of various extensions or modifications of the complex number system. In modern mathematics, number systems (sets) are considered important special examples of more general categories such as rings and fields, and the application of the term \"number\" is a matter of convention, without fundamental significance.",
                    "URL": "https://en.wikipedia.org/wiki/Number"
                },
                "rights": {
                    "Score": "0.88531065",
                    "Summary": "Rights are legal, social, or ethical principles of freedom or entitlement; that is, rights are the fundamental normative rules about what is allowed of people or owed to people according to some legal system, social convention, or ethical theory. Rights are of essential importance in such disciplines as law and ethics, especially theories of justice and deontology.\nRights are fundamental to any civilization and the history of social conflicts is often bound up with attempts both to define and to redefine them. According to the Stanford Encyclopedia of Philosophy, \"rights structure the form of governments, the content of laws, and the shape of morality as it is currently perceived\".",
                    "URL": "https://en.wikipedia.org/wiki/Rights"
                },
                "data structure": {
                    "Score": "0.88302416",
                    "Summary": "In computer science, a data structure is a data organization, management, and storage format that enables efficient access and modification. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data, i.e., it is an algebraic structure about data.",
                    "URL": "https://en.wikipedia.org/wiki/Data_structure"
                },
                "question": {
                    "Score": "0.82643306",
                    "Summary": "A question is an utterance which typically functions as a request for information, which is expected to be provided in the form of an answer. Questions can thus be understood as a kind of illocutionary act in the field of pragmatics or as special kinds of propositions in frameworks of formal semantics such as alternative semantics or inquisitive semantics. Questions are often conflated with interrogatives, which are the grammatical forms typically used to achieve them. Rhetorical questions, for example, are interrogative in form but may not be considered true questions as they are not expected to be answered.",
                    "URL": "https://en.wikipedia.org/wiki/Question"
                },
                "process": {
                    "Score": "0.8822031",
                    "Summary": "A process is a series or set of activities that interact to produce a result; it may occur once-only or be recurrent or periodic.\nThings called a process include:",
                    "URL": "https://en.wikipedia.org/wiki/Process"
                },
                "location": {
                    "Score": "0.881199",
                    "Summary": "In geography, location or place are used to denote a region (point, line, or area) on Earth’s surface or elsewhere. The term location generally implies a higher degree of certainty than place, the latter often indicating an entity with an ambiguous boundary, relying more on human or social attributes of place identity and sense of place than on geometry.",
                    "URL": "https://en.wikipedia.org/wiki/Location"
                },
                "illustration": {
                    "Score": "0.881199",
                    "Summary": "An illustration is a decoration, interpretation or visual explanation of a text, concept or process, designed for integration in print and digital published media, such as posters, flyers, magazines, books, teaching materials, animations, video games and films. An illustration is typically created by an illustrator. Digital illustrations are often used to make websites and apps more user-friendly, such as the use of emojis to accompany digital type. Illustration also means providing an example; either in writing or in picture form.\nThe origin of the word \"illustration\" is late Middle English (in the sense ‘illumination; spiritual or intellectual enlightenment’): via Old French from Latin illustratio(n-), from the verb illustrare.",
                    "URL": "https://en.wikipedia.org/wiki/Illustration"
                },
                "linear hashing": {
                    "Score": "0.87757",
                    "Summary": "Linear hashing (LH) is a dynamic data structure which implements a hash table and grows or shrinks one bucket at a time. It was invented by Witold Litwin in 1980.  It has been analyzed by Baeza-Yates and Soza-Pollman. \nIt is the first in a number of schemes known as dynamic hashing\n \nsuch as Larson's Linear Hashing with Partial Extensions, \n\nLinear Hashing with Priority Splitting,\n\nLinear Hashing with Partial Expansions and Priority Splitting,\n\nor Recursive Linear Hashing.\nThe file structure of a dynamic hashing data structure adapts itself to changes in the size of the file, so expensive periodic file reorganization is avoided. A Linear Hashing file expands by splitting\na pre-determined bucket into two and contracts by merging two predetermined buckets into one. The trigger for a reconstruction depends on the flavor of the scheme; it could be an overflow at a bucket or  load factor (number of records over the number of buckets) moving outside of a predetermined range.Linear Hashing has also been made into a scalable distributed data structure, LH*. In LH*, each bucket resides at a different server.\n LH* itself has been expanded to provide data availability in the presence of\nfailed buckets.\n Key based operations (inserts, deletes, updates, reads) in LH and \nLH* take maximum constant time independent of the number of buckets and hence of records.",
                    "URL": "https://en.wikipedia.org/wiki/Linear_hashing"
                },
                "collision": {
                    "Score": "0.8108937",
                    "Summary": "In physics, a collision is any event in which two or more bodies exert forces on each other in a relatively short time. Although the most common use of the word collision refers to incidents in which two or more objects collide with great force, the scientific use of the term implies nothing about the magnitude of the force.Some examples of physical interactions that scientists would consider collisions are the following:\n\nWhen an insect lands on a plant's leaf, its legs are said to collide with the leaf.\nWhen a cat strides across a lawn, each contact that its paws make with the ground is considered a collision, as well as each brush of its fur against a blade of grass.\nWhen a boxer throws a punch, their fist is said to collide with the opponent's body.\nWhen an astronomical object merges with a black hole, they are considered to collide.Some colloquial uses of the word collision are the following:\n\nA traffic collision involves at least one automobile.\nA mid-air collision occurs between airplanes.\nA ship collision accurately involves at least two moving maritime vessels hitting each other; the related term, allision, describes when a moving ship strikes a stationary object (often, but not always, another ship).In physics, collisions can be classified by the change in the total kinetic energy of the system before and after the collision:\n\nIf most or all of the total kinetic energy is lost (dissipated as heat, sound, etc. or absorbed by the objects themselves), the collision is said to be inelastic; such collisions involve objects coming to a full stop. An example of such a collision is a car crash, as cars crumple inward when crashing, rather than bouncing off of each other. This is by design, for the safety of the occupants and bystanders should a crash occur - the frame of the car absorbs the energy of the crash instead.\nIf most of the kinetic energy is conserved (i.e. the objects continue moving afterwards), the collision is said to be elastic. An example of this is a baseball bat hitting a baseball - the kinetic energy of the bat is transferred to the ball, greatly increasing the ball's velocity. The sound of the bat hitting the ball represents the loss of energy.\nAnd if all of the total kinetic energy is conserved (i.e. no energy is released as sound, heat, etc.), the collision is said to be perfectly elastic. Such a system is an idealization and cannot occur in reality, due to the second law of thermodynamics.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Collision"
                },
                "semantics": {
                    "Score": "0.8676895",
                    "Summary": "Semantics (from Ancient Greek: σημαντικός sēmantikós, \"significant\") is the study of meaning, reference, or truth. The term can be used to refer to subfields of several distinct disciplines, including philosophy, linguistics and computer science.",
                    "URL": "https://en.wikipedia.org/wiki/Semantics"
                },
                "length": {
                    "Score": "0.8619087",
                    "Summary": "Length is a measure of distance. In the International System of Quantities, length is a quantity with dimension distance. In most systems of measurement a base unit for length is chosen, from which all other units are derived. In the International System of Units (SI) system the base unit for length is the metre.\nLength is commonly understood to mean the most extended dimension of a fixed object. However, this is not always the case and may depend on the position the object is in.\nVarious terms for the length of a fixed object are used, and these include height, which is vertical length or vertical extent, and width, breadth or depth. Height is used when there is a base from which vertical measurements can be taken. Width or breadth usually refer to a shorter dimension when length is the longest one. Depth is used for the third dimension of a three dimensional object.Length is the measure of one spatial dimension, whereas area is a measure of two dimensions (length squared) and volume is a measure of three dimensions (length cubed).",
                    "URL": "https://en.wikipedia.org/wiki/Length"
                },
                "cuckoo": {
                    "Score": "0.8545231",
                    "Summary": "Cuckoos are birds in the Cuculidae  family, the sole taxon in the order Cuculiformes . The cuckoo family includes the common or European cuckoo, roadrunners, koels, malkohas, couas, coucals and anis. The coucals and anis are sometimes separated as distinct families, the Centropodidae and Crotophagidae respectively. The cuckoo order Cuculiformes is one of three that make up the Otidimorphae, the other two being the turacos and the bustards.\nThe cuckoos are generally medium-sized slender birds. Most species live in trees, though a sizeable minority are ground-dwelling. The family has a cosmopolitan distribution; the majority of species are tropical. Some species are migratory. The cuckoos feed on insects, insect larvae and a variety of other animals, as well as fruit. Some species are brood parasites, laying their eggs in the nests of other species and giving rise to the metaphor cuckoo's egg, but the majority of species raise their own young.\nCuckoos have played a role in human culture for thousands of years, appearing in Greek mythology as sacred to the goddess Hera. In Europe, the cuckoo is associated with spring, and with cuckoldry, for example in Shakespeare's Love's Labour's Lost. In India, cuckoos are sacred to Kamadeva, the god of desire and longing, whereas in Japan, the cuckoo symbolises unrequited love.",
                    "URL": "https://en.wikipedia.org/wiki/Cuckoo"
                },
                "commons": {
                    "Score": "0.846784",
                    "Summary": "The commons is the cultural and natural resources accessible to all members of a society, including natural materials such as air, water, and a habitable earth. These resources are held in common, not owned privately. Commons can also be understood as natural resources that groups of people (communities, user groups) manage for individual and collective benefit. Characteristically, this involves a variety of informal norms and values (social practice) employed for a governance mechanism.\nCommons can be also defined as a social practice of governing a resource not by state or market but by a community of users that self-governs the resource through institutions that it creates.",
                    "URL": "https://en.wikipedia.org/wiki/Commons"
                },
                "eviction": {
                    "Score": "0.8432728",
                    "Summary": "Eviction is the removal of a tenant from rental property by the landlord.  In some jurisdictions it may also involve the removal of persons from premises that were foreclosed by a mortgagee (often, the prior owners who defaulted on a mortgage).\nDepending on the laws of the jurisdiction, eviction may also be known as unlawful detainer, summary possession, summary dispossess, summary process, forcible detainer, ejectment, and repossession, among other terms.  Nevertheless, the term eviction is the most commonly used in communications between the landlord and tenant.  Depending on the jurisdiction involved, before a tenant can be evicted, a landlord must win an eviction lawsuit or prevail in another step in the legal process. It should be borne in mind that eviction, as with ejectment and certain other related terms, has precise meanings only in certain historical contexts (e.g., under the English common law of past centuries), or with respect to specific jurisdictions. In present-day practice and procedure, there has come to be a wide variation in the content of these terms from jurisdiction to jurisdiction.The legal aspects, procedures, and provisions for eviction, by whatever name, vary even between countries or states with similar legal structures.",
                    "URL": "https://en.wikipedia.org/wiki/Eviction"
                },
                "familiar": {
                    "Score": "0.8428453",
                    "Summary": "In European folklore of the medieval and early modern periods, familiars (sometimes referred to as familiar spirits) were believed to be supernatural entities that would assist witches and cunning folk in their practice of magic. According to records of the time, those alleging to have had contact with familiar spirits reported that they could manifest as numerous forms, usually as an animal, but sometimes as a human or humanoid figure, and were described as \"clearly defined, three-dimensional... forms, vivid with colour and animated with movement and sound\", as opposed to descriptions of ghosts with their \"smoky, undefined form[s]\".When they served witches, they were often thought to be malevolent, but when working for cunning folk they were often considered benevolent (although there was some ambiguity in both cases). The former were often categorized as demons, while the latter were more commonly thought of and described as fairies. The main purpose of familiars was to serve the witch or young witch, providing protection for them as they came into their new powers.Since the 20th century some magical practitioners, including adherents of the Neopagan religion of Wicca, use the concept of familiars, due to their association with older forms of magic. These contemporary practitioners use pets or wildlife, or believe that invisible versions of familiars act as magical aids.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Familiar"
                },
                "rerun": {
                    "Score": "0.839414",
                    "Summary": "A rerun or repeat is a rebroadcast of an episode of a radio or television program. There are two types of reruns – those that occur during a hiatus, and those that occur when a program is syndicated.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Rerun"
                },
                "alternative way": {
                    "Score": "0.83874846",
                    "Summary": "The Alterning Road (Vía Alterna) is a political party in Colombia. \nAt the last legislative elections, 10 March 2002, the party, as one of the many small parties, won parliamentary representation.",
                    "URL": "https://en.wikipedia.org/wiki/Alternative_Way"
                },
                "hash function": {
                    "Score": "0.8332747",
                    "Summary": "A hash function is any function that can be used to map data of arbitrary size to fixed-size values. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes.  The values are usually used to index a fixed-size table called a hash table. Use of a hash function to index a hash table is called hashing or scatter storage addressing.\nHash functions and their associated hash tables are used in data storage and retrieval applications to access data in a small and nearly constant time per retrieval. They require an amount of storage space only fractionally greater than the total space required for the data or records themselves. Hashing is a computationally and storage space-efficient form of data access that avoids the non-linear access time of ordered and unordered lists and structured trees, and the often exponential storage requirements of direct access of state spaces of large or variable-length keys.\nUse of hash functions relies on statistical properties of key and function interaction: worst-case behaviour is intolerably bad with a vanishingly small probability, and average-case behaviour can be nearly optimal (minimal collision).Hash functions are related to (and often confused with) checksums, check digits, fingerprints, lossy compression, randomization functions, error-correcting codes, and ciphers. Although the concepts overlap to some extent, each one has its own uses and requirements and is designed and optimized differently. The hash functions differ from the concepts numbered mainly in terms of data integrity.",
                    "URL": "https://en.wikipedia.org/wiki/Hash_function"
                },
                "wound": {
                    "Score": "0.8324599",
                    "Summary": "A wound is a type of injury which happens relatively quickly in which skin is torn, cut, or punctured (an open wound), or where blunt force trauma causes a contusion (a closed wound). In pathology, it specifically refers to a sharp injury which damages the epidermis of the skin.",
                    "URL": "https://en.wikipedia.org/wiki/Wound"
                },
                "performance": {
                    "Score": "0.830807",
                    "Summary": "A performance is an act of staging or presenting a play, concert, or other form of entertainment. It is also defined as the action or process of carrying out or accomplishing an action, task, or function.",
                    "URL": "https://en.wikipedia.org/wiki/Performance"
                },
                "linear probing": {
                    "Score": "0.830807",
                    "Summary": "Linear probing  is a scheme in computer programming for resolving collisions in hash tables, data structures for maintaining a collection of key–value pairs and looking up the value associated with a given key. It was invented in 1954 by Gene Amdahl, Elaine M. McGraw, and Arthur Samuel and first analyzed in 1963 by Donald Knuth.\nAlong with quadratic probing and double hashing, linear probing is a form of open addressing. In these schemes, each cell of a hash table stores a single key–value pair. When the hash function causes a collision by mapping a new key to a cell of the hash table that is already occupied by another key, linear probing searches the table for the closest following free location and inserts the new key there. Lookups are performed in the same way, by searching the table sequentially starting at the position given by the hash function, until finding a cell with a matching key or an empty cell.\nAs Thorup & Zhang (2012) write, \"Hash tables are the most commonly used nontrivial data structures, and the most popular implementation on standard hardware uses linear probing, which is both fast and simple.\"\nLinear probing can provide high performance because of its good locality of reference, but is more sensitive to the quality of its hash function than some other collision resolution schemes. It takes constant expected time per search, insertion, or deletion when implemented using a random hash function, a 5-independent hash function, or tabulation hashing. Good results can also be achieved in practice with other hash functions such as MurmurHash.",
                    "URL": "https://en.wikipedia.org/wiki/Linear_probing"
                },
                "demand": {
                    "Score": "0.83010644",
                    "Summary": "In economics, demand is the quantity of a good that consumers are willing and able to purchase at various prices during a given period of time. The relationship between price and quantity demanded is also called the demand curve. Demand for a specific item is a function of an item's perceived necessity, price, perceived quality, convenience, available alternatives, purchasers' disposable income and tastes, and many other options.",
                    "URL": "https://en.wikipedia.org/wiki/Demand"
                },
                "individual": {
                    "Score": "0.82289016",
                    "Summary": "An individual is that which exists as a distinct entity. Individuality (or self-hood) is the state or quality of being an individual; particularly (in the case of humans) of being a person unique from other people and possessing one's own  needs or goals, rights and  responsibilities. The concept of an individual features in diverse fields, including biology, law, and philosophy.",
                    "URL": "https://en.wikipedia.org/wiki/Individual"
                },
                "implementation": {
                    "Score": "0.82289016",
                    "Summary": "Implementation is the realization of an application, or execution of a plan, idea, model, design, specification, standard, algorithm, or policy.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Implementation"
                },
                "room": {
                    "Score": "0.8205979",
                    "Summary": "In a building, a room is any space enclosed within a number of walls to which entry is possible only by a door or other dividing structure that connects it either to a passageway, to another room, or to the outdoors, that is large enough for several persons to move about, and whose size, fixtures, furnishings, and sometimes placement within the building support the activity to be conducted in it.",
                    "URL": "https://en.wikipedia.org/wiki/Room"
                },
                "array": {
                    "Score": "0.81880736",
                    "Summary": "An array is a systematic arrangement of similar objects, usually in rows and columns.\nThings called an array include:\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Array"
                },
                "open source": {
                    "Score": "0.81817603",
                    "Summary": "Open source is source code that is made freely available for possible modification and redistribution. Products include permission to use the source code, design documents, or content of the product. The open-source model is a decentralized software development model that encourages open collaboration.\nA main principle of open-source software development is peer production, with products such as source code, blueprints, and documentation freely available to the public. The open-source movement in software began as a response to the limitations of proprietary code. The model is used for projects such as in open-source appropriate technology, and open-source drug discovery.Open source promotes universal access via an open-source or free license to a product's design or blueprint, and universal redistribution of that design or blueprint. Before the phrase open source became widely adopted, developers and producers have used a variety of other terms. Open source gained hold with the rise of the Internet. The open-source software movement arose to clarify copyright, licensing, domain, and consumer issues.\nGenerally, open source refers to a computer program in which the source code is available to the general public for use or modification from its original design. Code is released under the terms of a software license. Depending on the license terms, others may then download, modify, and publish their version (fork) back to the community.\nMany large formal institutions have sprung up to support the development of the open-source movement, including the Apache Software Foundation, which supports community projects such as the open-source framework Apache Hadoop and the open-source HTTP server Apache HTTP.",
                    "URL": "https://en.wikipedia.org/wiki/Open_source"
                },
                "concurrent hash table": {
                    "Score": "0.81801194",
                    "Summary": "A concurrent hash table (concurrent hash map) is an implementation of hash tables allowing concurrent access by multiple threads using a hash function.Concurrent hash tables thus represent a key concurrent data structure for use in concurrent computing which allow multiple threads to more efficiently cooperate for a computation among shared data.Due to the natural problems associated with concurrent access - namely contention - the way and scope in which the table can be concurrently accessed differs depending on the implementation. Furthermore, the resulting speed up might not be linear with the amount of threads used as contention needs to be resolved, producing processing overhead. There exist multiple solutions to mitigate the effects of contention, that each preserve the correctness of operations on the table.As with their sequential counterpart, concurrent hash tables can be generalized and extended to fit broader applications, such as allowing more complex data types to be used for keys and values. These generalizations can however negatively impact performance and should thus be chosen in accordance to the requirements of the application.",
                    "URL": "https://en.wikipedia.org/wiki/Concurrent_hash_table"
                },
                "hash join": {
                    "Score": "0.81394374",
                    "Summary": "The hash join is an example of a join algorithm and is used in the implementation of a relational database management system. All variants of hash join algorithms involve building hash tables from the tuples of one or both of the joined relations, and subsequently probing those tables so that only tuples with the same hash code need to be compared for equality in equijoins.\nHash joins are typically more efficient than nested loops joins, except when the probe side of the join is very small. They require an equijoin predicate (a predicate comparing records from one table with those from the other table using a conjunction of equality operators '=' on one or more columns).\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Hash_join"
                },
                "second": {
                    "Score": "0.8119097",
                    "Summary": "The second (symbol: s, also abbreviated: sec) is the base unit of time in the International System of Units (SI) (French: Système International d’unités), commonly understood and historically defined as 1⁄86400 of a day – this factor derived from the division of the day first into 24 hours, then to 60 minutes and finally to 60 seconds each. Analog clocks and watches often have sixty tick marks on their faces, representing seconds (and minutes), and a \"second hand\" to mark the passage of time in seconds.  Digital clocks and watches often have a two-digit seconds counter. The second is also part of several other units of measurement like meters per second for speed, meters per second per second for acceleration, and cycles per second for frequency.\n\nAlthough the historical definition of the unit was based on this division of the Earth's rotation cycle, the formal definition in the International System of Units (SI) is a much steadier timekeeper:The second is defined as being equal to the time duration of 9,192,631,770 periods of the radiation corresponding to the transition between the two hyperfine levels of the fundamental unperturbed ground-state of the caesium-133 atom.\nBecause the Earth's rotation varies and is also slowing very slightly, a leap second is added at irregular intervals to clock time to keep clocks in sync with Earth's rotation.\nMultiples of seconds are usually counted in hours and minutes. Fractions of a second are usually counted in tenths or hundredths. In scientific work, small fractions of a second are counted in milliseconds (thousandths), microseconds (millionths), nanoseconds (billionths), and sometimes smaller units of a second. An everyday experience with small fractions of a second is a 1-gigahertz microprocessor which has a cycle time of 1 nanosecond. Camera shutter speeds are often expressed in fractions of a second, such as 1⁄30 second or 1⁄1000 second.\nSexagesimal divisions of the day from a calendar based on astronomical observation have existed since the third millennium BC, though they were not seconds as we know them today. Small divisions of time could not be measured back then, so such divisions were mathematically derived. The first timekeepers that could count seconds accurately were pendulum clocks invented in the 17th century. Starting in the 1950s, atomic clocks became better timekeepers than Earth's rotation, and they continue to set the standard today.",
                    "URL": "https://en.wikipedia.org/wiki/Second"
                },
                "insert key": {
                    "Score": "0.8050392",
                    "Summary": "The Insert key Insert (often abbreviated Ins) is a key commonly found on computer keyboards.\nIt is primarily used to switch between the two text-entering modes on a personal computer (PC) or word processor:\novertype mode, in which the cursor, when typing, overwrites any text that is present in the current location; and\ninsert    mode, where the cursor inserts a character at its current position, forcing all characters past it one position further.The insert/overtype mode toggling is not global for the computer or even for a single application but rather local to the text input window in which the Insert key was pressed.",
                    "URL": "https://en.wikipedia.org/wiki/Insert_key"
                },
                "species": {
                    "Score": "0.80501723",
                    "Summary": "In biology, a species is the basic unit of classification and a taxonomic rank of an organism, as well as a unit of biodiversity. A species is often defined as the largest group of organisms in which any two individuals of the appropriate sexes or mating types can produce fertile offspring, typically by sexual reproduction. Other ways of defining species include their karyotype, DNA sequence, morphology, behaviour or ecological niche. In addition, paleontologists use the concept of the chronospecies since fossil reproduction cannot be examined.\nThe most recent rigorous estimate for the total number of species of eukaryotes is between 8 and 8.7 million. However, only about 14% of these had been described by 2011.All species (except viruses) are given a two-part name, a \"binomial\". The first part of a binomial is the genus to which the species belongs. The second part is called the specific name or the specific epithet (in botanical nomenclature, also sometimes in zoological nomenclature). For example, Boa constrictor is one of four species of the genus Boa, with constrictor being the species's epithet.\nWhile the definitions given above may seem adequate at first glance, when looked at more closely they represent problematic species concepts. For example, the boundaries between closely related species become unclear with hybridisation, in a species complex of hundreds of similar microspecies, and in a ring species. Also, among organisms that reproduce only asexually, the concept of a reproductive species breaks down, and each clone is potentially a microspecies. Although none of these are entirely satisfactory definitions, and while the concept of species may not be a perfect model of life, it is still an incredibly useful tool to scientists and conservationists for studying life on Earth, regardless of the theoretical difficulties. If species were fixed and clearly distinct from one another, there would be no problem, but evolutionary processes cause species to change continually, and to grade into one another.\nSpecies were seen from the time of Aristotle until the 18th century as fixed categories that could be arranged in a hierarchy, the great chain of being. In the 19th century, biologists grasped that species could evolve given sufficient time. Charles Darwin's 1859 book On the Origin of Species explained how species could arise by natural selection. That understanding was greatly extended in the 20th century through genetics and population ecology. Genetic variability arises from mutations and recombination, while organisms themselves are mobile, leading to geographical isolation and genetic drift with varying selection pressures. Genes can sometimes be exchanged between species by horizontal gene transfer; new species can arise rapidly through hybridisation and polyploidy; and species may become extinct for a variety of reasons. Viruses are a special case, driven by a balance of mutation and selection, and can be treated as quasispecies.",
                    "URL": "https://en.wikipedia.org/wiki/Species"
                },
                "cost": {
                    "Score": "0.8040578",
                    "Summary": "In production, research, retail, and accounting, a cost is the value of money that has been used up to produce something or deliver a service, and hence is not available for use anymore. In business, the cost may be one of acquisition, in which case the amount of money expended to acquire it is counted as cost. In this case, money is the input that is gone in order to acquire the thing. This acquisition cost may be the sum of the cost of production as incurred by the original producer, and further costs of transaction as incurred by the acquirer over and above the price paid to the producer. Usually, the price also includes a mark-up for profit over the cost of production.\nMore generalized in the field of economics, cost is a metric that is totaling up as a result of a process or as a differential for the result of a decision.  Hence cost is the metric used in the standard modeling paradigm applied to economic processes.\nCosts (pl.) are often further described based on their timing or their applicability.",
                    "URL": "https://en.wikipedia.org/wiki/Cost"
                },
                "kilobyte": {
                    "Score": "0.8027011",
                    "Summary": "The kilobyte is a multiple of the unit byte for digital information.\nThe International System of Units (SI) defines the prefix kilo as 1000 (103); per this definition, one kilobyte is 1000 bytes. The internationally recommended unit symbol for the kilobyte is kB.In some areas of information technology, particularly in reference to solid-state memory capacity, kilobyte instead typically refers to 1024 (210) bytes. This arises from the prevalence of sizes that are powers of two in modern digital memory architectures.",
                    "URL": "https://en.wikipedia.org/wiki/Kilobyte"
                }
            }
        },
        {
            "start_timestamp": "01:05:44",
            "title": "EXTENDIBLE HASHING",
            "text": "EXTENDIBLE HASHING\n\nChained-hashing approach where we split buckets\ninstead of letting the linked list grow forever.\n\nMultiple slot locations can point to the same\nbucket chain,\n\nReshulile bucket entries on split and increase the\n\n \n\nnumber of bits to examine.\n\n= Data movemen is lovalized to just the split chain",
            "transcript": "Extendable hashing is, is basically a chain hashing approach where we're going to split the buckets uh, instead of letting the length list grow forever. So one of the problems with the previous case is that we had, you know linked lists that could become arbitrarily large if we wanted to stop that, we had to resize that that bucket slot array thing to make it bigger to cut down on the length of the linked list, but that kind of defeated the purpose of having this. This dynamic hash table in the first place, so kind of the idea of extendable hashing is that we can grow the slot array, uh the the mapping array incrementally and we're going to split buckets only when they overflow- and the key point here is that multiple slots in the slot array can point to the same bucket chain. Uh and I'll show another example here what what this means. So then, you kind of have to reshuffle the buckets during the split, and then we increase the number of bits that we need to examine for the the split location. So I.",
            "transcript-corrected": "Extendable hashing is, is basically a chain hashing approach where we're going to split the buckets uh, instead of letting the long list grow forever. So one of the problems with the previous case is that we had, you know linked lists that could become arbitrarily large if we wanted to stop that, we had to resize that that bucket slot array thing to make it bigger to cut down on the length of the linked list, but that kind of defeat the purpose of having this. This dynamic hash table in the first place, so kind of the idea of extendable hashing is that we can grow the slot array, uh the mapping array incrementally and we're going to split buckets only when they overflow- and the key point here is that multiple slots in the slot array can point to the same bucket chain. Oh, and I'll show another example here what what this means. So then, you kind of have to reshuffle the buckets during the split, and then we increase the number of bits that we need to examine for the split location. So I.",
            "summary_brief": "In this video I'm going to show you an example of extendable hashing.",
            "summary_detailed": "Extendable hashing is, is basically a chain hashing approach where we're going to split the buckets instead of letting the long list grow forever. Multiple slots in the slot array can point to the same bucket chain. So then, you kind of have to reshuffle the buckets during the split, and then we increase the number of bits that we need to examine for the split location.",
            "key_concepts": {
                "bucket": {
                    "Score": "0.90533274",
                    "Summary": "A bucket is typically a watertight, vertical cylinder or truncated cone or square, with an open top and a flat bottom, attached to a semicircular carrying handle called the bail.A bucket is usually an open-top container. In contrast, a pail can have a top or lid and is a shipping container. In common usage, the two terms are often used interchangeably.",
                    "URL": "https://en.wikipedia.org/wiki/Bucket"
                },
                "location": {
                    "Score": "0.87311614",
                    "Summary": "In geography, location or place are used to denote a region (point, line, or area) on Earth’s surface or elsewhere. The term location generally implies a higher degree of certainty than place, the latter often indicating an entity with an ambiguous boundary, relying more on human or social attributes of place identity and sense of place than on geometry.",
                    "URL": "https://en.wikipedia.org/wiki/Location"
                },
                "number": {
                    "Score": "0.8416201",
                    "Summary": "A number is a mathematical object used to count, measure, and label. The original examples are the natural numbers 1, 2, 3, 4, and so forth. Numbers can be represented in language with number words. More universally, individual numbers can be represented by symbols, called numerals; for example, \"5\" is a numeral that represents the number five. As only a relatively small number of symbols can be memorized, basic numerals are commonly organized in a numeral system, which is an organized way to represent any number. The most common numeral system is the Hindu–Arabic numeral system, which allows for the representation of any number using a combination of ten fundamental numeric symbols, called digits. In addition to their use in counting and measuring, numerals are often used for labels (as with telephone numbers), for ordering (as with serial numbers), and for codes (as with ISBNs). In common usage, a numeral is not clearly distinguished from the number that it represents.\nIn mathematics, the notion of a number has been extended over the centuries to include 0, negative numbers, rational numbers such as one half \n  \n    \n      \n        \n          (\n          \n            \n              \n                1\n                2\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\tfrac {1}{2}}\\right)}\n  , real numbers such as the square root of 2 \n  \n    \n      \n        \n          (\n          \n            \n              2\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\sqrt {2}}\\right)}\n   and π, and complex numbers which extend the real numbers with a square root of −1 (and its combinations with real numbers by adding or subtracting its multiples). Calculations with numbers are done with arithmetical operations, the most familiar being addition, subtraction, multiplication, division, and exponentiation. Their study or usage is called arithmetic, a term which may also refer to number theory, the study of the properties of numbers.\nBesides their practical uses, numbers have cultural significance throughout the world. For example, in Western society, the number 13 is often regarded as unlucky, and \"a million\" may signify \"a lot\" rather than an exact quantity. Though it is now regarded as pseudoscience, belief in a mystical significance of numbers, known as numerology, permeated ancient and medieval thought. Numerology heavily influenced the development of Greek mathematics, stimulating the investigation of many problems in number theory which are still of interest today.During the 19th century, mathematicians began to develop many different abstractions which share certain properties of numbers, and may be seen as extending the concept. Among the first were the hypercomplex numbers, which consist of various extensions or modifications of the complex number system. In modern mathematics, number systems (sets) are considered important special examples of more general categories such as rings and fields, and the application of the term \"number\" is a matter of convention, without fundamental significance.",
                    "URL": "https://en.wikipedia.org/wiki/Number"
                },
                "array": {
                    "Score": "0.87311614",
                    "Summary": "An array is a systematic arrangement of similar objects, usually in rows and columns.\nThings called an array include:\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Array"
                },
                "hash table": {
                    "Score": "0.8172901",
                    "Summary": "In computing, a hash table (hash map) is a data structure that implements an associative array abstract data type, a structure that can map keys to values. A hash table uses a hash function to compute an index, also called a hash code, into an array of buckets or slots, from which the desired value can be found. During lookup, the key is hashed and the resulting hash indicates where the corresponding value is stored.\nIdeally, the hash function will assign each key to a unique bucket, but most hash table designs employ an imperfect hash function, which might cause hash collisions where the hash function generates the same index for more than one key. Such collisions are typically accommodated in some way.\nIn a well-dimensioned hash table, the average cost (number of instructions) for each lookup is independent of the number of elements stored in the table. Many hash table designs also allow arbitrary insertions and deletions of key–value pairs, at (amortized) constant average cost per operation.In many situations, hash tables turn out to be on average more efficient than search trees or any other table lookup structure. For this reason, they are widely used in many kinds of computer software, particularly for associative arrays, database indexing, caches, and sets.",
                    "URL": "https://en.wikipedia.org/wiki/Hash_table"
                }
            }
        },
        {
            "start_timestamp": "01:06:50",
            "title": "EXTENDIBLE HASHING",
            "text": "EXTENDIBLE HASHING\n\nFind A\n\nHi Insert B.\nLI]\n\n \n\nLit] 18\n\nUL) TE LEE",
            "transcript": "Think this will make sense with this visualization, so this extendable hashing table. We again have this kind of slot array or mapping array in which we're storing the first two bits or we need to look at the first two bits of each of the the hash values so uh what uh? What what the numbers here mean? Uh we have what's called the this global counter, which is uh telling us how many bits we need to care about and then for each page, just just conceptually, I'm showing the number of bits here. You don't need them for the algorithm, but these are like the local count of how many bits we need to care about for each each page. So what this means is, for example, in in the first two slots there 0 0 and 0 1. If we, if we look at just the first bits, that's what the local one means on the first bucket. If we look at just the first bit, we know that those values uh map to that uh bucket in the the bottom two. We need to look at two bits and that's why each of their local counters have a two in it. We need to look at two bits to get to each of those, so the the the global uh counter is the maximof all of the local counters that we have so the way that this is going to work is let's say we want to find key a and that's going to hash to those values. 0 1, 1 0, some other stuff. The way that we're going to do it is we're going to look up the first. The global counter says that we need to look at the first two bits of that hashed value, so we're going to go over here and look at that position in the slot array, the mapping array and it's going to tell us that we need to go to that bucket. So, similarly, if we want to insert key b and the hash function says it's, you know: 1 0, 1, 1 1, whatever comes after that, then again the global counter says we have to look at the first two bits. That's going to tell us to go to this position in the mapping array and it tells us to go to that bucket so now. Finally, if you want to insert key c again, we get the hash value and look at the first two bits and the the problem that we're going to see here is that uh, our bucket is now full. So I said kind of there's there's going to be this uh incremental resizing. So what we need to do is increment our global counter to three now uh, so that we're looking at the first three bits and we're going to have to split this bucket, that's full into now smaller buckets, so we've incremented the counter. We need to reallocate this array. So now we have the first three bits of the numbers. I realize that these are if you're particularly eagle-eyed, you may notice they're out of order, but they're just the values from from zero to seven the the arrows and the animation got too messy, so uh, but but they're, just all the values from zero to seven. So you can, you know, figure out the slot that you need to go to and uh uh. Now we we add a new split that bucket into two and we we redo the mappings so now, for example, key c we need to look at you know the global counter says: look at the first three bits, so we're going to go to that position in the mapping array and it tells us to go to this uh bucket there. So I know that was kind of a little complicated to go through. Are there any questions about how this extendable hashing works? Yes, if we delete all muscle elements, do we have like uh so uh? The question is: if you delete elements, can you shrink the list uh? Yes, so the the shrinking uh we're not gonna talk about it here. But shrinking is just like the inverse of of insertion. So you you could shrink the list. Yes, okay, so linear, hashing, um,.",
            "transcript-corrected": "Think this will make sense with this visualization, so this extendable hashing table. We again have this kind of slot array or mapping array in which we're storing the first two bits or we need to look at the first two bits of each of the hash values so uh what uh? What what the numbers here mean? Uh, we have what's called the this global counter, which is, uh telling us how many bits we need to care about and then for each page, just just conceptually, I'm showing the number of bits here. You don't need them for the algorithm, but these are like the local count of how many bits we need to care about for each each page. So what this means is, for example, in the first two slots there 0 0 and 0 1. If we, if we look at just the first bits, that's what the local one means on the first bucket. If we look at just the first bit, we know that those values uh map to that uh bucket in the bottom two. We need to look at two bits and that's why each of their local counters has a two in it. We need to look at two bits to get to each of those, so the the the global uh counter is the maxim of all of the local counters that we have so the way that this is going to work is let's say we want to find key a and that's going to hash to those values. 0, 1, 1, 0, some other stuff. The way that we're going to do it is we're going to look up the first. The global counter says that we need to look at the first two bits of that hashed value, so we're going to go over here and look at that position in the slot array, the mapping array and it's going to tell us that we need to go to that bucket. So, similarly, if we want to insert key band the hash function says it's, you know: 1 0, 1, 1, 1, whatever comes after that, then again the global counter says we have to look at the first two bits. That's going to tell us to go to this position in the mapping array and it tells us to go to that bucket so now. Finally, if you want to insert key c again, we get the hash value and look at the first two bits and the problem that we're going to see here is that uh, our bucket is now full. So I said kind of there's there's going to be this uh incremental resizing. So what we need to do is increment our global counter to three now, uh, so that we're looking at the first three bits and we're going to have to split this bucket, that's full into now smaller buckets, so we've incremented the counter. We need to reallocate this array. So now we have the first three bits of the numbers. I realize that these are if you're particularly eagle-eyed, you may notice they're out of order, but they're just the values from from zero to seven the arrows and the animation got too messy, so uh, but they're, just all the values from zero to seven. So you can, you know, figure out the slot that you need to go to and uh uh. Now we we add a new split that bucket into two and we we redo the mappings so now, for example, key c we need to look at, you know the global counter says: look at the first three bits, so we're going to go to that position in the mapping array and it tells us to go to this uh bucket there. So I know that was kind of a little complicated to go through. Are there any questions about how this extendable hashing works? Yes, if we delete all muscle elements, do we have like uh so uh? The question is: if you delete elements, can you shrink the list uh? Yes, so the shrinking uh, we're not gonna talk about it here. But shrinking is just like the inverse of of insertion. So you you could shrink the list. Yes, okay, so linear, hashing, um,.",
            "summary_brief": "In this video we're going to look at an extendable hashing table.",
            "summary_detailed": "Think this will make sense with this visualization, so this extendable hashing table. We again have this kind of slot array or mapping array in which we're storing the first two bits. We need to look at two bits to get to each of those, so the the global uh counter is the maxim of all of the local counters.",
            "key_concepts": {
                "extendible hashing": {
                    "Score": "0.88000053",
                    "Summary": "Extendible hashing is a type of hash system which treats a hash as a bit string and uses a trie for bucket lookup. Because of the hierarchical nature of the system, re-hashing is an incremental operation (done one bucket at a time, as needed).  This means that time-sensitive applications are less affected by table growth than by standard full-table rehashes.\nExtendible hashing was described by Ronald Fagin in 1979. Practically all modern filesystems use either extendible hashing or B-trees. In particular, the Global File System, ZFS, and the SpadFS filesystem use extendible hashing.",
                    "URL": "https://en.wikipedia.org/wiki/Extendible_hashing"
                },
                "array": {
                    "Score": "0.8654877",
                    "Summary": "An array is a systematic arrangement of similar objects, usually in rows and columns.\nThings called an array include:\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Array"
                },
                "algorithm": {
                    "Score": "0.8654877",
                    "Summary": "In mathematics and computer science, an algorithm ( (listen)) is a finite sequence of well-defined instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations, data processing, automated reasoning, automated decision-making and other tasks. In contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.As an effective method, an algorithm can be expressed within a finite amount of space and time, and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.",
                    "URL": "https://en.wikipedia.org/wiki/Algorithm"
                },
                "two bits": {
                    "Score": "0.8614926",
                    "Summary": "Two Bits is a 1995 American drama film directed by James Foley and starring Al Pacino, Mary Elizabeth Mastrantonio and Jerry Barone. It was written by Joseph Stefano, who considered the film a personal project, with a semi-biographical story. The title refers to the American slang term \"two bits\", for a quarter dollar.",
                    "URL": "https://en.wikipedia.org/wiki/Two_Bits"
                },
                "bucket": {
                    "Score": "0.8570851",
                    "Summary": "A bucket is typically a watertight, vertical cylinder or truncated cone or square, with an open top and a flat bottom, attached to a semicircular carrying handle called the bail.A bucket is usually an open-top container. In contrast, a pail can have a top or lid and is a shipping container. In common usage, the two terms are often used interchangeably.",
                    "URL": "https://en.wikipedia.org/wiki/Bucket"
                },
                "question": {
                    "Score": "0.84632397",
                    "Summary": "A question is an utterance which typically functions as a request for information, which is expected to be provided in the form of an answer. Questions can thus be understood as a kind of illocutionary act in the field of pragmatics or as special kinds of propositions in frameworks of formal semantics such as alternative semantics or inquisitive semantics. Questions are often conflated with interrogatives, which are the grammatical forms typically used to achieve them. Rhetorical questions, for example, are interrogative in form but may not be considered true questions as they are not expected to be answered.",
                    "URL": "https://en.wikipedia.org/wiki/Question"
                },
                "map": {
                    "Score": "0.84632397",
                    "Summary": "A map is a symbolic depiction emphasizing relationships between elements of some space, such as objects, regions, or themes.\nMany maps are static, fixed to paper or some other durable medium, while others are dynamic or interactive. Although most commonly used to depict geography, maps may represent any space, real or fictional, without regard to context or scale, such as in brain mapping, DNA mapping, or computer network topology mapping. The space being mapped may be two dimensional, such as the surface of the earth, three dimensional, such as the interior of the earth, or even more abstract spaces of any dimension, such as arise in modeling phenomena having many independent variables.\nAlthough the earliest maps known are of the heavens, geographic maps of territory have a very long tradition and exist from ancient times. The word \"map\" comes from the medieval Latin Mappa mundi, wherein mappa meant napkin or cloth and mundi the world. Thus, \"map\" became a shortened term referring to a two-dimensional representation of the surface of the world.",
                    "URL": "https://en.wikipedia.org/wiki/Map"
                },
                "smaller": {
                    "Score": "0.815768",
                    "Summary": "Smaller were an English alternative rock, Britpop band from Liverpool, active during the 1990s. They had hits with \"Wasted\" and \"Is\" in 1996 and 1997.",
                    "URL": "https://en.wikipedia.org/wiki/Smaller"
                }
            }
        },
        {
            "start_timestamp": "01:11:08",
            "title": "LINEAR HASHING",
            "text": "LINEAR HASHING\n\n \n\nFind 6\n\n \n\n \n\nInsert 17\n\n \n\n \n\n \n\n|\nUe it",
            "transcript": "What's going to happen, is the linear, hashing algorithm is going to maintain a pointer that tracks the next bucket to split so rather than splitting a particular bucket, as we did in the previous case, one of the buckets got too full and we split that bucket [Music]. We are. We want to split any time that any bucket overflows and we're going to maintain a pointer to the next bucket that we want to split. So this is going to solve one of the problems with extendable hashing was that occasionally you know we have to double end up doubling the size of this uh mapping array. You know every time we we need to add a new uh bit to consider uh. We have to increase the size of the mapping array so to get around that uh, linear hashing is going to do it kind of incrementally. So it's going to do the resizing just by adding one new bucket one new slot in the array at a time. So the way that we're going to handle that is by using multiple hash functions, two is, is sufficient to find the right bucket for a given key and we can use different overflow criterion. But, let's just say it's it's when the the size of the bucket fills up, you can use different conditions to decide when to trigger this, but uh, let's in in the example, in a show, it's just going to be when a particular bucket fills up. So what this is going to give you is like a smoother growth policy uh by splitting splitting buckets, irrespective of of which one overflows. So you don't run into this this case, where you kind of have to you, know, resize or double the mapping array when individual buckets fill up so again. Here's an example: we have these different array array buckets and we have this mapping array, and I mentioned we're going to keep this split pointer. That tells us which bucket we want to split next, so the hash function that we're going to start with is just going to say. Hash function of the key is the key mod uh n, which is the the number of buckets that I have so, for example, to find six we're going to say six mod four is two, and that gives us bucket two to look in, so we're gonna go and retrieve it from that bucket. That's, okay, we're gonna, insert 17.! Well, okay! Here we get a bucket one that we need to look in. We see bucket, one is full, so what we need to do is uh perform a split in order to do the the incremental resizing that we that we want to perform. So again, the split pointer keeps track of the bucket that we're going to split, not necessarily the one that got too big. So the first thing we need to do is add this overflow bucket, similar to the the the chain hashing that we had so 17 goes in there. The first part is done, but now we need to do uh the splitting. So the split pointer points to this first bucket we're going to split that bucket into two and we're going to add a new slot. On the end, so slot number four and we're going to create this new hash function. That's now key mod 2n, so double the end, so we rerun all of the keys in that first bucket 8 and 20. 8 still lands in the first bucket. 20 now goes into this new bucket that we've created and then we're going to advance our split pointer. So now, what's going to happen is for all of the subsequent calls. We need to decide whether the keys are above or below this, this split point or line. So in this case we have key 20.. If we come in here and we try and use you know the original hash function, it's going to say that we should go to bucket zero. That's going to be a problem because we split that bucket. We moved key20 to this bucket four, so we need to keep track of this line and we need to say: okay is the key that we're looking for. If we perform the first hash function, is it above or below the line? So if it's above the line in this case, like 20, we know that we need to rerun using the second hash function and we end up correctly down in this this bottom uh new bin- that we've added so now if we want to find another key like key9, so that that winds us up at the bucket one there. We know that that's below the split pointer line, so all we need to do is uh uh go and look it up in that table. So, what's going to happen, is over time uh we're going to keep moving the split pointer line down, keep splitting buckets eventually this one that's overflowed here will will split up when some other bucket fills up. We need to split it until we again wrap around you. Think of this, like a circular buffer. So we get down to the bottom. When we're done, we've essentially doubled the size of the array, we'll start again at the beginning, and we can get rid of the first hash function, hash one and replace that with hash. Two then we're back to kind of the the same place. We started so uh kind of the.",
            "transcript-corrected": "What's going to happen, is the linear, hashing algorithm is going to maintain a pointer that tracks the next bucket to split so rather than splitting a particular bucket, as we did in the previous case, one of the buckets got too full and we split that bucket [Music]. We are. We want to split any time that any bucket overflows and we're going to maintain a pointer to the next bucket that we want to split. So this is going to solve one of the problems with extendable hashing was that occasionally you know we have to double end up doubling the size of this uh mapping array. You know every time we we need to add a new uh bit to consider uh. We have to increase the size of the mapping array so to get around that, uh, linear hashing is going to do it kind of incrementally. So it's going to do the resizing just by adding one new bucket one new slot in the array at a time. So the way that we're going to handle that is by using multiple hash functions, two is, is sufficient to find the right bucket for a given key and we can use different overflow criterion. But, let's just say it's it's when the size of the bucket fills up, you can use different conditions to decide when to trigger this, but uh, let's in in the example, in a show, it's just going to be when a particular bucket fills up. So what this is going to give you is like a smoother growth policy uh by splitting, splitting buckets, irrespective of of which one overflows. So you don't run into this this case, where you kind of have  you, know, resize or double the mapping array when individual buckets fill up so again. Here's an example: we have these different array array buckets and we have this mapping array, and I mentioned we're going to keep this split pointer. That tells us which bucket we want to split next, so the hash function that we're going to start with is just going to say. The hash function of the key is the key mod uh n, which is the number of buckets that I have so, for example, to find six we're going to say six mod four is two, and that gives us bucket two to look in, so we're gonna go and retrieve it from that bucket. That's, okay, we're gonna, insert 17.! Well, okay! Here we get a bucket one that we need to look at. We see the bucket, one is full, so what we need to do is, uh perform a split in order to do the incremental resizing that we that we want to perform. So again, the split pointer keeps track of the bucket that we're going to split, not necessarily the one that got too big. So the first thing we need to do is add this overflow bucket, similar to the the the chain hashing that we had so 17 goes in there. The first part is done, but now we need to do uh the splitting. So the split pointer points to this first bucket we're going to split that bucket into two and we're going to add a new slot. In the end, so slot number four and we're going to create this new hash function. That's now key mod 2n, so double the end, so we rerun all of the keys in that first bucket 8 and 20. 8 still lands in the first bucket. 20 now goes into this new bucket that we've created and then we're going to advance our split pointer. So now, what's going to happen is for all of the subsequent calls. We need to decide whether the keys are above or below this, this split point or line. So in this case we have key 20.. If we come in here and we try and use you know the original hash function, it's going to say that we should go to bucket zero. That's going to be a problem because we split that bucket. We moved key20 to this bucket four, so we need to keep track of this line and we need to say: okay is the key that we're looking for. If we perform the first hash function, is it above or below the line? So if it's above the line in this case, like 20, we know that we need to rerun using the second hash function and we end up correctly down in this this bottom uh new bin- that we've added so now if we want to find another key like key9, so that that winds us up at the bucket one there. We know that that's below the split pointer line, so all we need to do is, uh uh, go and look it up in that table. So, what's going to happen, is over, time uh, we're going to keep moving the split pointer line down, keep splitting buckets eventually this one that's overflowed here will will split up when some other bucket fills up. We need to split it until we again wrap around you. Think of this, like a circular buffer. So we get down to the bottom. When we're done, we've essentially doubled the size of the array, we'll start again at the beginning, and we can get rid of the first hash function, hash one and replace that with hash. Two then we're back to kind of the same place. We started so, uh kind of the.",
            "summary_brief": "In our series of videos on python, we're going to be looking at a new algorithm that's going to solve one of the problems with extendable hashing.",
            "summary_detailed": " linear hashing is going to do the resizing just by adding one new bucket one new slot in the array at a time. The split pointer keeps track of the bucket that we're going to split, not necessarily the one that got too big. So you don't run into this this case, where you kind of have to resize or double the mapping array when individual buckets fill up.",
            "key_concepts": {
                "linear hashing": {
                    "Score": "0.8504941",
                    "Summary": "Linear hashing (LH) is a dynamic data structure which implements a hash table and grows or shrinks one bucket at a time. It was invented by Witold Litwin in 1980.  It has been analyzed by Baeza-Yates and Soza-Pollman. \nIt is the first in a number of schemes known as dynamic hashing\n \nsuch as Larson's Linear Hashing with Partial Extensions, \n\nLinear Hashing with Priority Splitting,\n\nLinear Hashing with Partial Expansions and Priority Splitting,\n\nor Recursive Linear Hashing.\nThe file structure of a dynamic hashing data structure adapts itself to changes in the size of the file, so expensive periodic file reorganization is avoided. A Linear Hashing file expands by splitting\na pre-determined bucket into two and contracts by merging two predetermined buckets into one. The trigger for a reconstruction depends on the flavor of the scheme; it could be an overflow at a bucket or  load factor (number of records over the number of buckets) moving outside of a predetermined range.Linear Hashing has also been made into a scalable distributed data structure, LH*. In LH*, each bucket resides at a different server.\n LH* itself has been expanded to provide data availability in the presence of\nfailed buckets.\n Key based operations (inserts, deletes, updates, reads) in LH and \nLH* take maximum constant time independent of the number of buckets and hence of records.",
                    "URL": "https://en.wikipedia.org/wiki/Linear_hashing"
                },
                "subsequent": {
                    "Score": "0.8595195",
                    "Summary": "",
                    "URL": "https://en.wikipedia.org/wiki/Subsequent"
                },
                "array": {
                    "Score": "0.8595195",
                    "Summary": "An array is a systematic arrangement of similar objects, usually in rows and columns.\nThings called an array include:\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Array"
                },
                "algorithm": {
                    "Score": "0.85089594",
                    "Summary": "In mathematics and computer science, an algorithm ( (listen)) is a finite sequence of well-defined instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations, data processing, automated reasoning, automated decision-making and other tasks. In contrast, a heuristic is an approach to problem solving that may not be fully specified or may not guarantee correct or optimal results, especially in problem domains where there is no well-defined correct or optimal result.As an effective method, an algorithm can be expressed within a finite amount of space and time, and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.",
                    "URL": "https://en.wikipedia.org/wiki/Algorithm"
                },
                "hash function": {
                    "Score": "0.8504941",
                    "Summary": "A hash function is any function that can be used to map data of arbitrary size to fixed-size values. The values returned by a hash function are called hash values, hash codes, digests, or simply hashes.  The values are usually used to index a fixed-size table called a hash table. Use of a hash function to index a hash table is called hashing or scatter storage addressing.\nHash functions and their associated hash tables are used in data storage and retrieval applications to access data in a small and nearly constant time per retrieval. They require an amount of storage space only fractionally greater than the total space required for the data or records themselves. Hashing is a computationally and storage space-efficient form of data access that avoids the non-linear access time of ordered and unordered lists and structured trees, and the often exponential storage requirements of direct access of state spaces of large or variable-length keys.\nUse of hash functions relies on statistical properties of key and function interaction: worst-case behaviour is intolerably bad with a vanishingly small probability, and average-case behaviour can be nearly optimal (minimal collision).Hash functions are related to (and often confused with) checksums, check digits, fingerprints, lossy compression, randomization functions, error-correcting codes, and ciphers. Although the concepts overlap to some extent, each one has its own uses and requirements and is designed and optimized differently. The hash functions differ from the concepts numbered mainly in terms of data integrity.",
                    "URL": "https://en.wikipedia.org/wiki/Hash_function"
                },
                "bucket": {
                    "Score": "0.8357285",
                    "Summary": "A bucket is typically a watertight, vertical cylinder or truncated cone or square, with an open top and a flat bottom, attached to a semicircular carrying handle called the bail.A bucket is usually an open-top container. In contrast, a pail can have a top or lid and is a shipping container. In common usage, the two terms are often used interchangeably.",
                    "URL": "https://en.wikipedia.org/wiki/Bucket"
                },
                "second": {
                    "Score": "0.82537115",
                    "Summary": "The second (symbol: s, also abbreviated: sec) is the base unit of time in the International System of Units (SI) (French: Système International d’unités), commonly understood and historically defined as 1⁄86400 of a day – this factor derived from the division of the day first into 24 hours, then to 60 minutes and finally to 60 seconds each. Analog clocks and watches often have sixty tick marks on their faces, representing seconds (and minutes), and a \"second hand\" to mark the passage of time in seconds.  Digital clocks and watches often have a two-digit seconds counter. The second is also part of several other units of measurement like meters per second for speed, meters per second per second for acceleration, and cycles per second for frequency.\n\nAlthough the historical definition of the unit was based on this division of the Earth's rotation cycle, the formal definition in the International System of Units (SI) is a much steadier timekeeper:The second is defined as being equal to the time duration of 9,192,631,770 periods of the radiation corresponding to the transition between the two hyperfine levels of the fundamental unperturbed ground-state of the caesium-133 atom.\nBecause the Earth's rotation varies and is also slowing very slightly, a leap second is added at irregular intervals to clock time to keep clocks in sync with Earth's rotation.\nMultiples of seconds are usually counted in hours and minutes. Fractions of a second are usually counted in tenths or hundredths. In scientific work, small fractions of a second are counted in milliseconds (thousandths), microseconds (millionths), nanoseconds (billionths), and sometimes smaller units of a second. An everyday experience with small fractions of a second is a 1-gigahertz microprocessor which has a cycle time of 1 nanosecond. Camera shutter speeds are often expressed in fractions of a second, such as 1⁄30 second or 1⁄1000 second.\nSexagesimal divisions of the day from a calendar based on astronomical observation have existed since the third millennium BC, though they were not seconds as we know them today. Small divisions of time could not be measured back then, so such divisions were mathematically derived. The first timekeepers that could count seconds accurately were pendulum clocks invented in the 17th century. Starting in the 1950s, atomic clocks became better timekeepers than Earth's rotation, and they continue to set the standard today.",
                    "URL": "https://en.wikipedia.org/wiki/Second"
                },
                "circular buffer": {
                    "Score": "0.819913",
                    "Summary": "In computer science, a circular buffer, circular queue, cyclic buffer or ring buffer is a data structure that uses a single, fixed-size buffer as if it were connected end-to-end. This structure lends itself easily to buffering data streams.\n\n",
                    "URL": "https://en.wikipedia.org/wiki/Circular_buffer"
                },
                "policy": {
                    "Score": "0.8084137",
                    "Summary": "Policy is a deliberate system of guidelines to guide decisions and achieve rational outcomes. A policy is a statement of intent and is implemented as a procedure or protocol. Policies are generally adopted by a governance body within an organization. Policies can assist in both subjective and objective decision making. Policies used in subjective decision-making usually assist senior management with decisions that must be based on the relative merits of a number of factors, and as a result, are often hard to test objectively, e.g. work–life balance policy. In contrast, policies to assist in objective decision-making are usually operational in nature and can be objectively tested, e.g. password policy.The term may apply to government, public sector organizations and groups, as well as individuals, Presidential executive orders, corporate privacy policies, and parliamentary rules of order are all examples of policy. Policy differs from rules or law. While the law can compel or prohibit behaviors (e.g. a law requiring the payment of taxes on income), policy merely guides actions toward those that are most likely to achieve the desired outcome.Policy or policy study may also refer to the process of making important organizational decisions, including the identification of different alternatives such as programs or spending priorities, and choosing among them on the basis of the impact they will have. Policies can be understood as political, managerial, financial, and administrative mechanisms arranged to reach explicit goals. In public corporate finance, a critical accounting policy is a policy for a firm/company or an industry that is considered to have a notably high subjective element, and that has a material impact on the financial statements.",
                    "URL": "https://en.wikipedia.org/wiki/Policy"
                }
            }
        },
        {
            "start_timestamp": "01:16:36",
            "title": "CONCLUSION",
            "text": "CONCLUSION\n\nFast data structures that support look-ups that\nare used all throughout DBMS internals.\n\n= Prade-oll het ween speed and Vexihilizy\n\nHash tables are usually not what you want to use\n\ntor a table index...",
            "transcript": "Idea is that we're splitting buckets based on the split pointer? Eventually we get to all the overflowed buckets and then, when we reach the last slot, you know we we loop around and get back to the beginning. Are there any quick questions about that? Great okay, so just to wrap up kind of the the hash tables that we talked about today are fast data structures. They support o1, lookups, which you know the the time complexities space complexity are important, but again we really care about where we care a lot about the constants that are associated with them. They're used all throughout dbms internals. We have these different trade-offs. We need to consider between speed and flexibility, but hash tables are usually not what you want to use for table index, so they have a lot of uses, in particular for things like joins or other intermediates, maybe for tracking metadata, but usually for table indexes. What you want to use is what we'll talk about next class b plus trees, which are have been described by some as the greatest data structure of all time. I happen to share that opinion uh and I'm really excited for uh wednesday's lecture. So I will see you all on wednesday [Applause].",
            "transcript-corrected": "The idea is that we're splitting buckets based on the split pointer? Eventually we get to all the overflowed buckets and then, when we reach the last slot, you know we we loop around and get back to the beginning. Are there any quick questions about that? Great, okay, so just to wrap up kind of the hash tables that we talked about today are fast data structures. They support o1, lookups, which you know the time complexities space complexity are important, but again we really care about where we care a lot about the constants that are associated with them. They're used all throughout DBMS internals. We have these different trade-offs. We need to consider between speed and flexibility, but hash tables are usually not what you want to use for table index, so they have a lot of uses, in particular for things like joins or other intermediates, maybe for tracking metadata, but usually for table indexes. What you want to use is what we'll talk about next class b, plus trees, which are have been described by some as the greatest data structure of all time. I happen to share that opinion, uh and I'm really excited for the uh Wednesdays lecture. So I will see you all on Wednesday [Applause].",
            "summary_brief": "So we're going to talk a little bit about hash tables and we're going to talk a little bit about some of the different ways that you can use them.",
            "summary_detailed": "The idea is that we're splitting buckets based on the split pointer? Eventually we get to all the overflowed buckets and then, when we reach the last slot, you know we we loop around and get back to the beginning. Are there any quick questions about that? Great, okay, so just to wrap up kind of the hash tables that we talked about today are fast data structures.",
            "key_concepts": {
                "speed": {
                    "Score": "0.83141375",
                    "Summary": "In everyday use and in kinematics, the speed (commonly referred to as v) of an object is the magnitude of the rate of change of its position with time or the magnitude of the change of its position per unit of time; it is thus a scalar quantity. The average speed of an object in an interval of time is the distance travelled by the object divided by the duration of the interval; the instantaneous speed is the limit of the average speed as the duration of the time interval approaches zero.\nSpeed has the dimensions of distance divided by time. The SI unit of speed is the metre per second (m/s), but the most common unit of speed in everyday usage is the kilometre per hour (km/h) or, in the US and the UK, miles per hour (mph). For air and marine travel the knot is commonly used.\nThe fastest possible speed at which energy or information can travel, according to special relativity, is the speed of light in a vacuum c = 299792458 metres per second (approximately 1079000000 km/h or 671000000 mph). Matter cannot quite reach the speed of light, as this would require an infinite amount of energy. In relativity physics, the concept of rapidity replaces the classical idea of speed.",
                    "URL": "https://en.wikipedia.org/wiki/Speed"
                },
                "data structure": {
                    "Score": "0.8168789",
                    "Summary": "In computer science, a data structure is a data organization, management, and storage format that enables efficient access and modification. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data, i.e., it is an algebraic structure about data.",
                    "URL": "https://en.wikipedia.org/wiki/Data_structure"
                },
                "structure": {
                    "Score": "0.84752727",
                    "Summary": "A structure is an arrangement and organization of interrelated elements in a material object or system, or the object or system so organized. Material structures include man-made objects such as buildings and machines and natural objects such as biological organisms, minerals and chemicals. Abstract structures include data structures in computer science and musical form. Types of structure include a hierarchy (a cascade of one-to-many relationships), a network featuring many-to-many links, or a lattice featuring connections between components that are neighbors in space.",
                    "URL": "https://en.wikipedia.org/wiki/Structure"
                },
                "bucket": {
                    "Score": "0.86106384",
                    "Summary": "A bucket is typically a watertight, vertical cylinder or truncated cone or square, with an open top and a flat bottom, attached to a semicircular carrying handle called the bail.A bucket is usually an open-top container. In contrast, a pail can have a top or lid and is a shipping container. In common usage, the two terms are often used interchangeably.",
                    "URL": "https://en.wikipedia.org/wiki/Bucket"
                },
                "lecture": {
                    "Score": "0.8168789",
                    "Summary": "A lecture (from the Greek lecture, meaning reading) is an oral presentation intended to present information or teach people about a particular subject, for example by a university or college teacher. Lectures are used to convey critical information, history, background, theories, and equations. A politician's speech, a minister's sermon, or even a business person’s sales presentation may be similar in form to a lecture.  Usually the lecturer will stand at the front of the room and recite information relevant to the lecture's content.\nThough lectures are much criticised as a teaching method, universities have not yet found practical alternative teaching methods for the large majority of their courses.  Critics point out that lecturing is mainly a one-way method of communication that does not involve significant audience participation but relies upon passive learning.  Therefore, lecturing is often contrasted to active learning. Lectures delivered by talented speakers can be highly stimulating; at the very least, lectures have survived in academia as a quick, cheap, and efficient way of introducing large numbers of students to a particular field of study.\nLectures have a significant role outside the classroom, as well. Academic and scientific awards routinely include a lecture as part of the honor, and academic conferences often center on \"keynote addresses\", i.e., lectures. The public lecture has a long history in the sciences and in social movements. Union halls, for instance, historically have hosted numerous free and public lectures on a wide variety of matters. Similarly, churches, community centers, libraries, museums, and other organizations have hosted lectures in furtherance of their missions or their constituents' interests. Lectures represent a continuation of oral tradition in contrast to textual communication in books and other media. Lectures may be considered a type of grey literature.",
                    "URL": "https://en.wikipedia.org/wiki/Lecture"
                },
                "space complexity": {
                    "Score": "0.8082656",
                    "Summary": "The space complexity of an algorithm or a computer program is the amount of memory space required to solve an instance of the computational problem as a function of characteristics of the input. It is the memory required by an algorithm until it executes completely.Similar to time complexity, space complexity is often expressed asymptotically in big O notation, such as \n  \n    \n      \n        O\n        (\n        n\n        )\n        ,\n      \n    \n    {\\displaystyle O(n),}\n  \n\n  \n    \n      \n        O\n        (\n        n\n        log\n        ⁡\n        n\n        )\n        ,\n      \n    \n    {\\displaystyle O(n\\log n),}\n   \n  \n    \n      \n        O\n        (\n        \n          n\n          \n            α\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle O(n^{\\alpha }),}\n   \n  \n    \n      \n        O\n        (\n        \n          2\n          \n            n\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle O(2^{n}),}\n   etc., where n is a characteristic of the input influencing space complexity.",
                    "URL": "https://en.wikipedia.org/wiki/Space_complexity"
                }
            }
        },
        {
            "start_timestamp": "01:17:58",
            "title": "",
            "text": "",
            "transcript": "[Music] this video, I see talking about the saint nice brew, run through a can or two shared with my brewers, magnificent buster's mellow and for the rest of the commercial pastor, michael to my fellow or a mic check busted. The bees are said to grab a 40. [Music], take a sip and wipe your lips to my 40s, getting more I'm out, he gots to fill drink, a drink, a drink, and then I burp after I slurp ice through. I put in much work with the bmt and the e trouble get us a saint. I crew, on the double you.",
            "transcript-corrected": "[Music] this video, I see talking about the saint nice brew, run through a can or two shared with my brewers, magnificent buster's mellow and for the rest of the commercial pastor, Michael to my fellow or a mic check busted. The bees are said to grab a 40. [Music], take a sip and wipe your lips to my 40s, getting more I'm out, he gets to fill drink, a drink, a drink, and then I burp after I slurp ice through. I put in much work with the bmt and the e trouble get us a saint. My crew, on the double you.",
            "summary_brief": "My crew, on the double you.",
            "summary_detailed": "\"I put in much work with the bmt and the e trouble get us a saint\" \"My crew, on the double you\" \"The bees are said to grab a 40. [Music] Take a sip and wipe your lips to my 40s, getting more I'm out\" \"I burp after I slurp ice through\"",
            "key_concepts": {}
        }
    ]
}